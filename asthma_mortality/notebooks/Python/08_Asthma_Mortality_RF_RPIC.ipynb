{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyM6mqgqY6Jg/zxOJk+DpxDa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/acoiman/pdt/blob/main/asthma_mortality/notebooks/Python/08_Asthma_Mortality_RF_RPIC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predicting Asthma Mortality in Argentina using Remote Sensing Data and Machine Learning\n",
        "\n"
      ],
      "metadata": {
        "id": "kZxCQdAv7GPa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we will use remote sensing data and Random Forest (RF) to predict asthma mortality in Argentina at departmental level from 2001 to 2022. We will model the Normalized Asthma Mortality Rate (NAMR) in a two-stage RF approach—classification followed by regression—using predictor variables derived from satellite-based observations such as burned areas, and Particulate Matter with 2.5 micrometers in diameter or less (PM2.5), along with Population Density (PD), and lagged and feature engineered variables."
      ],
      "metadata": {
        "id": "boJNPAKpFs7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import required libraries"
      ],
      "metadata": {
        "id": "fXevDbl0GYZh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dataframe libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# geospatial libraries\n",
        "import geopandas as gpd\n",
        "import mapclassify\n",
        "from libpysal.weights import Queen\n",
        "from esda.moran import Moran\n",
        "from pysal.explore import esda\n",
        "\n",
        "# plot libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "import seaborn as sns\n",
        "from matplotlib.patches import Patch\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
        "\n",
        "# sklearn libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error,r2_score,explained_variance_score,median_absolute_error, max_error\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# other libraries\n",
        "import os\n",
        "from joblib import Parallel, delayed\n",
        "import shap\n",
        "from itables import init_notebook_mode, show"
      ],
      "metadata": {
        "id": "xBh05cJz7J5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load and reduce data"
      ],
      "metadata": {
        "id": "IbsFWZPlZAnr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd work/"
      ],
      "metadata": {
        "id": "o700iVYSRUAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the PROJ_LIB path\n",
        "os.environ['PROJ_LIB'] = \"/opt/conda/envs/gds/share/proj\""
      ],
      "metadata": {
        "id": "V2QSVvb5ODyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset with data per department\n",
        "gdf = gpd.read_file(\"pdt/asthma_mortality/data/gpkg/tma_pm25_ba_pd_pdpm25_2001_2022.gpkg\")"
      ],
      "metadata": {
        "id": "-2n88TuBySeZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop geometry\n",
        "df = gdf.drop(columns=\"geometry\")"
      ],
      "metadata": {
        "id": "GpwOavZXySrG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape df to long format\n",
        "years = range(2001, 2023)\n",
        "records = []"
      ],
      "metadata": {
        "id": "1sArwXOhycxt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for _, row in df.iterrows():\n",
        "    iddpto = row[\"IDDPTO\"]\n",
        "    for year in years:\n",
        "        records.append({\n",
        "            \"IDDPTO\": iddpto,\n",
        "            \"YEAR\": year,\n",
        "            \"CA\": row.get(f\"CA_{year}\", np.nan),\n",
        "            \"PM25\": row.get(f\"PM25_{year}\", np.nan),\n",
        "            \"NBA\": row.get(f\"NBA_{year}\", np.nan),\n",
        "            \"PD\": row.get(f\"PD_{year}\", np.nan),\n",
        "            \"PDPM25\": row.get(f\"PDPM25_{year}\", np.nan)\n",
        "            })"
      ],
      "metadata": {
        "id": "QcFq8Nybyc0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create new df from list and sort\n",
        "panel_df = pd.DataFrame(records)"
      ],
      "metadata": {
        "id": "tjF9UTvxyiJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort and reset index\n",
        "panel_df = panel_df.sort_values(by=[\"IDDPTO\", \"YEAR\"]).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "-gY9XrPXymxS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploratory Data Analysis (EDA)"
      ],
      "metadata": {
        "id": "OZSDIWyhsttE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a copy of the panel_df DataFrame for exploratory data analysis (EDA)\n",
        "df_eda = panel_df.copy()"
      ],
      "metadata": {
        "id": "cwaLM9Tym9ql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the 'YEAR' column in panel_df to datetime format and assign it to df_eda\n",
        "df_eda['YEAR'] = pd.to_datetime(panel_df['YEAR'], format='%Y')"
      ],
      "metadata": {
        "id": "pL2C0bKOmgkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize the first rows\n",
        "init_notebook_mode(all_interactive=True)\n",
        "show(df_eda)"
      ],
      "metadata": {
        "id": "NMiJpZ_0ymz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get the number of rows\n",
        "len(df_eda)"
      ],
      "metadata": {
        "id": "AeqINbgpyiSG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter the year 2022 (Test set)\n",
        "df_eda_2022 = df_eda[df_eda['YEAR'] == pd.to_datetime(2022, format='%Y')]"
      ],
      "metadata": {
        "id": "uVbw3LtTl6XK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize the first rows\n",
        "init_notebook_mode(all_interactive=False)\n",
        "df_eda_2022.CA.describe()"
      ],
      "metadata": {
        "id": "dUPwi-8AhHMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a box plot for CA column\n",
        "sns.boxplot(x=df_eda_2022['CA'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xnGE4NeQg00D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a barplot showing the distribution  pf CA column\n",
        "sns.histplot(df_eda_2022['CA'], bins=25)\n",
        "plt.xlabel('CA')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Distribution of NAMR')\n",
        "plt.xlabel(\"NAMR\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oaxGEkoxg0_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# how many zero values are there for CA column\n",
        "df_eda_2022[df_eda_2022['CA'] == 0].shape[0]"
      ],
      "metadata": {
        "id": "fbcOBLy9iuCL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# in percentage\n",
        "round(((df_eda_2022[df_eda_2022['CA'] == 0].shape[0] / len(df_eda_2022)) * 100), 2)"
      ],
      "metadata": {
        "id": "-b99xt-kg1Gn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter out the year 2022\n",
        "df_eda_0121 = df_eda[df_eda['YEAR'] < pd.to_datetime(2022, format='%Y')]"
      ],
      "metadata": {
        "id": "lp9d7vTcp1Oi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the 'YEAR' column as the index for the DataFrame\n",
        "df_eda_0121.set_index('YEAR', inplace=True)"
      ],
      "metadata": {
        "id": "5xTwCZEei4zl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot mortality rate over time\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.lineplot(data=df_eda_0121, x=df_eda_0121.index, y='CA', marker='o', estimator='mean')\n",
        "plt.title('Mean Mortality Rate Over Time')\n",
        "plt.ylabel('Mean NAMR')\n",
        "plt.xlabel('Year')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ozn-svl0i42P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ACF and PACF plots\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
        "\n",
        "plot_pacf(df_eda_0121['CA'], ax=axes[0], lags=21, title='Partial Autocorrelation (PACF)')\n",
        "plot_acf(df_eda_0121['CA'], ax=axes[1], lags=21, title='Autocorrelation (ACF)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "u6XCGxWRi45I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exploratory Spatial  Data Analysis (ESDA)"
      ],
      "metadata": {
        "id": "s30rJPMg3mzn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset with data per department\n",
        "gdf = gpd.read_file(\"pdt/asthma_mortality/data/gpkg/tma_pm25_ba_pd_pdpm25_2001_2022.gpkg\")"
      ],
      "metadata": {
        "id": "LFPCmdS83lsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape gdf to long format\n",
        "years = range(2001, 2023)\n",
        "records = []"
      ],
      "metadata": {
        "id": "a2mzrcX23lsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for _, row in gdf.iterrows():\n",
        "    iddpto = row[\"IDDPTO\"]\n",
        "    geometry = row[\"geometry\"]\n",
        "    for year in years:\n",
        "        records.append({\n",
        "            \"IDDPTO\": iddpto,\n",
        "            \"YEAR\": year,\n",
        "            \"CA\": row.get(f\"CA_{year}\", np.nan),\n",
        "            \"PM25\": row.get(f\"PM25_{year}\", np.nan),\n",
        "            \"NBA\": row.get(f\"NBA_{year}\", np.nan),\n",
        "            \"PD\": row.get(f\"PD_{year}\", np.nan),\n",
        "            \"PDPM25\": row.get(f\"PDPM25_{year}\", np.nan),\n",
        "            \"geometry\": geometry # Add geometry\n",
        "            })"
      ],
      "metadata": {
        "id": "Orqq2xcd3lsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create new df from list and sort\n",
        "panel_gdf = pd.DataFrame(records)"
      ],
      "metadata": {
        "id": "7GbOZKNj3lsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort and reset index\n",
        "panel_gdf = panel_gdf.sort_values(by=[\"IDDPTO\", \"YEAR\"]).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "j3fbgLZp3lsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize the fisrt rows\n",
        "init_notebook_mode(all_interactive=True)\n",
        "show(panel_gdf)"
      ],
      "metadata": {
        "id": "Vx3JdCS64U_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter the DataFrame to include rows where 'YEAR' is less than 2022 and create a copy\n",
        "gdf_esda_0121 = panel_gdf[panel_gdf['YEAR'] < 2022].copy()"
      ],
      "metadata": {
        "id": "obNKES0u5UeQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define spatial weights matrix using Queen contiguity\n",
        "w = Queen.from_dataframe(gdf_esda_0121)\n",
        "w.transform = 'R'"
      ],
      "metadata": {
        "id": "jedPW4GN1nit"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute Moran's I for each mean feature\n",
        "moran_results = {}\n",
        "for col in ['CA', 'PM25', 'NBA', 'PD', 'PDPM25']:\n",
        "    moran = Moran(gdf_esda_0121[col], w)\n",
        "    moran_results[col] = {'Moran_I': moran.I, 'Moran_p_sim': moran.p_sim}\n",
        "# Create a table (DataFrame) from the results\n",
        "moran_df = pd.DataFrame.from_dict(moran_results, orient='index')"
      ],
      "metadata": {
        "id": "zznS94a82b9M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the table\n",
        "init_notebook_mode(all_interactive=True)\n",
        "show(moran_df)"
      ],
      "metadata": {
        "id": "EGA09b0f6Nr3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1 – RF Classification Model\n",
        "\n",
        "In this section, we will train and evaluate a Random Forest (RF) classification model to predict whether the Normalized Asthma Mortality Rate (NAMR, represented by the variable CA) indicates the absence (0) or presence (1) of asthma mortality (binary classification). We will apply a walk-forward (expanding window) validation approach, which is appropriate for epidemiological studies involving time series data¹. We will start by training the RF classification model using data from 2001 to 2006 (a 5-year window) and testing it with data from 2007. The training window will then be expanded by one year at each iteration until it spans from 2001 to 2021, with 2022 data used for testing.\n"
      ],
      "metadata": {
        "id": "FviPCsCgeazB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training and Testing a RF Classification Model"
      ],
      "metadata": {
        "id": "rmaljiP9yO9M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a copy of the DataFrame to preserve the original data\n",
        "df_ts = panel_df.copy()"
      ],
      "metadata": {
        "id": "VvbjmPeX8KeR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create lag variables (up to 2 years)\n",
        "def create_lags(df, var, max_lag=2):\n",
        "    for lag in range(1, max_lag+1):\n",
        "        df[f\"{var}_lag{lag}\"] = df[var].shift(lag)\n",
        "    return df"
      ],
      "metadata": {
        "id": "kUE_4MC78Jr8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for var in [\"PM25\", \"NBA\", \"PD\", \"PDPM25\"]:\n",
        "    df_ts = create_lags(df_ts, var)"
      ],
      "metadata": {
        "id": "t33aEHI48Tgi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for var in [\"CA\"]:\n",
        "    df_ts = create_lags(df_ts, var,  max_lag=2)"
      ],
      "metadata": {
        "id": "xY5QgpQIrtFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop the initial rows with NaNs due to lagging\n",
        "df_ts = df_ts.dropna().reset_index(drop=True)"
      ],
      "metadata": {
        "id": "hO8mOP018Z-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Binary target\n",
        "df_ts['CA_bin'] = (df_ts['CA'] > 0).astype(int)"
      ],
      "metadata": {
        "id": "b3wi4OCfB7tG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize data frame\n",
        "init_notebook_mode(all_interactive=True)\n",
        "show(df_ts)"
      ],
      "metadata": {
        "id": "_KdLGbPZIE8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = []  # results list\n",
        "\n",
        "for i in range(2006, 2022):  # start walk-forward from year 2006 to 2021\n",
        "    train_years = list(range(2001, i + 1))  # expanding window\n",
        "    test_year = i + 1\n",
        "    print(f\"Training: {train_years[0]}–{train_years[-1]}, Testing: {test_year}\")\n",
        "\n",
        "    # Split train/test by year\n",
        "    train_df = df_ts[df_ts['YEAR'].isin(train_years)]\n",
        "    test_df = df_ts[df_ts['YEAR'] == test_year]\n",
        "\n",
        "    # Define features and target\n",
        "    features = ['PM25', 'NBA', 'PD', 'PDPM25', 'PM25_lag1',\n",
        "                'PM25_lag2', 'NBA_lag1', 'NBA_lag2', 'PD_lag1', 'PD_lag2',\n",
        "                'PDPM25_lag1', 'PDPM25_lag2', 'CA_lag1', 'CA_lag2']\n",
        "    target = 'CA_bin'\n",
        "\n",
        "    X_train = train_df[features]\n",
        "    y_train = train_df[target]\n",
        "    X_test = test_df[features]\n",
        "    y_test = test_df[target]\n",
        "\n",
        "    # Train classification model\n",
        "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predict (labels)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Classification metrics\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    prec = precision_score(y_test, y_pred, zero_division=0)\n",
        "    rec = recall_score(y_test, y_pred, zero_division=0)\n",
        "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
        "\n",
        "    # Store results\n",
        "    results.append({\n",
        "        'train_years': f\"{train_years[0]}-{train_years[-1]}\",\n",
        "        'test_year': test_year,\n",
        "        'Accuracy': acc,\n",
        "        'Precision': prec,\n",
        "        'Recall': rec,\n",
        "        'F1_Score': f1\n",
        "    })"
      ],
      "metadata": {
        "id": "QpzJKkrZf1CH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert results into a dataframe\n",
        "results_df = pd.DataFrame(results)"
      ],
      "metadata": {
        "id": "MfQ2YyQkdYMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize the results\n",
        "init_notebook_mode(all_interactive=True)\n",
        "results_df"
      ],
      "metadata": {
        "id": "PynMwBM8dYPy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate and display the mean and standard deviation for each evaluation metric\n",
        "mean_metrics = results_df[['Accuracy', 'Precision', 'Recall', 'F1_Score']].mean()\n",
        "std_metrics = results_df[['Accuracy', 'Precision', 'Recall', 'F1_Score']].std()\n",
        "\n",
        "print(\"Mean of Evaluation Metrics:\")\n",
        "print(mean_metrics)\n",
        "print(\"\\nStandard Deviation of Evaluation Metrics:\")\n",
        "print(std_metrics)"
      ],
      "metadata": {
        "id": "w4-M16ST0b5Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metric Value\tInterpretation\n",
        "* Accuracy\t0.775 ± 0.012.\tOn average, the classifier correctly identified whether CA was 0 or 1 about 77.5% ± 1.2% of the time. This is decent but may be misleading if there is class imbalance (e.g., many zeros).\n",
        "* Precision\t0.6770 ±  0.039.\tOn average, of all the cases where the classifier predicted CA > 0, 67.7% ± 3.9% were correct. Upper moderate precision means some false positives (it sometimes predicts CA as 1 when the true value is 0).\n",
        "* Recall 0.611 ± 0.047.\tOn average, the model only identified 61.1%  ± 4.7% of true CA > 0 cases .  So it's missing nearly a third of the true positives (false negatives are moderate).\n",
        "* F1 Score\t0.638 ± 0.030.\tThe harmonic mean of precision and recall. This moderate value indicates a trade-off between missing positives and over-predicting them."
      ],
      "metadata": {
        "id": "_uxoPiB2_ktm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a plot of each metric by year:\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "for metric in ['Accuracy', 'Precision', 'Recall', 'F1_Score']:\n",
        "    ax.plot(results_df['test_year'], results_df[metric], marker='o', label=metric)\n",
        "\n",
        "ax.set_xlabel(\"Test Year\")\n",
        "ax.set_ylabel(\"Score\")\n",
        "ax.set_title(\"Walk-Forward Validation Metrics (2007–2022)\")\n",
        "ax.legend()\n",
        "ax.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5LYlT0zR6vkm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RF Classification Model Parameter Tuning"
      ],
      "metadata": {
        "id": "K8PM_t-m3sV5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define hyperparameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [None, 5, 10],\n",
        "    'min_samples_split': [2, 5],\n",
        "    'min_samples_leaf': [1, 2]\n",
        "}"
      ],
      "metadata": {
        "id": "Hq5yKReQdYU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = []  # clear results list before starting\n",
        "\n",
        "for i in range(2006, 2022):  # walk-forward from 2006 to 2021\n",
        "    train_years = list(range(2001, i + 1))  # expanding window\n",
        "    test_year = i + 1\n",
        "    print(f\"Training: {train_years[0]}–{train_years[-1]}, Testing: {test_year}\")\n",
        "\n",
        "    # Split train/test by year\n",
        "    train_df = df_ts[df_ts['YEAR'].isin(train_years)]\n",
        "    test_df = df_ts[df_ts['YEAR'] == test_year]\n",
        "\n",
        "    # Define features and target\n",
        "    features = ['PM25', 'NBA', 'PD', 'PDPM25', 'PM25_lag1',\n",
        "                'PM25_lag2', 'NBA_lag1', 'NBA_lag2', 'PD_lag1', 'PD_lag2',\n",
        "                'PDPM25_lag1', 'PDPM25_lag2', 'CA_lag1', 'CA_lag2']\n",
        "    target = 'CA_bin'\n",
        "\n",
        "    X_train = train_df[features]\n",
        "    y_train = train_df[target]\n",
        "    X_test = test_df[features]\n",
        "    y_test = test_df[target]\n",
        "\n",
        "    # Grid Search with 3-fold CV\n",
        "    grid_search = GridSearchCV(\n",
        "        estimator=RandomForestClassifier(random_state=42),\n",
        "        param_grid=param_grid,\n",
        "        scoring='recall',\n",
        "        cv=3,\n",
        "        n_jobs=-1,\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    best_model = grid_search.best_estimator_\n",
        "\n",
        "    # Predict on test set\n",
        "    y_pred = best_model.predict(X_test)\n",
        "\n",
        "    # Evaluation metrics\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    prec = precision_score(y_test, y_pred, zero_division=0)\n",
        "    rec = recall_score(y_test, y_pred, zero_division=0)\n",
        "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
        "\n",
        "    # Store results and best params\n",
        "    results.append({\n",
        "        'train_years': f\"{train_years[0]}-{train_years[-1]}\",\n",
        "        'test_year': test_year,\n",
        "        'Accuracy': acc,\n",
        "        'Precision': prec,\n",
        "        'Recall': rec,\n",
        "        'F1_Score': f1,\n",
        "        'Best_Params': grid_search.best_params_\n",
        "    })\n"
      ],
      "metadata": {
        "id": "4t-prDNhoXPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert results into a dataframe\n",
        "resultspt_df = pd.DataFrame(results)"
      ],
      "metadata": {
        "id": "4PnM-joGoXSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize dataframe\n",
        "init_notebook_mode(all_interactive=True)\n",
        "resultspt_df"
      ],
      "metadata": {
        "id": "5ROi0CWboXU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate and display the mean and standard deviation for each evaluation metric\n",
        "mean_metrics = resultspt_df[['Accuracy', 'Precision', 'Recall', 'F1_Score']].mean()\n",
        "std_metrics = resultspt_df[['Accuracy', 'Precision', 'Recall', 'F1_Score']].std()\n",
        "\n",
        "print(\"Mean of Evaluation Metrics:\")\n",
        "print(mean_metrics)\n",
        "print(\"\\nStandard Deviation of Evaluation Metrics:\")\n",
        "print(std_metrics)"
      ],
      "metadata": {
        "id": "o3rWzr_GdYXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metric Value\tInterpretation\n",
        "* Accuracy\t0.776 ± 0.017.\tOn average, the classifier correctly identified whether CA was 0 or 1 about 77.6% ± 1.7% of the time. This is decent but may be misleading if there is class imbalance (e.g., many zeros).\n",
        "* Precision\t0.678 ±  0.040.\tOn average, of all the cases where the classifier predicted CA > 0, 67.8% ± 4% were correct. Upper moderate precision means some false positives (it sometimes predicts CA as 1 when the true value is 0).\n",
        "* Recall 0.600 ± 0.047.\tOn average, the model only identified 60%  ± 4.7% of true CA > 0 cases .  So it's missing nearly a third of the true positives (false negatives are moderate).\n",
        "* F1 Score\t0.635 ± 0.032.\tThe harmonic mean of precision and recall. This moderate value indicates a trade-off between missing positives and over-predicting them.\n",
        "\n",
        "**Note:** Parameter tuning did not improve substantially model performance"
      ],
      "metadata": {
        "id": "VPs1WSjQ5ce5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a plot of each metric by year:\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "for metric in ['Accuracy', 'Precision', 'Recall', 'F1_Score']:\n",
        "    ax.plot(results_df['test_year'], resultspt_df[metric], marker='o', label=metric)\n",
        "\n",
        "ax.set_xlabel(\"Test Year\")\n",
        "ax.set_ylabel(\"Score\")\n",
        "ax.set_title(\"Walk-Forward Validation Metrics (2007–2022) with Parameter Tuning\")\n",
        "ax.legend()\n",
        "ax.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fVdR4PNC6_6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training RF Classification Model on 2001–2021 and Predict 2022\n",
        "\n",
        "In this section, for the SHAP analysis, we will train the RF classification model on data from 2001–2021 and predict, for 2022, whether the Normalized Asthma Mortality Rate (NAMR, represented by the variable CA) indicates absence (0) or presence (1) of asthma mortality (binary classification)"
      ],
      "metadata": {
        "id": "N_J9hX8q8tYf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define features and target\n",
        "features = ['PM25', 'NBA', 'PD', 'PDPM25', 'PM25_lag1',\n",
        "            'PM25_lag2', 'NBA_lag1', 'NBA_lag2', 'PD_lag1', 'PD_lag2',\n",
        "            'PDPM25_lag1', 'PDPM25_lag2', 'CA_lag1', 'CA_lag2']\n",
        "target = 'CA_bin'"
      ],
      "metadata": {
        "id": "xCfO8HQYIfCU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training and test sets\n",
        "train_df = df_ts[df_ts['YEAR'] <= 2021].dropna(subset=features + [target])\n",
        "test_df = df_ts[df_ts['YEAR'] == 2022].dropna(subset=features + [target])"
      ],
      "metadata": {
        "id": "DLQ413_eMxIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define inputs\n",
        "X_train = train_df[features]\n",
        "y_train = train_df[target]\n",
        "\n",
        "# Keep IDDPTO in test set\n",
        "X_test_full = test_df[['IDDPTO'] + features+ ['CA_bin']].copy()\n",
        "y_test = test_df[target].reset_index(drop=True)"
      ],
      "metadata": {
        "id": "nW6WK0dUM3UK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "EshhB9FhM3Wq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict using only feature columns\n",
        "y_pred = clf.predict(X_test_full[features])\n",
        "\n",
        "#  Add prediction to test set with IDDPTO\n",
        "X_test_full['CA_bin_pred'] = y_pred"
      ],
      "metadata": {
        "id": "mLu3UpuzNiJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate prediction\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, zero_division=0)\n",
        "recall = recall_score(y_test, y_pred, zero_division=0)\n",
        "f1 = f1_score(y_test, y_pred, zero_division=0)\n",
        "\n",
        "# Print metrics\n",
        "print(f\"Prediction Results for 2022:\")\n",
        "print(f\"Accuracy:  {accuracy:.3f}\")\n",
        "print(f\"Precision: {precision:.3f}\")\n",
        "print(f\"Recall:    {recall:.3f}\")\n",
        "print(f\"F1 Score:  {f1:.3f}\")"
      ],
      "metadata": {
        "id": "4a-0Ox1HM3Zq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metric Value\tInterpretation\n",
        "* Accuracy\t0.781.\tOn average, the classifier correctly predicted whether CA was 0 or 1 in 2022 in about 78.1% of the time. This is decent but may be misleading if there is class imbalance (e.g., many zeros).\n",
        "* Precision\t0.720.\tOn average, of all the cases where the classifier predicted CA > 0 in 2022, 72 % were correct. This precision means a few false positives (it sometimes predicts CA as 1 when the true value is 0).\n",
        "* Recall 0.559.\tOn average, the model only identified 55.9%  of true CA > 0 cases.  So it's missing nearly a half of the true positives (false negatives are high).\n",
        "* F1 Score\t0.629.\tThe harmonic mean of precision and recall. This moderate value indicates a trade-off between missing positives and over-predicting them."
      ],
      "metadata": {
        "id": "pobVGpCMnkTW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preserve only IDDPTO, CA_bin, and CA_bin_pred from X_test_full\n",
        "bin_pred_result = X_test_full[['IDDPTO', 'CA_bin', 'CA_bin_pred']].copy()"
      ],
      "metadata": {
        "id": "3dxD1PjhNpoy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the new DataFrame\n",
        "init_notebook_mode(all_interactive=True)\n",
        "show(bin_pred_result)"
      ],
      "metadata": {
        "id": "MS4qUKc1IfFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SHAP (SHapley Additive Explanations)\n",
        "\n",
        "In this section we will interpret the contribution of each independent variable to the final predition of the RF classification model using the SHAP method"
      ],
      "metadata": {
        "id": "OlZzuaJVYLwG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- SHAP for Binary Classifier ----\n",
        "# Use TreeExplainer (optimized for RandomForest)\n",
        "explainer = shap.TreeExplainer(clf)"
      ],
      "metadata": {
        "id": "6hQEBSfmYLwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get the test set\n",
        "X = test_df[features]"
      ],
      "metadata": {
        "id": "BhlFOlbFYLwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to compute SHAP values for a single row\n",
        "def compute_shap(row):\n",
        "    return explainer.shap_values(row)"
      ],
      "metadata": {
        "id": "QMfvgKByYLwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parallel computation\n",
        "shap_values_list = Parallel(n_jobs=-1)(\n",
        "    delayed(compute_shap)(X.iloc[[i]]) for i in range(len(X))\n",
        ")"
      ],
      "metadata": {
        "id": "ecmEZI2uYLwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine SHAP values for Class 1 into a single array\n",
        "shap_values = np.vstack([vals[0][:, 1] for vals in shap_values_list])  # Class 1 SHAPs\n"
      ],
      "metadata": {
        "id": "8eLMUU7SYLwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a SHAP summary plot to visualize the impact of features on the model's predictions\n",
        "shap.summary_plot(shap_values, X, feature_names=features,\n",
        "                  show= False)\n",
        "plt.title(\"(a) SHAP Summary Plot RF Classification\", fontsize=17)\n",
        "plt.xlabel(\"SHAP Values\", size=12)\n",
        "plt.ylabel(\"Features\", size=12)\n",
        "plt.ylabel(\"Features\")\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "nMXc1dX2YLwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Part 2 – Regression Model\n",
        "\n",
        "\n",
        "In this section, we will train and evaluate a Random Forest (RF) regression model to predict NAMR values where it is present  (CA_bin == 1 or NAMR values > 0). We will apply a walk-forward (expanding window) validation approach, which is appropriate for epidemiological studies involving time series data¹. We will start by training the RF regression model using data from 2001 to 2006 (a 5-year window) and testing it with data from 2007. The training window will then be expanded by one year at each iteration until it spans from 2001 to 2021, with 2022 data used for testing."
      ],
      "metadata": {
        "id": "J_uk1xOhj-1W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter bin_pred_result to keep only rows where CA_bin is 1\n",
        "bin_positive = df_ts[(df_ts['CA_bin'] == 1)]"
      ],
      "metadata": {
        "id": "rTQprraPNtWW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the filtered DataFrame\n",
        "init_notebook_mode(all_interactive=True)\n",
        "show(bin_positive)"
      ],
      "metadata": {
        "id": "w7c0-86ZRh04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training and Testing a RF Regression Model"
      ],
      "metadata": {
        "id": "duzZd-SCVJ-y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = []  # store results\n",
        "\n",
        "for i in range(2006, 2022):  # walk-forward from 2006 to 2021\n",
        "    train_years = list(range(2001, i + 1))  # expanding window\n",
        "    test_year = i + 1\n",
        "    print(f\"Training: {train_years[0]}–{train_years[-1]}, Testing: {test_year}\")\n",
        "\n",
        "    # Filter by year\n",
        "    train_df = df_ts[df_ts['YEAR'].isin(train_years)]\n",
        "    test_df = df_ts[df_ts['YEAR'] == test_year]\n",
        "\n",
        "    # Filter by CA_bin == 1\n",
        "    train_pos = train_df[train_df['CA_bin'] == 1].copy()\n",
        "    test_pos = test_df[test_df['CA_bin'] == 1].copy()\n",
        "\n",
        "    # Skip iteration if empty (avoid errors)\n",
        "    if train_pos.empty or test_pos.empty:\n",
        "        print(f\"Skipped: No positive cases in train or test for {test_year}\")\n",
        "        continue\n",
        "\n",
        "    # Features and regression target\n",
        "    features = ['PM25', 'NBA', 'PD', 'PDPM25', 'PM25_lag1',\n",
        "                'PM25_lag2', 'NBA_lag1', 'NBA_lag2', 'PD_lag1', 'PD_lag2',\n",
        "                'PDPM25_lag1', 'PDPM25_lag2', 'CA_lag1', 'CA_lag2']\n",
        "    target = 'CA'  # regression target\n",
        "\n",
        "    X_train = train_pos[features]\n",
        "    y_train = train_pos[target]\n",
        "    X_test = test_pos[features]\n",
        "    y_test = test_pos[target]\n",
        "\n",
        "    # Train regression model\n",
        "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predict and evaluate\n",
        "    y_pred = model.predict(X_test)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    # Save results\n",
        "    results.append({\n",
        "        'train_years': f\"{train_years[0]}-{train_years[-1]}\",\n",
        "        'test_year': test_year,\n",
        "        'R2': r2\n",
        "    })\n"
      ],
      "metadata": {
        "id": "LdBXM7ufM6h8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert the results into a data frame\n",
        "results_df = pd.DataFrame(results)"
      ],
      "metadata": {
        "id": "qOfocX5nM6lW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "init_notebook_mode(all_interactive=True)\n",
        "results_df"
      ],
      "metadata": {
        "id": "iGmRLJLdM6oL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate and display the mean and standard deviation for each evaluation metric\n",
        "mean_metrics = results_df[['R2']].mean()\n",
        "std_metrics = results_df[[\"R2\"]].std()\n",
        "\n",
        "print(\"Mean of Evaluation Metrics:\")\n",
        "print(mean_metrics)\n",
        "print(\"\\nStandard Deviation of Evaluation Metrics:\")\n",
        "print(std_metrics)"
      ],
      "metadata": {
        "id": "ifYW4mpfM6q8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* A mean R² of 0.440 means the model explains about 44%   of the variability in asthma mortality among departments where mortality actually occurred.\n",
        "\n",
        "* The Random Forest regression model trained only on positive asthma mortality cases (CA_bin = 1) achieved a mean R² of 0.440 ± 0.138 across 16 annual test windows (2007–2021). This indicates moderate predictive capacity in estimating asthma mortality rates based on the selected predictors"
      ],
      "metadata": {
        "id": "ZrycQ4XqSdJ4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RF Regression Model Parameter Tuning"
      ],
      "metadata": {
        "id": "8lyO1cGFX0kc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define feature list and hyperparameter grid\n",
        "features = ['PM25', 'NBA', 'PD', 'PDPM25', 'PM25_lag1',\n",
        "            'PM25_lag2', 'NBA_lag1', 'NBA_lag2', 'PD_lag1', 'PD_lag2',\n",
        "            'PDPM25_lag1', 'PDPM25_lag2', 'CA_lag1', 'CA_lag2']\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [None, 10],\n",
        "    'min_samples_leaf': [1, 2]\n",
        "}"
      ],
      "metadata": {
        "id": "3GApD5twUvUY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "\n",
        "for i in range(2006, 2022):  # walk-forward from 2006 to 2021\n",
        "    train_years = list(range(2001, i + 1))\n",
        "    test_year = i + 1\n",
        "    print(f\"Training: {train_years[0]}–{train_years[-1]}, Testing: {test_year}\")\n",
        "\n",
        "    # Filter by year\n",
        "    train_df = df_ts[df_ts['YEAR'].isin(train_years)]\n",
        "    test_df = df_ts[df_ts['YEAR'] == test_year]\n",
        "\n",
        "    # Filter to CA_bin == 1\n",
        "    train_pos = train_df[train_df['CA_bin'] == 1].copy()\n",
        "    test_pos = test_df[test_df['CA_bin'] == 1].copy()\n",
        "\n",
        "    # Skip if empty\n",
        "    if train_pos.empty or test_pos.empty:\n",
        "        print(f\"Skipped: No positive cases in train or test for {test_year}\")\n",
        "        continue\n",
        "\n",
        "    X_train = train_pos[features]\n",
        "    y_train = train_pos['CA']\n",
        "    X_test = test_pos[features]\n",
        "    y_test = test_pos['CA']\n",
        "\n",
        "    # Grid search for best model\n",
        "    grid_search = GridSearchCV(\n",
        "        estimator=RandomForestRegressor(random_state=42),\n",
        "        param_grid=param_grid,\n",
        "        scoring='r2',\n",
        "        cv=3,\n",
        "        n_jobs=-1,\n",
        "        verbose=0\n",
        "    )\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    best_model = grid_search.best_estimator_\n",
        "\n",
        "    # Predict and evaluate\n",
        "    y_pred = best_model.predict(X_test)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    # Store result\n",
        "    results.append({\n",
        "        'train_years': f\"{train_years[0]}-{train_years[-1]}\",\n",
        "        'test_year': test_year,\n",
        "        'R2': r2,\n",
        "        'Best_Params': grid_search.best_params_\n",
        "    })"
      ],
      "metadata": {
        "id": "_6lppZxRUvWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert results into a dataframe\n",
        "resultspt_df = pd.DataFrame(results)"
      ],
      "metadata": {
        "id": "mbG3URuzZHRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize dataframe\n",
        "init_notebook_mode(all_interactive=True)\n",
        "resultspt_df"
      ],
      "metadata": {
        "id": "AoJz4U8vZHRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate and display the mean and standard deviation for each evaluation metric\n",
        "mean_metrics = resultspt_df[[\"R2\"]].mean()\n",
        "std_metrics = resultspt_df[[\"R2\"]].std()\n",
        "\n",
        "print(\"Mean of Evaluation Metrics:\")\n",
        "print(mean_metrics)\n",
        "print(\"\\nStandard Deviation of Evaluation Metrics:\")\n",
        "print(std_metrics)"
      ],
      "metadata": {
        "id": "nOsJ5n5mUvc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** Parameter tuning did not improve the model performance"
      ],
      "metadata": {
        "id": "kaZUQ3xLZ26j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training RF Regression Model on 2001–2021 and Predict 2022\n",
        "\n",
        "In this section, for the SHAP analysis and mapping, we will train the RF regression model on data from 2001–2021 and predict the 2022 Normalized Asthma Mortality Rate in departments where it is present (CA_bin = 1 or NAMR > 0)."
      ],
      "metadata": {
        "id": "XSH3VX7XaiU_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define features and target\n",
        "features = ['PM25', 'NBA', 'PD', 'PDPM25', 'PM25_lag1',\n",
        "            'PM25_lag2', 'NBA_lag1', 'NBA_lag2', 'PD_lag1', 'PD_lag2',\n",
        "            'PDPM25_lag1', 'PDPM25_lag2', 'CA_lag1', 'CA_lag2']\n",
        "target = 'CA'"
      ],
      "metadata": {
        "id": "gZmdPCBuZvnF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare training and test sets\n",
        "train_df = df_ts[df_ts['YEAR'] <= 2021].dropna(subset=features + [target])\n",
        "test_df = df_ts[df_ts['YEAR'] == 2022].dropna(subset=features + [target])"
      ],
      "metadata": {
        "id": "D597ptEDhuPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter for positive cases (CA_bin == 1)\n",
        "train_pos = train_df[train_df['CA_bin'] == 1].copy()\n",
        "test_pos = test_df[test_df['CA_bin'] == 1].copy()"
      ],
      "metadata": {
        "id": "xo1D6UAuhuRg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define inputs\n",
        "X_train = train_pos[features]\n",
        "y_train = train_pos[target]"
      ],
      "metadata": {
        "id": "h5EOUUvBhuUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Keep IDDPTO and make prediction-ready copy\n",
        "X_test_full = test_pos[['IDDPTO'] + features + [target]].copy()\n",
        "X_test = X_test_full[features]\n",
        "y_test = test_pos[target].reset_index(drop=True)"
      ],
      "metadata": {
        "id": "2fodtm3EhuW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train regression model\n",
        "reg = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "reg.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "0K-50v7lhuZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict using feature columns\n",
        "y_pred = reg.predict(X_test)"
      ],
      "metadata": {
        "id": "1S3MTF3uh6Ev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Store prediction in column CA_pred\n",
        "X_test_full['CA_pred'] = y_pred"
      ],
      "metadata": {
        "id": "fFXsy3UBh6HN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate\n",
        "r2 = r2_score(y_test, y_pred)"
      ],
      "metadata": {
        "id": "L_ouKt8ZcPUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print evaluation\n",
        "print(\"Prediction Results for 2022:\")\n",
        "print(f\"R²: {r2:.3f}\")"
      ],
      "metadata": {
        "id": "HXj1T1aah6KE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metric Value\tInterpretation:\n",
        "\n",
        "The Random Forest regression model trained only on positive asthma mortality\n",
        "cases (CA_bin = 1) achieved a  R² of 0.636. The model explains about 63% of the variability in asthma mortality among departments where mortality actually occurred. This indicates good predictive capacity in estimating asthma mortality rates in 2022."
      ],
      "metadata": {
        "id": "OIPxOOvtkce6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# select IDDPTO, CA and CA_pred from X_test_full\n",
        "reg_pred_result = X_test_full[['IDDPTO', 'CA', 'CA_pred']].copy()"
      ],
      "metadata": {
        "id": "eGCQ6OEKjXB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize the reults\n",
        "init_notebook_mode(all_interactive=True)\n",
        "reg_pred_result"
      ],
      "metadata": {
        "id": "dt5jRqFYh6M1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# line chart actual vs predicted NAMR 2022\n",
        "plt.figure(figsize=(15, 6))\n",
        "plt.plot(reg_pred_result['IDDPTO'], reg_pred_result['CA'], color='blue', label='Actual NAMR')\n",
        "plt.plot(reg_pred_result['IDDPTO'], reg_pred_result['CA_pred'], color='red', label='Predicted NAMR')\n",
        "plt.xlabel('Departments')\n",
        "plt.ylabel('NAMR Values')\n",
        "plt.title('Actual vs Predicted NAMR 2022')\n",
        "plt.xticks([]) # Remove x-axis labels\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4qGO_l3xWVsW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SHAP (SHapley Additive Explanations)\n",
        "\n",
        "In this section we will interpret the contribution of each independent variable to the final predition of the RF regression model using the SHAP method"
      ],
      "metadata": {
        "id": "8WJTv7uN8Xgj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- SHAP for Regression ----\n",
        "# Use TreeExplainer (optimized for RandomForest)\n",
        "explainer = shap.TreeExplainer(reg)\n",
        "\n",
        "# get test set\n",
        "X = test_pos[features]\n",
        "\n",
        "# Function to compute SHAP values for a single row\n",
        "def compute_shap(row):\n",
        "    # For regression, shap_values returns a single 1D array\n",
        "    return explainer.shap_values(row)\n",
        "\n",
        "# Parallel computation (adjust n_jobs as needed)\n",
        "shap_values_list = Parallel(n_jobs=-1)(\n",
        "    delayed(compute_shap)(X.iloc[[i]]) for i in range(len(X))\n",
        ")\n",
        "\n",
        "# Stack the 1D SHAP value arrays vertically\n",
        "# No need to index [:, 1] as there's only one set of SHAP values for regression\n",
        "shap_values = np.vstack(shap_values_list)"
      ],
      "metadata": {
        "id": "yfQ6RYfoL6_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a SHAP summary plot to visualize the impact of features on the model's predictions\n",
        "shap.summary_plot(shap_values, X, feature_names=features,\n",
        "                  show= False)\n",
        "plt.title(\"(b) SHAP Summary Plot RF Regression\", fontsize=17)\n",
        "plt.xlabel(\"SHAP Values\", size=12)\n",
        "plt.ylabel(\"Features\", size=12)\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "zSPXIag7Kg3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🌍 Mapping actual vs predicted asthma mortality rate\n",
        "\n",
        "As explained above, since our dataset contains a high proportion of zero values, we will map the predicted NAMR for 2022 only in departments where the actual values are greater than zero. Departments with an actual NAMR value of zero will retain a predicted value of zero."
      ],
      "metadata": {
        "id": "ATMk6nJjNlKG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparing data for mapping"
      ],
      "metadata": {
        "id": "wsxmUbI9iEDT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from df_ts get filter 2022 and CA_bin equal to 0\n",
        "dpto_zero = df_ts[df_ts['YEAR'] == 2022]\n",
        "dpto_zero = dpto_zero[dpto_zero['CA_bin'] == 0]"
      ],
      "metadata": {
        "id": "xi0gg34miIcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# keep IDDPTO and CA_bin columns\n",
        "dpto_zero = dpto_zero[['IDDPTO', 'CA_bin']]"
      ],
      "metadata": {
        "id": "VxVGoBgxiIcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# rename CA_bin to CA and copy the column as CA_pred\n",
        "dpto_zero.rename(columns={'CA_bin': 'CA'}, inplace=True)\n",
        "dpto_zero['CA_pred'] = dpto_zero['CA'].copy()"
      ],
      "metadata": {
        "id": "BedfgYi9izSK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize dataframe\n",
        "init_notebook_mode(all_interactive=True)\n",
        "show(dpto_zero)"
      ],
      "metadata": {
        "id": "yizqYqwoiIcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get df info\n",
        "dpto_zero.info()"
      ],
      "metadata": {
        "id": "unDLUU-UjLfP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# concat reg_pred_result with dpto_zero\n",
        "df_concat = pd.concat([reg_pred_result, dpto_zero])"
      ],
      "metadata": {
        "id": "zQRQxD5wjhMy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get df info\n",
        "df_concat.info()"
      ],
      "metadata": {
        "id": "6z_JN0oujha6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize dataframe\n",
        "init_notebook_mode(all_interactive=True)\n",
        "show(df_concat)"
      ],
      "metadata": {
        "id": "Lf-Uk6CDkPkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset with data per department\n",
        "gdf = gpd.read_file(\"pdt/asthma_mortality/data/gpkg/tma_pm25_ba_pd_pdpm25_2001_2022.gpkg\")"
      ],
      "metadata": {
        "id": "udrByK-rkPnj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# keep IDDPTO and geometry of the gdf\n",
        "dpto_geom = gdf[['IDDPTO', 'geometry']]"
      ],
      "metadata": {
        "id": "U3Ezn0G9kRU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# merge df_concat and dpto_geom by IDDPTO preserve  df_concat data\n",
        "df_map = pd.merge(df_concat, dpto_geom, on='IDDPTO', how='left')"
      ],
      "metadata": {
        "id": "t832QFA7kRuD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# rename CA as CA_2022 and CA_pred as CA_2022_PRED\n",
        "df_map.rename(columns={'CA': 'CA_2022', 'CA_pred': 'CA_2022_PRED'}, inplace=True)"
      ],
      "metadata": {
        "id": "_qx1yeAamcKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# round CA_2022_PRED to two decimal places\n",
        "df_map['CA_2022_PRED'] = df_map['CA_2022_PRED'].round(2)"
      ],
      "metadata": {
        "id": "i-38Rg4snI5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert df_map to a gdf\n",
        "gdf_map = gpd.GeoDataFrame(df_map, geometry='geometry')"
      ],
      "metadata": {
        "id": "fkncrTETnral"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize geodataframe\n",
        "init_notebook_mode(all_interactive=True)\n",
        "show(gdf_map)"
      ],
      "metadata": {
        "id": "H5bM-ZZdlqtq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save df_map as gpkg file\n",
        "gdf_map.to_file(\"pdt/asthma_mortality/data/gpkg/results_RF.gpkg\", driver=\"GPKG\")"
      ],
      "metadata": {
        "id": "MemjyiM3VyWh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculate classification schema for mapping"
      ],
      "metadata": {
        "id": "clFu3h07LM8w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use [Pysal](https://pysal.org/)'s [mapclassify](https://pysal.org/mapclassify/index.html) library to determine the best classifier for the choropleth map.\n",
        "\n",
        "We will use the map classifier with the best ACDM (mean Absolute Deviation Around the class Median). In Pysal, ACDM refers to the mean absolute deviation around the class median. It is a measure of a classifier's fit to the data, specifically by evaluating the average distance between each data point and the median value of the assigned class."
      ],
      "metadata": {
        "id": "_vR6QhT5MSgU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# open results_RF.gpkg as a gdf\n",
        "df_cl = gpd.read_file(\"pdt/asthma_mortality/data/gpkg/results_RF.gpkg\")"
      ],
      "metadata": {
        "id": "dLVaBhNCn-ux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize the dataframe\n",
        "init_notebook_mode(all_interactive=True)\n",
        "show(df_cl)"
      ],
      "metadata": {
        "id": "WAtE2YAvX6__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get df basic info\n",
        "df_cl.info()"
      ],
      "metadata": {
        "id": "RfWbAYX4N9N8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the length of the dataframe 'df_cl'\n",
        "len(df_cl)"
      ],
      "metadata": {
        "id": "g0F-jKiQNxvV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select data to analize\n",
        "selected_data = df_cl.loc[:,[\"CA_2022\", \"CA_2022_PRED\"]]"
      ],
      "metadata": {
        "id": "8mOWh83wMtb9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classify the data into 4 quantile groups\n",
        "q4 = mapclassify.Quantiles(selected_data, k=4)\n",
        "q4"
      ],
      "metadata": {
        "id": "xaxBNjrgM8wd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Equal Interval Classification\n",
        "ei5 = mapclassify.EqualInterval(selected_data, k=5)\n",
        "ei5"
      ],
      "metadata": {
        "id": "1OSGjbdRNepG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classify the data into groups based on the head/tail breaks algorithm\n",
        "ht = mapclassify.HeadTailBreaks(selected_data)\n",
        "ht"
      ],
      "metadata": {
        "id": "LdJq40eONexG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MaximumBreaks classification method\n",
        "mb5 = mapclassify.MaximumBreaks(selected_data, k=5)\n",
        "mb5"
      ],
      "metadata": {
        "id": "_4svptQ_Nezr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the Standard Deviation and Mean classification method to the selected data.\n",
        "msd = mapclassify.StdMean(selected_data)\n",
        "msd"
      ],
      "metadata": {
        "id": "Nc0MZ-vdNe2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply Fisher-Jenks classification with 5 classes\n",
        "fj5 = mapclassify.FisherJenks(selected_data, k=5)\n",
        "fj5"
      ],
      "metadata": {
        "id": "MJ-oXygNObrk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ACDM(mean Absolute Deviation Around the class Median) visualization"
      ],
      "metadata": {
        "id": "umQ-3FECNNXz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bunch classifier objects\n",
        "class5 = q4, ei5, ht, mb5, msd, fj5\n",
        "# Collect ADCM for each classifier\n",
        "fits = np.array([c.adcm for c in class5])\n",
        "# Convert ADCM scores to a DataFrame\n",
        "adcms = pd.DataFrame(fits)\n",
        "# Add classifier names\n",
        "adcms[\"classifier\"] = [c.name for c in class5]\n",
        "# Add column names to the ADCM\n",
        "adcms.columns = [\"ADCM\", \"Classifier\"]\n",
        "ax = sns.barplot(\n",
        "    y=\"Classifier\", x=\"ADCM\", data=adcms, hue= adcms[\"Classifier\"],  legend=False\n",
        ")"
      ],
      "metadata": {
        "id": "2ksylA_zG8VN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create choropleth maps"
      ],
      "metadata": {
        "id": "MsI6Mtjcl85R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Two classifiers have the lowest ACDM: FisherJenks and HeadTailBreaks. We'll select FisherJenks as the classifier to create the choropleth maps."
      ],
      "metadata": {
        "id": "EXSn0psmO5kU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the bins to a list for further processing\n",
        "bins = fj5.bins.tolist()\n",
        "bins"
      ],
      "metadata": {
        "id": "Qa6eGH-RO4_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# insert 0 at 0 position\n",
        "bins.insert(0, 0.0)\n",
        "bins"
      ],
      "metadata": {
        "id": "e1qlFA1NRF6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a custom classification using UserDefined for actual values\n",
        "classi_actual = mapclassify.UserDefined(df_cl[\"CA_2022\"], bins)"
      ],
      "metadata": {
        "id": "G8I-KbzeRNQS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a custom classification using UserDefined for predicted values\n",
        "classi_pred = mapclassify.UserDefined(df_cl[\"CA_2022_PRED\"], bins)"
      ],
      "metadata": {
        "id": "0pRkvgeeiZE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(12, 8))\n",
        "fig.subplots_adjust(hspace=0, wspace=-0.9)\n",
        "plt.suptitle('Normalized Asthma Mortality Rate 2022', fontsize=14, y=1)\n",
        "\n",
        "# Plot classi_actual\n",
        "classi_actual.plot(\n",
        "    df_cl,\n",
        "    legend=False,  # We'll build it manually\n",
        "    axis_on=False,\n",
        "    border_color='black',\n",
        "    cmap=\"viridis_r\",\n",
        "    ax=axes[0]\n",
        ")\n",
        "\n",
        "# Plot classi_pred\n",
        "classi_pred.plot(\n",
        "    df_cl,\n",
        "    legend=False,  # We'll build it manually\n",
        "    axis_on=False,\n",
        "    border_color='black',\n",
        "    cmap=\"viridis_r\",\n",
        "    ax=axes[1]\n",
        ")\n",
        "\n",
        "\n",
        "# Custom bin labels and colors\n",
        "bin_labels = [\"0.00\", \"0.00-0.65\", \"0.65-2.16\", \"2.16-4.13\", \"4.13-7.49\", \"7.49-14.15\"]\n",
        "n_bins = len(bin_labels)\n",
        "# cmap = mpl.cm.get_cmap(\"viridis_r\", n_bins)\n",
        "cmap = mpl.colormaps.get_cmap(\"viridis_r\").resampled(n_bins)\n",
        "colors = [mpl.colors.to_hex(cmap(i)) for i in range(cmap.N)]\n",
        "\n",
        "# Create legend patches for bins\n",
        "bin_patches = [Patch(facecolor=color, edgecolor='black', label=label)\n",
        "               for color, label in zip(colors, bin_labels)]\n",
        "\n",
        "\n",
        "# Combine all patches\n",
        "all_patches = bin_patches\n",
        "\n",
        "# Display custom legend\n",
        "#axes[0].legend(handles=all_patches, loc='upper right', bbox_to_anchor=(1.1, 0.4), fontsize=8)\n",
        "axes[1].legend(handles=all_patches, loc='upper right', bbox_to_anchor=(0.9, 0.25), fontsize=10)\n",
        "\n",
        "# Set titles\n",
        "axes[0].set_title('Actual', fontsize=12)\n",
        "axes[1].set_title('Predicted', fontsize=12)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "HQR2id95gs6i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## References"
      ],
      "metadata": {
        "id": "NIYaZLxTt9UT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Utku, A., & Akcayol, M. A. (2024). Spread patterns of COVID-19 in European countries: hybrid deep learning model for prediction and transmission analysis. Neural Computing and Applications, 36(17), 10201-10217."
      ],
      "metadata": {
        "id": "_L6lbg14uUvp"
      }
    }
  ]
}