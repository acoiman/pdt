{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOq9DeTlaPGaRDoDZI9iH5f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/acoiman/pdt/blob/main/asthma_mortality/notebooks/Python/09_Asthma_Mortality_LULC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Land Use and Land Cover (LULC) Changes Data"
      ],
      "metadata": {
        "id": "AevSCWngc4iO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we will calculate Land Use and Land Cover (LULC) transition areas for consecutive years from 2001 to 2022. Specifically, we will focus on transitions involving:\n",
        "\n",
        "i) Agricultural and livestock areas (AGR)\n",
        "\n",
        "ii) Natural wooded vegetation (NWV)\n",
        "\n",
        "iii) Built-up (BU)\n",
        "\n",
        "To get  AGR and NWV transition areas, we will use the dataset provided by [MapBiomas Argentina](https://argentina.mapbiomas.org/mapas-de-la-coleccion/). We will also use [GLAD dataset ](https://glad.umd.edu/dataset) to extract BU transition areas.\n"
      ],
      "metadata": {
        "id": "bdisUllQKsOH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##üì¶ Import Required Libraries"
      ],
      "metadata": {
        "id": "fdlvQ-6njmkK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# geospatial data handling\n",
        "import ee\n",
        "import geemap\n",
        "import geopandas as gpd\n",
        "import folium\n",
        "\n",
        "# data frame libraries\n",
        "import pandas as pd\n",
        "\n",
        "# paralell execution\n",
        "from joblib import Parallel, delayed\n",
        "\n",
        "# other libraries\n",
        "import branca.colormap as cm\n",
        "import os\n",
        "from itables import init_notebook_mode"
      ],
      "metadata": {
        "id": "uWmsptlhDJpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üåç Connect to Google Earth Engine (GEE)"
      ],
      "metadata": {
        "id": "x3eqoWLMgevB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# trigger the authentication flow\n",
        "ee.Authenticate()"
      ],
      "metadata": {
        "id": "-qQgNBqJgc9i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the library.\n",
        "ee.Initialize(project='ee-pdt')\n",
        "print(ee.String('Hello from the Earth Engine servers!').getInfo())"
      ],
      "metadata": {
        "id": "gzkMyRxVg5Ld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the PROJ_LIB path\n",
        "os.environ['PROJ_LIB'] = \"/opt/conda/envs/gds/share/proj\""
      ],
      "metadata": {
        "id": "2QvKn9Zd0_Uv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# change to my computer home directory\n",
        "%cd work/"
      ],
      "metadata": {
        "id": "56N1yREtdWO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìü Calculating the Normalized Agricultural and Livestock Transition areas (NAGRT)"
      ],
      "metadata": {
        "id": "l1_MmRMQwUb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Computing NAGRT for the period 2000-2001"
      ],
      "metadata": {
        "id": "ToJVAemVMtq7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section, we will calculate the agricultural and livestock transition areas for the period 2000‚Äì2001. This includes all areas that changed from any land cover class to the agricultural and livestock category between 2000 and 2001 (gainings). The resulting dataset will be aggregated by department, normalized by each department‚Äôs surface area, and then multiplied by 1,000 km¬≤ to enhance interpretability."
      ],
      "metadata": {
        "id": "oorgnCM2Myk2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the transition image and select the 2000‚Äì2001 band\n",
        "transitions = ee.Image(\n",
        "    'projects/mapbiomas-public/assets/argentina/collection1/mapbiomas_argentina_collection1_transitions_v1'\n",
        ").select('transitions_2000_2001')\n",
        "\n",
        "# Define the target land cover classes (to transition into)\n",
        "target_classes = [18, 15, 9, 36, 21]  # Agriculture, Pasture, Forest Plant., Shrub Plant., Mosaic\n",
        "\n",
        "# Extract FROM and TO class\n",
        "from_class = transitions.divide(100).floor().toInt()\n",
        "to_class = transitions.mod(100).toInt()\n",
        "\n",
        "# Build condition: TO in target_classes\n",
        "to_is_target = to_class.eq(target_classes[0])\n",
        "for cls in target_classes[1:]:\n",
        "    to_is_target = to_is_target.Or(to_class.eq(cls))\n",
        "\n",
        "# Build condition: FROM NOT in target_classes\n",
        "from_not_target = from_class.neq(target_classes[0])\n",
        "for cls in target_classes[1:]:\n",
        "    from_not_target = from_not_target.And(from_class.neq(cls))\n",
        "\n",
        "# Final mask: to target class, but from another class\n",
        "expansion_mask = to_is_target.And(from_not_target)\n",
        "\n",
        "# Binary mask\n",
        "binary_mask = expansion_mask.selfMask()\n",
        "\n",
        "# Load departments\n",
        "departments = ee.FeatureCollection('projects/ee-pdt/assets/argentina/ar_dpto')\n",
        "\n",
        "# Pixel area in km¬≤\n",
        "pixel_area_km2 = ee.Image.pixelArea().divide(1e6)\n",
        "\n",
        "# Area of valid pixels\n",
        "expansion_area_img = binary_mask.multiply(pixel_area_km2)\n",
        "\n",
        "# Function to compute and normalize expansion area\n",
        "def compute_expansion(feature):\n",
        "    area_exp = expansion_area_img.reduceRegion(\n",
        "        reducer=ee.Reducer.sum(),\n",
        "        geometry=feature.geometry(),\n",
        "        scale=30,\n",
        "        maxPixels=1e13\n",
        "    ).get('transitions_2000_2001')\n",
        "\n",
        "    dept_area_km2 = feature.geometry().area().divide(1e6)\n",
        "    exp_km2 = ee.Number(area_exp)\n",
        "    exp_norm = exp_km2.divide(dept_area_km2)\n",
        "\n",
        "    exp_norm_1000 = exp_norm.multiply(1000).multiply(100).round().divide(100)\n",
        "\n",
        "    return feature.set({\n",
        "        'NAGRT_0001': exp_norm_1000,\n",
        "    })"
      ],
      "metadata": {
        "id": "0g9jTXvPwM6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply function to all departments\n",
        "result = departments.map(compute_expansion)"
      ],
      "metadata": {
        "id": "L7fdS9g5ufKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert FeatureCollection into a GeoDataFrame\n",
        "gdf_nagrt_0001 = geemap.ee_to_gdf(result)"
      ],
      "metadata": {
        "id": "1Ow1k3pIwe0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize the dataframe\n",
        "init_notebook_mode(all_interactive=True)\n",
        "gdf_nagrt_0001.head()"
      ],
      "metadata": {
        "id": "QoMQQPXQwmvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Mapping the NAGRT period 2000-2001\n",
        "\n",
        "In this section we will display vector data (GeoDataFrame with NAGRT 2000-2001) using folium.Choropleth"
      ],
      "metadata": {
        "id": "oVYfzC40QeiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create base map centered on Argentina\n",
        "m = folium.Map(location=[-38.4, -63.6], zoom_start=5, control_scale=True)\n",
        "\n",
        "# Add Choropleth layer from gdf\n",
        "choropleth = folium.Choropleth(\n",
        "    geo_data=gdf_nagrt_0001,\n",
        "    name='NAGRT 2000-2001',\n",
        "    data=gdf_nagrt_0001.drop(columns=['geometry']),\n",
        "    columns=['IDDPTO', 'NAGRT_0001'],\n",
        "    key_on='feature.properties.IDDPTO',\n",
        "    fill_color='YlOrRd',\n",
        "    fill_opacity=0.7,\n",
        "    line_opacity=0.3,\n",
        "    nan_fill_color='gray',\n",
        "    legend_name='Normalized Agricultural and Livestock Area transitions (NAGRT) period 2000-2021'\n",
        ")\n",
        "choropleth.add_to(m)\n",
        "\n",
        "# Now add an interactive GeoJson layer with popups\n",
        "geojson = folium.GeoJson(\n",
        "    gdf_nagrt_0001,\n",
        "    name='Interactive Layer',\n",
        "    style_function=lambda feature: {\n",
        "        'fillOpacity': 0,\n",
        "        'color': 'black',\n",
        "        'weight': 0.3,\n",
        "    },\n",
        "    tooltip=folium.GeoJsonTooltip(\n",
        "        fields=['IDDPTO', 'NAGRT_0001'],\n",
        "        aliases=['Dept ID:', 'Expansion (/1000 km¬≤):'],\n",
        "        localize=True,\n",
        "        sticky=True,\n",
        "        labels=True\n",
        "    )\n",
        ").add_to(m)\n",
        "\n",
        "# Display expansion raster (binary_mask) as red overlay ---\n",
        "vis_params = {\n",
        "    'min': 0,\n",
        "    'max': 1,\n",
        "    'palette': ['#ffffff', '#000000']  # white = no change, red = expansion\n",
        "}\n",
        "\n",
        "# Get map tiles from Earth Engine image\n",
        "map_id_dict = binary_mask.getMapId(vis_params)\n",
        "\n",
        "# Create Folium TileLayer\n",
        "tile = folium.raster_layers.TileLayer(\n",
        "    tiles=map_id_dict['tile_fetcher'].url_format,\n",
        "    attr='Earth Engine',\n",
        "    name='Mapbiomas transition Raster (Black)',\n",
        "    overlay=True,\n",
        "    control=True\n",
        ")\n",
        "\n",
        "# Add raster layer to folium map\n",
        "m.add_child(tile)\n",
        "\n",
        "# Add layer control\n",
        "folium.LayerControl().add_to(m)"
      ],
      "metadata": {
        "id": "7Oty7Ev7QeiT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# display the map\n",
        "m"
      ],
      "metadata": {
        "id": "aQjQDivPQeiT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####  Checking results of NAGRT period 2000-2001"
      ],
      "metadata": {
        "id": "zMseBHQxXfCZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section, we will extract the transition image where binary_mask is equal to 1 for the department with the highest NAGRT (IDDPTO = \"06651\"). We will then verify whether pixel values correspond to transitions that end in, but do not start from any agricultural and livestock area class code (15, 18, 9, 36, 21)"
      ],
      "metadata": {
        "id": "lCWln2jBXnbv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the feature with IDDPTO '06651'\n",
        "dept_06651 = departments.filter(ee.Filter.eq('IDDPTO', '06651')).first()\n",
        "\n",
        "# Clip the transitions image by the geometry of the selected department\n",
        "transitions_clipped = transitions.clip(dept_06651.geometry())\n",
        "binary_mask_clipped = binary_mask.clip(dept_06651.geometry())\n",
        "\n",
        "# Get pixel values of the transitions image where binary_mask_clipped == 1\n",
        "# Define the reducer to get a list of pixel values\n",
        "reducer = ee.Reducer.toList()\n",
        "\n",
        "# Reduce the clipped transitions image using the clipped binary mask\n",
        "# We multiply the transitions image by the binary mask so only pixels where\n",
        "# the mask is 1 are included in the reduction.\n",
        "pixel_values = transitions_clipped.updateMask(binary_mask_clipped).reduceRegion(\n",
        "    reducer=reducer,\n",
        "    geometry=dept_06651.geometry(),\n",
        "    scale=30,  # Use the same scale as before\n",
        "    maxPixels=1e13\n",
        ")\n",
        "\n",
        "# Extract the list of pixel values\n",
        "list_of_values = pixel_values.get('transitions_2000_2001').getInfo()"
      ],
      "metadata": {
        "id": "v7k4hHyQTmr0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get unique values of list_of_values\n",
        "# the result meets our checking condition\n",
        "unique_values = list(set(list_of_values))\n",
        "unique_values"
      ],
      "metadata": {
        "id": "TY8ZBA0GUPTu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Computing NAGRT from 2000 to 2022\n",
        "\n",
        "In this section, we will calculate the agricultural and livestock transition areas for consecutive years. This includes all areas that changed from any land cover class to the agricultural and livestock category during each year-to-year transition between 2000 and 2022 (gainings). The resulting dataset will be aggregated by department, normalized by each department‚Äôs surface area, and multiplied by 1,000 km¬≤ to enhance interpretability."
      ],
      "metadata": {
        "id": "HRkG7jU9KK3Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the FeatureCollection of departments in Argentina\n",
        "departments = ee.FeatureCollection('projects/ee-pdt/assets/argentina/ar_dpto')\n",
        "\n",
        "# Create an image representing the area of each pixel in square kilometers\n",
        "pixel_area_km2 = ee.Image.pixelArea().divide(1e6)\n",
        "\n",
        "# Define the target classes for analysis or processing\n",
        "target_classes = [18, 15, 9, 36, 21]"
      ],
      "metadata": {
        "id": "QHAmq3ShHm6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_transition_year(y1):\n",
        "    \"\"\"\n",
        "    Compute the Normalized Agricultural and Livestock Transition Rate (NAGRT)\n",
        "    for a specific year-to-year transition and return it as a GeoDataFrame.\n",
        "\n",
        "    Parameters:\n",
        "        y1 (int): The start year of the transition (e.g., 2001 for 2001‚Äì2002)\n",
        "\n",
        "    Returns:\n",
        "        GeoDataFrame with columns: ['IDDPTO', 'NAGRT_y1_y2']\n",
        "\n",
        "    Note: The name of the output column should be NAGRT_y1_y2,\n",
        "          but for the sake of posterior analysis we choose NAGRT_y2\n",
        "    \"\"\"\n",
        "    try:\n",
        "\n",
        "        # Define transition band and output column name\n",
        "        y2 = y1 + 1\n",
        "        band_name = f\"transitions_{y1}_{y2}\"\n",
        "        # col_name = f\"NAGRT_{y1}_{y2}\"\n",
        "        col_name = f\"NAGRT_{y2}\"\n",
        "\n",
        "        # Load the transition image band for the given year\n",
        "        transitions = ee.Image('projects/mapbiomas-public/assets/argentina/collection1/mapbiomas_argentina_collection1_transitions_v1') \\\n",
        "            .select(band_name)\n",
        "\n",
        "        # Extract FROM and TO classes from the transition code\n",
        "        from_class = transitions.divide(100).floor().toInt()\n",
        "        to_class = transitions.mod(100).toInt()\n",
        "\n",
        "        # Build mask for transitions TO target classes\n",
        "        to_is_target = to_class.eq(target_classes[0])\n",
        "        for cls in target_classes[1:]:\n",
        "            to_is_target = to_is_target.Or(to_class.eq(cls))\n",
        "\n",
        "        # Exclude transitions FROM the same target classes (i.e., exclude stable)\n",
        "        from_not_target = from_class.neq(target_classes[0])\n",
        "        for cls in target_classes[1:]:\n",
        "            from_not_target = from_not_target.And(from_class.neq(cls))\n",
        "\n",
        "        # Final mask: to a target class, but not from a target class\n",
        "        expansion_mask = to_is_target.And(from_not_target)\n",
        "\n",
        "        # Binary mask image where valid transitions are 1\n",
        "        binary_mask = expansion_mask.selfMask()\n",
        "\n",
        "        # Multiply by pixel area in km¬≤ to get expansion area per pixel\n",
        "        expansion_area_img = binary_mask.multiply(pixel_area_km2)\n",
        "\n",
        "        # Per-department computation function\n",
        "        def compute_metrics(feature):\n",
        "            area_exp = expansion_area_img.reduceRegion(\n",
        "                reducer=ee.Reducer.sum(),\n",
        "                geometry=feature.geometry(),\n",
        "                scale=30,\n",
        "                maxPixels=1e13\n",
        "            ).get(band_name)\n",
        "\n",
        "            dept_area_km2 = feature.geometry().area().divide(1e6)\n",
        "            exp_km2 = ee.Number(area_exp)\n",
        "            exp_norm = exp_km2.divide(dept_area_km2)\n",
        "            exp_norm_1000 = exp_norm.multiply(1000).multiply(100).round().divide(100)\n",
        "\n",
        "            return feature.set({col_name: exp_norm_1000})\n",
        "\n",
        "        # Apply computation to all departments and select relevant fields\n",
        "        result_fc = departments.map(compute_metrics).select(['IDDPTO', col_name])\n",
        "\n",
        "        # Convert to GeoDataFrame\n",
        "        gdf = geemap.ee_to_gdf(result_fc)\n",
        "\n",
        "        # Return DataFrame with only ID and calculated column\n",
        "        return gdf[['IDDPTO', col_name]]\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"[ERROR] Processing {y1}-{y2}: {e}\")\n",
        "        return pd.DataFrame(columns=['IDDPTO', f\"NAGRT_{y1}_{y2}\"])"
      ],
      "metadata": {
        "id": "EYmHghMajAi-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# list to store all dataframe derived from the for loop\n",
        "all_dfs_agr = []"
      ],
      "metadata": {
        "id": "ObiMyEOdbW1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop from 2000 to 2021 (ending at transitions_2021_2022)\n",
        "for year in range(2000, 2022):\n",
        "    print(f\"Processing transition {year}-{year+1}\")\n",
        "    df = process_transition_year(year)\n",
        "    all_dfs_agr.append(df)"
      ],
      "metadata": {
        "id": "qrvYwdh4bW1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge all dataframes on 'IDDPTO'\n",
        "df_final_agr = all_dfs_agr[0]\n",
        "for df in all_dfs_agr[1:]:\n",
        "    df_final_agr = df_final_agr.merge(df, on='IDDPTO', how='outer')"
      ],
      "metadata": {
        "id": "vFsDRboZbW1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "init_notebook_mode(all_interactive=True)\n",
        "df_final_agr.head()"
      ],
      "metadata": {
        "id": "nSiQPv0LbW1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_agr.info()"
      ],
      "metadata": {
        "id": "pFtruGonbW1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test if df_final_agr['NAGRT_2001_2002'] is the same as gdf_nagrt_0001['NAGRT_0001']\n",
        "print((df_final_agr['NAGRT_2001'] == gdf_nagrt_0001['NAGRT_0001']).all())"
      ],
      "metadata": {
        "id": "xNJszV91bWNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Merging NAGRT (2001-2022) with other features"
      ],
      "metadata": {
        "id": "UIHYdwnPTiSa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# copy  df_final_agr\n",
        "df = df_final_agr.copy()"
      ],
      "metadata": {
        "id": "H4Qr4GQ-Th0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load geopackage with PM2.5, Burned areas an other features\n",
        "gdf = gpd.read_file(\"pdt/asthma_mortality/data/gpkg/tma_pm25_ba_pd_pdpm25_2001_2022.gpkg\")"
      ],
      "metadata": {
        "id": "FVqYcll7TauJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform a left merge, preserving all rows from gdf\n",
        "gdf_nagrt_0122 = gdf.merge(df, on='IDDPTO', how='left')"
      ],
      "metadata": {
        "id": "xCClHBziPpiM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize gdf_nagrt_0122\n",
        "init_notebook_mode(all_interactive=True)\n",
        "gdf_nagrt_0122.head()"
      ],
      "metadata": {
        "id": "LAgrYc3fVUoY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gdf_nagrt_0122.shape"
      ],
      "metadata": {
        "id": "g-arPTqDWUha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save dataset with NAGRT (2001-2022) as other features as a gpkg file\n",
        "gdf_nagrt_0122.to_file(\"pdt/asthma_mortality/data/gpkg/tma_pm25_ba_pd_pdpm25_agrt_2001_2022.gpkg\", driver=\"GPKG\")"
      ],
      "metadata": {
        "id": "M9qk6hiJV7-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üì±Calculating the Normalized Natural Wooded Vegetation Transitions areas (NNWVT)"
      ],
      "metadata": {
        "id": "wSnYfVhC6AU0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Computing the NNWVT for the period 2000-2001\n",
        "\n",
        "In this section, we will calculate the NNWVT areas for the period 2000‚Äì2001. This includes all areas that changed from natural wooded vegetation class to  any other land cover category between 2000 and 2001 (losses). The resulting dataset will be aggregated by department, normalized by each department‚Äôs surface area, and then multiplied by 1,000 km¬≤ to enhance interpretability."
      ],
      "metadata": {
        "id": "O0BSjVvXHYsu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the transition image and select the 2000‚Äì2001 band\n",
        "transitions = ee.Image(\n",
        "    'projects/mapbiomas-public/assets/argentina/collection1/mapbiomas_argentina_collection1_transitions_v1'\n",
        ").select('transitions_2000_2001')\n",
        "\n",
        "# Define the Natural Wooded Vegetation classes\n",
        "source_classes = [3, 4, 45, 6]\n",
        "\n",
        "# Extract from and to classes\n",
        "from_class = transitions.divide(100).floor().toInt()\n",
        "to_class = transitions.mod(100).toInt()\n",
        "\n",
        "# Condition: from_class in source_classes\n",
        "from_source = from_class.eq(source_classes[0])\n",
        "for cls in source_classes[1:]:\n",
        "    from_source = from_source.Or(from_class.eq(cls))\n",
        "\n",
        "# Condition: to_class not in source_classes\n",
        "to_not_source = to_class.neq(source_classes[0])\n",
        "for cls in source_classes[1:]:\n",
        "    to_not_source = to_not_source.And(to_class.neq(cls))\n",
        "\n",
        "# Final mask: pixels that were natural vegetation but changed to something else (losses)\n",
        "loss_mask = from_source.And(to_not_source)\n",
        "\n",
        "# Binary mask image\n",
        "binary_mask = loss_mask.selfMask()\n",
        "\n",
        "# Load departments\n",
        "departments = ee.FeatureCollection('projects/ee-pdt/assets/argentina/ar_dpto')\n",
        "\n",
        "# Pixel area in km¬≤\n",
        "pixel_area_km2 = ee.Image.pixelArea().divide(1e6)\n",
        "\n",
        "# Multiply mask by pixel area\n",
        "loss_area_img = binary_mask.multiply(pixel_area_km2)\n",
        "\n",
        "# Function to compute total loss area and normalize\n",
        "def compute_loss(feature):\n",
        "    area_loss = loss_area_img.reduceRegion(\n",
        "        reducer=ee.Reducer.sum(),\n",
        "        geometry=feature.geometry(),\n",
        "        scale=30,\n",
        "        maxPixels=1e13\n",
        "    ).get('transitions_2000_2001')\n",
        "\n",
        "    dept_area_km2 = feature.geometry().area().divide(1e6)\n",
        "    loss_km2 = ee.Number(area_loss)\n",
        "    loss_norm = loss_km2.divide(dept_area_km2)\n",
        "\n",
        "    # Normalize by 1000 km¬≤ and round to 2 decimals\n",
        "    loss_norm_1000 = loss_norm.multiply(1000).multiply(100).round().divide(100)\n",
        "\n",
        "    return feature.set({'NNWVT_0001': loss_norm_1000})"
      ],
      "metadata": {
        "id": "y0l0gHx5oGw6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply to departments\n",
        "result = departments.map(compute_loss)"
      ],
      "metadata": {
        "id": "Iov_IQeVXBXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert FeatureCollection into a GeoDataFrame\n",
        "gdf_nnwvt_0001 = geemap.ee_to_gdf(result)"
      ],
      "metadata": {
        "id": "nI627pW2z8oK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first few rows of the DataFrame\n",
        "init_notebook_mode(all_interactive=True)\n",
        "gdf_nnwvt_0001"
      ],
      "metadata": {
        "id": "RODMl46vz9Xf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Mapping the NNWVT period 2000-2001\n",
        "\n",
        "In this section we will display vector data (GeoDataFrame with NWVT_0001) using folium.Choropleth"
      ],
      "metadata": {
        "id": "s4b2UxD7iKx7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create base map centered on Argentina\n",
        "m = folium.Map(location=[-38.4, -63.6], zoom_start=5, control_scale=True)\n",
        "\n",
        "# Add Choropleth layer from gdf\n",
        "choropleth = folium.Choropleth(\n",
        "    geo_data=gdf_nnwvt_0001,\n",
        "    name='NNWVT 2000-2001',\n",
        "    data=gdf_nnwvt_0001.drop(columns=['geometry']),\n",
        "    columns=['IDDPTO', 'NNWVT_0001'],\n",
        "    key_on='feature.properties.IDDPTO',\n",
        "    fill_color='YlOrRd',\n",
        "    fill_opacity=0.7,\n",
        "    line_opacity=0.3,\n",
        "    nan_fill_color='gray',\n",
        "    legend_name='Normalized Non-wooden Vegetation transition (NNWVT) period 2000-2001'\n",
        ")\n",
        "choropleth.add_to(m)\n",
        "\n",
        "# Now add an interactive GeoJson layer with popups\n",
        "geojson = folium.GeoJson(\n",
        "    gdf_nnwvt_0001,\n",
        "    name='Interactive Layer',\n",
        "    style_function=lambda feature: {\n",
        "        'fillOpacity': 0,\n",
        "        'color': 'black',\n",
        "        'weight': 0.3,\n",
        "    },\n",
        "    tooltip=folium.GeoJsonTooltip(\n",
        "        fields=['IDDPTO', 'NNWVT_0001'],\n",
        "        aliases=['Dept ID:', 'Losses (/1000 km¬≤):'],\n",
        "        localize=True,\n",
        "        sticky=True,\n",
        "        labels=True\n",
        "    )\n",
        ").add_to(m)\n",
        "\n",
        "# Define visualization parameters for binary_mask\n",
        "vis_params = {\n",
        "    'min': 0,\n",
        "    'max': 1,\n",
        "    'palette': ['#ffffff', '#000000']  # white = no change, red = loss\n",
        "}\n",
        "\n",
        "# Get map tiles from Earth Engine image\n",
        "map_id_dict = binary_mask.getMapId(vis_params)\n",
        "\n",
        "# Create Folium TileLayer\n",
        "tile = folium.raster_layers.TileLayer(\n",
        "    tiles=map_id_dict['tile_fetcher'].url_format,\n",
        "    attr='Earth Engine',\n",
        "    name='Mapbiomas transition Raster (Black)',\n",
        "    overlay=True,\n",
        "    control=True\n",
        ")\n",
        "\n",
        "# Add raster layer to folium map\n",
        "m.add_child(tile)\n",
        "\n",
        "# Add layer control\n",
        "folium.LayerControl().add_to(m)"
      ],
      "metadata": {
        "id": "8NhZNW-hBam_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# display the map\n",
        "m"
      ],
      "metadata": {
        "id": "3OG_9zIRuAax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####  Checking results of NNWVT period 2000-2001"
      ],
      "metadata": {
        "id": "2DBqnL3PzR9O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section, we will extract the transition image where binary_mask is equal to 1 for the department with the highest NNWVT (IDDPTO = \"62007\"). We will then verify whether pixel values correspond to transitions that start  in, but do not end from any Natural Wooden Vegetation class code (3, 4, 45, 6)"
      ],
      "metadata": {
        "id": "GiM17-pRzR9O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the feature with IDDPTO '62007'\n",
        "dept_62007 = departments.filter(ee.Filter.eq('IDDPTO', '62007')).first()\n",
        "\n",
        "# Clip the transitions image by the geometry of the selected department\n",
        "transitions_clipped = transitions.clip(dept_62007.geometry())\n",
        "binary_mask_clipped = binary_mask.clip(dept_62007.geometry())\n",
        "\n",
        "# Get pixel values of the transitions image where binary_mask_clipped == 1\n",
        "# Define the reducer to get a list of pixel values\n",
        "reducer = ee.Reducer.toList()\n",
        "\n",
        "# Reduce the clipped transitions image using the clipped binary mask\n",
        "# We multiply the transitions image by the binary mask so only pixels where\n",
        "# the mask is 1 are included in the reduction.\n",
        "pixel_values = transitions_clipped.updateMask(binary_mask_clipped).reduceRegion(\n",
        "    reducer=reducer,\n",
        "    geometry=dept_62007.geometry(),\n",
        "    scale=30,  # Use the same scale as before\n",
        "    maxPixels=1e13\n",
        ")\n",
        "\n",
        "# Extract the list of pixel values\n",
        "list_of_values = pixel_values.get('transitions_2000_2001').getInfo()"
      ],
      "metadata": {
        "id": "rdj5bnbDzR9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get unique values of list_of_values\n",
        "unique_values = list(set(list_of_values))"
      ],
      "metadata": {
        "id": "3y3_-1IlzR9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print values divided by 100 (from class before period the dot, to clas after the dot)\n",
        "# the result meets our checking condition\n",
        "for value in unique_values:\n",
        "    print(value/100)"
      ],
      "metadata": {
        "id": "3rpvhvlX4LbE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Computing NNWVT from 2001 to 2022\n",
        "\n",
        "\n",
        "In this section, we will calculate the NNWVT areas for the period 2001‚Äì2022. This includes all areas that changed from natural wooded vegetation class to  any other land cover category between 2001 and 2002 (losses). The resulting dataset will be aggregated by department, normalized by each department‚Äôs surface area, and then multiplied by 1,000 km¬≤ to enhance interpretability."
      ],
      "metadata": {
        "id": "-DEQz6Nk6ROi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Department boundaries\n",
        "departments = ee.FeatureCollection('projects/ee-pdt/assets/argentina/ar_dpto')\n",
        "\n",
        "# Natural Wooded Vegetation source classes\n",
        "source_classes = [3, 4, 45, 6]\n",
        "\n",
        "# Pixel area in km¬≤\n",
        "pixel_area_km2 = ee.Image.pixelArea().divide(1e6)"
      ],
      "metadata": {
        "id": "8XA8OL9468ho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_transition(y1):\n",
        "\n",
        "  \"\"\"\n",
        "  Compute the Normalized Non-wooden Vegetation transition (NNWVT)\n",
        "  for a specific year-to-year transition and return it as a GeoDataFrame.\n",
        "\n",
        "  Parameters:\n",
        "      y1 (int): The start year of the transition (e.g., 2001 for 2001‚Äì2002)\n",
        "\n",
        "  Returns:\n",
        "      GeoDataFrame with columns: ['IDDPTO', 'NNWVT_y1_y2']\n",
        "\n",
        "      Note: The name of the output column should be NNWVT_y1_y2,\n",
        "            but for the sake of posterior analysis we choose NNWVT_y2 (y2 is the end year)\n",
        "  \"\"\"\n",
        "\n",
        "  try:\n",
        "\n",
        "    # Define transition band and output column name\n",
        "    y2 = y1 + 1\n",
        "    band_name = f'transitions_{y1}_{y2}'\n",
        "    # col_name = f'NNWVT_{y1}_{y2}'\n",
        "    col_name = f'NNWVT_{y2}'\n",
        "\n",
        "    # Load transition band\n",
        "    transitions = ee.Image('projects/mapbiomas-public/assets/argentina/collection1/mapbiomas_argentina_collection1_transitions_v1') \\\n",
        "        .select(band_name)\n",
        "\n",
        "    # Extract from/to class codes\n",
        "    from_class = transitions.divide(100).floor().toInt()\n",
        "    to_class = transitions.mod(100).toInt()\n",
        "\n",
        "    # from_class in source_classes\n",
        "    from_source = from_class.eq(source_classes[0])\n",
        "    for cls in source_classes[1:]:\n",
        "        from_source = from_source.Or(from_class.eq(cls))\n",
        "\n",
        "    # to_class not in source_classes\n",
        "    to_not_source = to_class.neq(source_classes[0])\n",
        "    for cls in source_classes[1:]:\n",
        "        to_not_source = to_not_source.And(to_class.neq(cls))\n",
        "\n",
        "    # Final mask: loss of native vegetation\n",
        "    loss_mask = from_source.And(to_not_source)\n",
        "\n",
        "    # Binary mask\n",
        "    binary_mask = loss_mask.selfMask()\n",
        "\n",
        "    # Compute area of loss\n",
        "    loss_area_img = binary_mask.multiply(pixel_area_km2)\n",
        "\n",
        "    # Compute loss by department\n",
        "    def compute_loss(feature):\n",
        "        area_loss = loss_area_img.reduceRegion(\n",
        "            reducer=ee.Reducer.sum(),\n",
        "            geometry=feature.geometry(),\n",
        "            scale=30,\n",
        "            maxPixels=1e13\n",
        "        ).get(band_name)\n",
        "\n",
        "        dept_area_km2 = feature.geometry().area().divide(1e6)\n",
        "        loss_km2 = ee.Number(area_loss)\n",
        "        loss_norm = loss_km2.divide(dept_area_km2)\n",
        "        loss_norm_1000 = loss_norm.multiply(1000).multiply(100).round().divide(100)\n",
        "\n",
        "        return feature.set({col_name: loss_norm_1000})\n",
        "\n",
        "    # Apply computation\n",
        "    result = departments.map(compute_loss)\n",
        "\n",
        "    # Convert to GeoDataFrame\n",
        "    gdf = geemap.ee_to_gdf(result).drop(columns='geometry')\n",
        "\n",
        "    # Return DataFrame with only ID and calculated column\n",
        "    return gdf[['IDDPTO', col_name]]\n",
        "\n",
        "  except Exception as e:\n",
        "    print(f\"[ERROR] Processing {y1}-{y2}: {e}\")\n",
        "    return pd.DataFrame(columns=['IDDPTO', f\"NNWVT_{y1}_{y2}\"])"
      ],
      "metadata": {
        "id": "EHT2QlP_6ncX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# list to store all dataframe derived from the for loop\n",
        "all_dfs = []"
      ],
      "metadata": {
        "id": "dsPUod4_JXDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop from 2000 to 2021 (ending at transitions_2021_2022)\n",
        "for year in range(2000, 2022):\n",
        "    print(f\"Processing transition {year}-{year+1}\")\n",
        "    df = process_transition(year)\n",
        "    all_dfs.append(df)"
      ],
      "metadata": {
        "id": "KAejrnGBJXG7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge all dataframes on 'IDDPTO'\n",
        "df_final = all_dfs[0]\n",
        "for df in all_dfs[1:]:\n",
        "    df_final = df_final.merge(df, on='IDDPTO', how='outer')"
      ],
      "metadata": {
        "id": "v3BLipSUJXJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize the data.frame\n",
        "init_notebook_mode(all_interactive=True)\n",
        "df_final.head()"
      ],
      "metadata": {
        "id": "DR_iUHZkNkH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get info of the data.frame\n",
        "df_final.info()"
      ],
      "metadata": {
        "id": "GV29zvEaNkK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test if df_final['NNWVT_2001'] is the same as gdf_nagrt_0001['NAGRT_00001']\n",
        "print((df_final['NNWVT_2001'] == gdf_nnwvt_0001['NNWVT_0001']).all())"
      ],
      "metadata": {
        "id": "g07LjwnU-Njv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Merge NNWVT (2001-2022) with other features"
      ],
      "metadata": {
        "id": "no-yHRvUOa6d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load geopackage with PM2.5, Burned areas an other datasets\n",
        "gdf = gpd.read_file(\"pdt/asthma_mortality/data/gpkg/tma_pm25_ba_pd_pdpm25_agrt_2001_2022.gpkg\")"
      ],
      "metadata": {
        "id": "4CJC84Y1Oa6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform a left merge, preserving all rows from gdf\n",
        "gdf_nnwvt_0122 = gdf.merge(df_final, on='IDDPTO', how='left')"
      ],
      "metadata": {
        "id": "BTxp_1g_Oa6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize gdf_nagrt_0122\n",
        "init_notebook_mode(all_interactive=True)\n",
        "gdf_nnwvt_0122.head()"
      ],
      "metadata": {
        "id": "8pTB_UP5Oa6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gdf_nnwvt_0122.shape"
      ],
      "metadata": {
        "id": "M3sOda-JOa6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save dataset with NAGRT (2001-2022) as other features as a gpkg file\n",
        "gdf_nnwvt_0122.to_file(\"pdt/asthma_mortality/data/gpkg/tma_pm25_ba_pd_pdpm25_agrt_nwvt_2001_2022.gpkg\", driver=\"GPKG\")"
      ],
      "metadata": {
        "id": "8_I6INkQOa6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üèòÔ∏è Calculating the Normalized Built-up Transitions areas (NBUT)\n",
        "\n",
        "The GLAD dataset for Built-up classes is only available every 5 years from 2000 to 2020 at https://code.earthengine.google.com/f9f56ceb38ed9e911767c4014eeb536d. We will compute the NBUT areas between the available years using dummies transition values as explain bellow and the [Global Land Use and Land Cover 2000-2020 legend](https://storage.googleapis.com/earthenginepartners-hansen/GLCLU2000-2020/v2/legend.xlsx)."
      ],
      "metadata": {
        "id": "rhiteuM3ZFz_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example on how to get a dummy transition value\n",
        "# From is the start year\n",
        "# To is the End year\n",
        "From = 66\n",
        "To = 250\n",
        "value = (From * 256) + To\n",
        "print(\"Dummy transition value is:\",  value)"
      ],
      "metadata": {
        "id": "JPcRHkGw1klX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get From and To value from dummie trasition value\n",
        "From_2 = value//256\n",
        "To_2 = value%256\n",
        "print(\"Value:\", value, \"From:\", From_2, \"To:\", To_2)"
      ],
      "metadata": {
        "id": "YSRXqBWM2dPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Computing the NBUT for the period 2000-2005\n",
        "\n",
        "We will calculate the NBUT areas for the period 2000‚Äì2005. This includes all areas that changed from any class to built-up category between 2000 and 2005 (gainings). The resulting dataset will be aggregated by department, normalized by each department‚Äôs surface area, and then multiplied by 1,000 km¬≤ to enhance interpretability.\n",
        "\n",
        "$$NBUT = \\left(\\text{Built-up transition¬†area}\\right/\\text{Dep.area})*1000$$"
      ],
      "metadata": {
        "id": "tk6eYp3NBBT4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load argentina boundaries\n",
        "ar_poly = ee.FeatureCollection('projects/ee-pdt/assets/argentina/ar_poly')"
      ],
      "metadata": {
        "id": "lvqWgdVgj6ok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load glad OceanMask\n",
        "landmask = ee.Image(\"projects/glad/OceanMask\").lte(1)"
      ],
      "metadata": {
        "id": "OuMOvqKnm4ek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load glad lulc 2000\n",
        "m00 = ee.Image('projects/glad/GLCLU2020/v2/LCLUC_2000').updateMask(landmask)\n",
        "\n",
        "# clip m00 to ar_poly\n",
        "m00_ar = m00.clip(ar_poly)\n",
        "\n",
        "# load glad lulc 2005\n",
        "m05 = ee.Image('projects/glad/GLCLU2020/v2/LCLUC_2005').updateMask(landmask)\n",
        "\n",
        "# clip m00 to ar_poly\n",
        "m05_ar = m05.clip(ar_poly)\n",
        "\n",
        "# create a transition image where each pixel value of m00 is multiplied by 256 and the sum the pixel value of m05\n",
        "transition_0005_ar = m00_ar.multiply(256).add(m05_ar)"
      ],
      "metadata": {
        "id": "MxwyVv22nDBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define target built-up classes\n",
        "target_classes = [250]\n",
        "\n",
        "# Extract from and to classes\n",
        "from_class = transition_0005_ar.divide(256).floor().toInt()\n",
        "to_class = transition_0005_ar.mod(256).toInt()\n",
        "\n",
        "# Condition: to_class is in target_classes\n",
        "to_target = to_class.eq(target_classes[0])\n",
        "for cls in target_classes[1:]:\n",
        "    to_target = to_target.Or(to_class.eq(cls))\n",
        "\n",
        "# Condition: from_class is NOT in target_classes\n",
        "from_not_target = from_class.neq(target_classes[0])\n",
        "for cls in target_classes[1:]:\n",
        "    from_not_target = from_not_target.And(from_class.neq(cls))\n",
        "\n",
        "# Final mask: pixels that transitioned to built-up from a different class\n",
        "builtup_mask = to_target.And(from_not_target)\n",
        "\n",
        "# Binary mask image\n",
        "binary_mask = builtup_mask.selfMask()\n",
        "\n",
        "# Pixel area in km¬≤\n",
        "pixel_area_km2 = ee.Image.pixelArea().divide(1e6)\n",
        "\n",
        "# Multiply to get built-up area in km¬≤ per pixel\n",
        "builtup_area_img = binary_mask.multiply(pixel_area_km2)\n",
        "\n",
        "# Load departments\n",
        "departments = ee.FeatureCollection('projects/ee-pdt/assets/argentina/ar_dpto')\n",
        "\n",
        "# Function to compute expansion per department\n",
        "def compute_builtup(feature):\n",
        "    area_built = builtup_area_img.reduceRegion(\n",
        "        reducer=ee.Reducer.sum(),\n",
        "        geometry=feature.geometry(),\n",
        "        scale=30,\n",
        "        maxPixels=1e13\n",
        "    ).get('b1')  # band name\n",
        "\n",
        "    dept_area_km2 = feature.geometry().area().divide(1e6)\n",
        "    built_km2 = ee.Number(area_built)\n",
        "    built_norm = built_km2.divide(dept_area_km2)\n",
        "\n",
        "    # Normalize per 1000 km¬≤ and round to 2 decimals\n",
        "    built_norm_1000 = built_norm.multiply(1000).multiply(100).round().divide(100)\n",
        "\n",
        "     # The name of the feature should be NBUT_2000_2005,\n",
        "     # but for the sake of posterior analysis we choose NBUT_2005\n",
        "    return feature.set({'NBUT_2005': built_norm_1000})\n",
        "\n",
        "# Map over all departments\n",
        "result = departments.map(compute_builtup)\n"
      ],
      "metadata": {
        "id": "PjQ8wgfk1Ef9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to GeoDataFrame and extract desired columns\n",
        "gdf_but_0005 = geemap.ee_to_gdf(result)\n",
        "df_but_0005 = gdf_but_0005[['IDDPTO', 'NBUT_2005']]"
      ],
      "metadata": {
        "id": "7zNFGuBUVi_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize dataframe\n",
        "init_notebook_mode(all_interactive=True)\n",
        "df_but_0005"
      ],
      "metadata": {
        "id": "hdOIriNhVjCP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Mapping the NBUT period 2000-2005\n",
        "\n",
        "In this section we will display vector data (GeoDataFrame with NBUT 2000-2005) using folium.Choropleth"
      ],
      "metadata": {
        "id": "IKLA6qeppQJG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create base map centered on Argentina\n",
        "m = folium.Map(location=[-38.4, -63.6], zoom_start=5, control_scale=True)\n",
        "\n",
        "# m = folium.Map(\n",
        "#     location=[-38.4, -63.6],\n",
        "#     zoom_start=5,\n",
        "#     control_scale=True,\n",
        "#     tiles='https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}',\n",
        "#     attr='Esri',\n",
        "#     name='Esri Satellite',\n",
        "#     overlay=False,\n",
        "#     control=True\n",
        "# )\n",
        "\n",
        "# Add Choropleth layer from gdf\n",
        "choropleth = folium.Choropleth(\n",
        "    geo_data=gdf_but_0005,\n",
        "    name='NBUT 2000-2005',\n",
        "    data=df_but_0005,\n",
        "    columns=['IDDPTO', 'NBUT_2005'],\n",
        "    key_on='feature.properties.IDDPTO',\n",
        "    fill_color='YlOrRd',\n",
        "    fill_opacity=0.7,\n",
        "    line_opacity=0.3,\n",
        "    nan_fill_color='gray',\n",
        "    legend_name=' Normalized Built-up transitions areas period 2000-2005'\n",
        ")\n",
        "choropleth.add_to(m)\n",
        "\n",
        "# Now add an interactive GeoJson layer with popups\n",
        "geojson = folium.GeoJson(\n",
        "    gdf_but_0005,\n",
        "    name='Interactive Layer',\n",
        "    style_function=lambda feature: {\n",
        "        'fillOpacity': 0,\n",
        "        'color': 'black',\n",
        "        'weight': 0.3,\n",
        "    },\n",
        "    tooltip=folium.GeoJsonTooltip(\n",
        "        fields=['IDDPTO', 'NBUT_2005'],\n",
        "        aliases=['Dept ID:', 'Expansion (/1000 km¬≤):'],\n",
        "        localize=True,\n",
        "        sticky=True,\n",
        "        labels=True\n",
        "    )\n",
        ").add_to(m)\n",
        "\n",
        "# Display expansion raster (binary_mask) as red overlay ---\n",
        "vis_params = {\n",
        "    'min': 0,\n",
        "    'max': 1,\n",
        "    'palette': ['#ffffff', '#000000']  # white = no change, red = expansion\n",
        "}\n",
        "\n",
        "# Get map tiles from Earth Engine image\n",
        "map_id_dict = binary_mask.getMapId(vis_params)\n",
        "\n",
        "# Create Folium TileLayer\n",
        "tile = folium.raster_layers.TileLayer(\n",
        "    tiles=map_id_dict['tile_fetcher'].url_format,\n",
        "    attr='Earth Engine',\n",
        "    name='GLAD transition Raster (Black)',\n",
        "    overlay=True,\n",
        "    control=True\n",
        ")\n",
        "\n",
        "# Add raster layer to folium map\n",
        "m.add_child(tile)\n",
        "\n",
        "# Add layer control\n",
        "folium.LayerControl().add_to(m)"
      ],
      "metadata": {
        "id": "5-ZV7BjDpQJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# display map\n",
        "m"
      ],
      "metadata": {
        "id": "UNvqeHmcVjHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####  Checking results of NBUT period 2000-2005"
      ],
      "metadata": {
        "id": "8_Watr7OyjeO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section, we will extract the transition image where binary_mask is equal to 1 for the department with the highest NBUT (IDDPTO = \"02000\"). We will then verify whether pixel values correspond to transitions that end in, but do not start from any built-up class code (250, 251, 252, 253)"
      ],
      "metadata": {
        "id": "QKS5b4w9yjeP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the feature with IDDPTO '06134'\n",
        "dept_02000 = departments.filter(ee.Filter.eq('IDDPTO', '02000')).first()\n",
        "\n",
        "# Clip the transitions image by the geometry of the selected department\n",
        "transitions_clipped = transition_0005_ar.clip(dept_02000.geometry())\n",
        "binary_mask_clipped = binary_mask.clip(dept_02000.geometry())\n",
        "\n",
        "# Get pixel values of the transitions image where binary_mask_clipped == 1\n",
        "# Define the reducer to get a list of pixel values\n",
        "reducer = ee.Reducer.toList()\n",
        "\n",
        "# Reduce the clipped transitions image using the clipped binary mask\n",
        "# We multiply the transitions image by the binary mask so only pixels where\n",
        "# the mask is 1 are included in the reduction.\n",
        "pixel_values = transitions_clipped.updateMask(binary_mask_clipped).reduceRegion(\n",
        "    reducer=reducer,\n",
        "    geometry=dept_02000.geometry(),\n",
        "    scale=30,  # Use the same scale as before\n",
        "    maxPixels=1e13\n",
        ")\n",
        "\n",
        "# Extract the list of pixel values\n",
        "list_of_values = pixel_values.get('b1').getInfo()"
      ],
      "metadata": {
        "id": "spde-bBcyjeP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get unique values of list_of_values\n",
        "unique_values = list(set(list_of_values))"
      ],
      "metadata": {
        "id": "pr-pqQMuyjeP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# list of values from classes\n",
        "lovf = []\n",
        "# verify the \"from\" class is not in target_classes\n",
        "target_classes = [250, 251, 252, 253]\n",
        "for value in unique_values:\n",
        "    if value // 256 in target_classes:\n",
        "        print(value)\n",
        "    else:\n",
        "        lovf.append(value)\n",
        "        if len(lovf) == len(unique_values):\n",
        "            print(\"No value of 'from' class is in target_classes\")\n"
      ],
      "metadata": {
        "id": "1CxB_X7a1ew7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# list of values to classes\n",
        "lovt = []\n",
        "# verify the \"to\" class is in target_classes\n",
        "target_classes = [250, 251, 252, 253]\n",
        "for value in unique_values:\n",
        "    if value % 256 in target_classes:\n",
        "        lovt.append(value)\n",
        "        if len(lovt) == len(unique_values):\n",
        "            print(\"All values of 'to' class are in target_classes\")\n",
        "    else:\n",
        "        print(value)\n"
      ],
      "metadata": {
        "id": "HT_4Hkdz1Emk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Imputing values NBUT between 2001 and 2005\n",
        "\n",
        "For the time series analysis, we require NBUT data for each year between 2001 and 2005. Since no significant built-up gains are expected during this period, we will assume stability and impute the 2005 value backward from 2001 to 2004.\n",
        "\n"
      ],
      "metadata": {
        "id": "6V9TJhDMZGSY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# impute missing years\n",
        "df_but_0005['NBUT_2001'] = df_but_0005['NBUT_2005']\n",
        "df_but_0005['NBUT_2002'] = df_but_0005['NBUT_2005']\n",
        "df_but_0005['NBUT_2003'] = df_but_0005['NBUT_2005']\n",
        "df_but_0005['NBUT_2004'] = df_but_0005['NBUT_2005']"
      ],
      "metadata": {
        "id": "6qOfKi6-ZFru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# rearrange colums\n",
        "df_but_0005 = df_but_0005[['IDDPTO', 'NBUT_2001', 'NBUT_2002', 'NBUT_2003', 'NBUT_2004', 'NBUT_2005']]"
      ],
      "metadata": {
        "id": "gA9IhcbEkT85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize data.frame\n",
        "init_notebook_mode(all_interactive=True)\n",
        "df_but_0005"
      ],
      "metadata": {
        "id": "gs6JFQa2buQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Merge NBUT (2001-2005) with other features"
      ],
      "metadata": {
        "id": "X-m8HCJl_FL1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load geopackage with PM2.5, Burned areas an other datasets\n",
        "gdf = gpd.read_file(\"pdt/asthma_mortality/data/gpkg/tma_pm25_ba_pd_pdpm25_agrt_nwvt_2001_2022.gpkg\")"
      ],
      "metadata": {
        "id": "8ELtlqQ4_FL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform a left merge, preserving all rows from gdf\n",
        "gdf_nbut_0005 = gdf.merge(df_but_0005, on='IDDPTO', how='left')"
      ],
      "metadata": {
        "id": "Koaauvf-_FL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize gdf\n",
        "init_notebook_mode(all_interactive=True)\n",
        "gdf_nbut_0005.head()"
      ],
      "metadata": {
        "id": "PBx-K_PJ_FL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gdf_nbut_0005.shape"
      ],
      "metadata": {
        "id": "WHZGtpiS_FL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save dataset with NBUT (2000-2005) as other features as a gpkg file\n",
        "gdf_nbut_0005.to_file(\"pdt/asthma_mortality/data/gpkg/tma_pm25_ba_pd_pdpm25_agrt_nwvt_nbut0005_2001_2022.gpkg\", driver=\"GPKG\")"
      ],
      "metadata": {
        "id": "Q_eyL942_FL3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Computing the NBUT for the period 2005-2010\n",
        "\n",
        "In this section, we will calculate the NBUT areas for the period 2005‚Äì2010. This includes all areas that changed from any class to built-up category between 2005 and 2010 (gainings). The resulting dataset will be aggregated by department, normalized by each department‚Äôs surface area, and then multiplied by 1,000 km¬≤ to enhance interpretability."
      ],
      "metadata": {
        "id": "QicV0AWjJ9HI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load argentina boundaries\n",
        "ar_poly = ee.FeatureCollection('projects/ee-pdt/assets/argentina/ar_poly')"
      ],
      "metadata": {
        "id": "VAP-rOT7J9HI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load glad OceanMask\n",
        "landmask = ee.Image(\"projects/glad/OceanMask\").lte(1)"
      ],
      "metadata": {
        "id": "MErvbvS2J9HI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load glad lulc 2005\n",
        "m05 = ee.Image('projects/glad/GLCLU2020/v2/LCLUC_2005').updateMask(landmask)\n",
        "\n",
        "# clip m05 to ar_poly\n",
        "m05_ar = m05.clip(ar_poly)\n",
        "\n",
        "# load glad lulc 2010\n",
        "m10 = ee.Image('projects/glad/GLCLU2020/v2/LCLUC_2010').updateMask(landmask)\n",
        "\n",
        "# clip m10 to ar_poly\n",
        "m10_ar = m10.clip(ar_poly)\n",
        "\n",
        "# create a transition image where each pixel value of m05 is multiplied by 256 and the sum the pixel value of m10\n",
        "transition_0510_ar = m05_ar.multiply(256).add(m10_ar)"
      ],
      "metadata": {
        "id": "nO25Gb1mJ9HI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define target built-up class\n",
        "target_classes = [250]\n",
        "\n",
        "# Extract from and to classes\n",
        "from_class = transition_0510_ar.divide(256).floor().toInt()\n",
        "to_class = transition_0510_ar.mod(256).toInt()\n",
        "\n",
        "# Condition: to_class is in target_classes\n",
        "to_target = to_class.eq(target_classes[0])\n",
        "for cls in target_classes[1:]:\n",
        "    to_target = to_target.Or(to_class.eq(cls))\n",
        "\n",
        "# Condition: from_class is NOT in target_classes\n",
        "from_not_target = from_class.neq(target_classes[0])\n",
        "for cls in target_classes[1:]:\n",
        "    from_not_target = from_not_target.And(from_class.neq(cls))\n",
        "\n",
        "# Final mask: pixels that transitioned to built-up from a different class\n",
        "builtup_mask = to_target.And(from_not_target)\n",
        "\n",
        "# Binary mask image\n",
        "binary_mask = builtup_mask.selfMask()\n",
        "\n",
        "# Pixel area in km¬≤\n",
        "pixel_area_km2 = ee.Image.pixelArea().divide(1e6)\n",
        "\n",
        "# Multiply to get built-up area in km¬≤ per pixel\n",
        "builtup_area_img = binary_mask.multiply(pixel_area_km2)\n",
        "\n",
        "# Load departments\n",
        "departments = ee.FeatureCollection('projects/ee-pdt/assets/argentina/ar_dpto')\n",
        "\n",
        "# Function to compute expansion per department\n",
        "def compute_builtup(feature):\n",
        "    area_built = builtup_area_img.reduceRegion(\n",
        "        reducer=ee.Reducer.sum(),\n",
        "        geometry=feature.geometry(),\n",
        "        scale=30,\n",
        "        maxPixels=1e13\n",
        "    ).get('b1')  # band name\n",
        "\n",
        "    dept_area_km2 = feature.geometry().area().divide(1e6)\n",
        "    built_km2 = ee.Number(area_built)\n",
        "    built_norm = built_km2.divide(dept_area_km2)\n",
        "\n",
        "    # Normalize per 1000 km¬≤ and round to 2 decimals\n",
        "    built_norm_1000 = built_norm.multiply(1000).multiply(100).round().divide(100)\n",
        "\n",
        "    # The name of the feature should be NBUT_2005_2010,\n",
        "    # but for the sake of posterior analysis we choose NBUT_2010\n",
        "    return feature.set({'NBUT_2010': built_norm_1000})\n",
        "\n",
        "# Map over all departments\n",
        "result = departments.map(compute_builtup)"
      ],
      "metadata": {
        "id": "IHxphALXJ9HJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to GeoDataFrame and extract desired columns\n",
        "gdf_but_0510 = geemap.ee_to_gdf(result)\n",
        "df_but_0510 = gdf_but_0510[['IDDPTO', 'NBUT_2010']]"
      ],
      "metadata": {
        "id": "0sXKDycbJ9HJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize dataframe\n",
        "init_notebook_mode(all_interactive=True)\n",
        "df_but_0510"
      ],
      "metadata": {
        "id": "f5oa4BIiJ9HJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Mapping the NBUT period 2005-2010\n",
        "\n",
        "In this section we will display vector data (GeoDataFrame with NBUT 2005-2010) using folium.Choropleth"
      ],
      "metadata": {
        "id": "neYvOW_tJ9HJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create base map centered on Argentina\n",
        "m = folium.Map(location=[-38.4, -63.6], zoom_start=5, control_scale=True)\n",
        "\n",
        "# Add Choropleth layer from gdf\n",
        "choropleth = folium.Choropleth(\n",
        "    geo_data=gdf_but_0510,\n",
        "    name='NBUT 2005-2010',\n",
        "    data=df_but_0510,\n",
        "    columns=['IDDPTO', 'NBUT_2010'],\n",
        "    key_on='feature.properties.IDDPTO',\n",
        "    fill_color='YlOrRd',\n",
        "    fill_opacity=0.7,\n",
        "    line_opacity=0.3,\n",
        "    nan_fill_color='gray',\n",
        "    legend_name=' Normalized Built-up transitions areas period 2005-2010'\n",
        ")\n",
        "choropleth.add_to(m)\n",
        "\n",
        "# Now add an interactive GeoJson layer with popups\n",
        "geojson = folium.GeoJson(\n",
        "    gdf_but_0510,\n",
        "    name='Interactive Layer',\n",
        "    style_function=lambda feature: {\n",
        "        'fillOpacity': 0,\n",
        "        'color': 'black',\n",
        "        'weight': 0.3,\n",
        "    },\n",
        "    tooltip=folium.GeoJsonTooltip(\n",
        "        fields=['IDDPTO', 'NBUT_2010'],\n",
        "        aliases=['Dept ID:', 'Expansion (/1000 km¬≤):'],\n",
        "        localize=True,\n",
        "        sticky=True,\n",
        "        labels=True\n",
        "    )\n",
        ").add_to(m)\n",
        "\n",
        "# Display expansion raster (binary_mask) as red overlay ---\n",
        "vis_params = {\n",
        "    'min': 0,\n",
        "    'max': 1,\n",
        "    'palette': ['#ffffff', '#000000']  # white = no change, red = expansion\n",
        "}\n",
        "\n",
        "# Get map tiles from Earth Engine image\n",
        "map_id_dict = binary_mask.getMapId(vis_params)\n",
        "\n",
        "# Create Folium TileLayer\n",
        "tile = folium.raster_layers.TileLayer(\n",
        "    tiles=map_id_dict['tile_fetcher'].url_format,\n",
        "    attr='Earth Engine',\n",
        "    name='GLAD transition Raster (Black)',\n",
        "    overlay=True,\n",
        "    control=True\n",
        ")\n",
        "\n",
        "# Add raster layer to folium map\n",
        "m.add_child(tile)\n",
        "\n",
        "# Add layer control\n",
        "folium.LayerControl().add_to(m)"
      ],
      "metadata": {
        "id": "TbZ7CAKEJ9HJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# display map\n",
        "m"
      ],
      "metadata": {
        "id": "2Pg0ghX3J9HJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####  Checking results of NBUT period 2005-2010"
      ],
      "metadata": {
        "id": "TnE2j3QtJ9HJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section, we will extract the transition image where binary_mask is equal to 1 for the department with the highest NBUT (IDDPTO = \"50007\"). We will then verify whether pixel values correspond to transitions that end in, but do not start from any built-up class code (250, 251, 252, 253)"
      ],
      "metadata": {
        "id": "jBmgyORuJ9HJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the feature with IDDPTO '50007'\n",
        "dept_50007 = departments.filter(ee.Filter.eq('IDDPTO', '50007')).first()\n",
        "\n",
        "# Clip the transitions image by the geometry of the selected department\n",
        "transitions_clipped = transition_0510_ar.clip(dept_50007.geometry())\n",
        "binary_mask_clipped = binary_mask.clip(dept_50007.geometry())\n",
        "\n",
        "# Get pixel values of the transitions image where binary_mask_clipped == 1\n",
        "# Define the reducer to get a list of pixel values\n",
        "reducer = ee.Reducer.toList()\n",
        "\n",
        "# Reduce the clipped transitions image using the clipped binary mask\n",
        "# We multiply the transitions image by the binary mask so only pixels where\n",
        "# the mask is 1 are included in the reduction.\n",
        "pixel_values = transitions_clipped.updateMask(binary_mask_clipped).reduceRegion(\n",
        "    reducer=reducer,\n",
        "    geometry=dept_50007.geometry(),\n",
        "    scale=30,  # Use the same scale as before\n",
        "    maxPixels=1e13\n",
        ")\n",
        "\n",
        "# Extract the list of pixel values\n",
        "list_of_values = pixel_values.get('b1').getInfo()"
      ],
      "metadata": {
        "id": "tK_lKtX2J9HJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get unique values of list_of_values\n",
        "unique_values = list(set(list_of_values))"
      ],
      "metadata": {
        "id": "ASSF1QzTJ9HK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# list of values from classes\n",
        "lovf = []\n",
        "# verify the \"from\" class is not in target_classes\n",
        "target_classes = [250, 251, 252, 253]\n",
        "for value in unique_values:\n",
        "    if value // 256 in target_classes:\n",
        "        print(value)\n",
        "    else:\n",
        "        lovf.append(value)\n",
        "        if len(lovf) == len(unique_values):\n",
        "            print(\"No value of 'from' class is in target_classes\")\n"
      ],
      "metadata": {
        "id": "koZjGVk-J9HK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# list of values to classes\n",
        "lovt = []\n",
        "# verify the \"to\" class is in target_classes\n",
        "target_classes = [250, 251, 252, 253]\n",
        "for value in unique_values:\n",
        "    if value % 256 in target_classes:\n",
        "        lovt.append(value)\n",
        "        if len(lovt) == len(unique_values):\n",
        "            print(\"All values of 'to' class are in target_classes\")\n",
        "    else:\n",
        "        print(value)\n"
      ],
      "metadata": {
        "id": "3IKnUXkuJ9HK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Imputing values betwwen 2005 and 2010\n",
        "\n",
        "For the time series analysis, we require NBUT data for each year between 2005 and 2010. Since no significant built-up gains are expected during this period, we will assume stability and impute the 2010 value backward from 2006 to 2009\n",
        "\n"
      ],
      "metadata": {
        "id": "HmLcjjGjeLRV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# impute missing years\n",
        "df_but_0510['NBUT_2006'] = df_but_0510['NBUT_2010']\n",
        "df_but_0510['NBUT_2007'] = df_but_0510['NBUT_2010']\n",
        "df_but_0510['NBUT_2008'] = df_but_0510['NBUT_2010']\n",
        "df_but_0510['NBUT_2009'] = df_but_0510['NBUT_2010']"
      ],
      "metadata": {
        "id": "SbF9zuFheLRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# rearrange colums\n",
        "df_but_0510 = df_but_0510[['IDDPTO', 'NBUT_2006', 'NBUT_2007', 'NBUT_2008', 'NBUT_2009', 'NBUT_2010']]"
      ],
      "metadata": {
        "id": "E4Wk4oxbkb7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize data.frame\n",
        "init_notebook_mode(all_interactive=True)\n",
        "df_but_0510"
      ],
      "metadata": {
        "id": "steh0d_yeLRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Merge NBUT (2005-2010) with other features"
      ],
      "metadata": {
        "id": "didG9sVwJ9HK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load geopackage with PM2.5, Burned areas an other datasets\n",
        "gdf = gpd.read_file(\"pdt/asthma_mortality/data/gpkg/tma_pm25_ba_pd_pdpm25_agrt_nwvt_nbut0005_2001_2022.gpkg\")"
      ],
      "metadata": {
        "id": "Tc5iX4XXJ9HK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform a left merge, preserving all rows from gdf\n",
        "gdf_nbut_0510 = gdf.merge(df_but_0510, on='IDDPTO', how='left')"
      ],
      "metadata": {
        "id": "LkOrUfEEJ9HK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize gdf\n",
        "init_notebook_mode(all_interactive=True)\n",
        "gdf_nbut_0510.head()"
      ],
      "metadata": {
        "id": "IKXssQ5lJ9HK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gdf_nbut_0510.shape"
      ],
      "metadata": {
        "id": "kFUwtykXJ9HL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save dataset with NBUT (2005-2010) as other features as a gpkg file\n",
        "gdf_nbut_0510.to_file(\"pdt/asthma_mortality/data/gpkg/tma_pm25_ba_pd_pdpm25_agrt_nwvt_nbut0010_2001_2022.gpkg\", driver=\"GPKG\")"
      ],
      "metadata": {
        "id": "43iBneK-J9HL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Computing the NBUT for the period 2010-2015\n",
        "\n",
        "In this section, we will calculate the NBUT areas for the period 2010‚Äì2015. This includes all areas that changed from any class to built-up category between 2010 and 2015 (gainings). The resulting dataset will be aggregated by department, normalized by each department‚Äôs surface area, and then multiplied by 1,000 km¬≤ to enhance interpretability."
      ],
      "metadata": {
        "id": "xO3pdlxN11B_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load argentina boundaries\n",
        "ar_poly = ee.FeatureCollection('projects/ee-pdt/assets/argentina/ar_poly')"
      ],
      "metadata": {
        "id": "TNoHeI2q11B_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load glad OceanMask\n",
        "landmask = ee.Image(\"projects/glad/OceanMask\").lte(1)"
      ],
      "metadata": {
        "id": "VZ2hO6_F11B_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load glad lulc 2010\n",
        "m10 = ee.Image('projects/glad/GLCLU2020/v2/LCLUC_2010').updateMask(landmask)\n",
        "\n",
        "# clip m10 to ar_poly\n",
        "m10_ar = m10.clip(ar_poly)\n",
        "\n",
        "# load glad lulc 2015\n",
        "m15 = ee.Image('projects/glad/GLCLU2020/v2/LCLUC_2015').updateMask(landmask)\n",
        "\n",
        "# clip m15 to ar_poly\n",
        "m15_ar = m15.clip(ar_poly)\n",
        "\n",
        "# create a transition image where each pixel value of m10 is multiplied by 256 and the sum the pixel value of m15\n",
        "transition_1015_ar = m10_ar.multiply(256).add(m15_ar)"
      ],
      "metadata": {
        "id": "nROExPhE11CA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define target built-up classes\n",
        "target_classes = [250]\n",
        "\n",
        "# Extract from and to classes\n",
        "from_class = transition_1015_ar.divide(256).floor().toInt()\n",
        "to_class = transition_1015_ar.mod(256).toInt()\n",
        "\n",
        "# Condition: to_class is in target_classes\n",
        "to_target = to_class.eq(target_classes[0])\n",
        "for cls in target_classes[1:]:\n",
        "    to_target = to_target.Or(to_class.eq(cls))\n",
        "\n",
        "# Condition: from_class is NOT in target_classes\n",
        "from_not_target = from_class.neq(target_classes[0])\n",
        "for cls in target_classes[1:]:\n",
        "    from_not_target = from_not_target.And(from_class.neq(cls))\n",
        "\n",
        "# Final mask: pixels that transitioned to built-up from a different class\n",
        "builtup_mask = to_target.And(from_not_target)\n",
        "\n",
        "# Binary mask image\n",
        "binary_mask = builtup_mask.selfMask()\n",
        "\n",
        "# Pixel area in km¬≤\n",
        "pixel_area_km2 = ee.Image.pixelArea().divide(1e6)\n",
        "\n",
        "# Multiply to get built-up area in km¬≤ per pixel\n",
        "builtup_area_img = binary_mask.multiply(pixel_area_km2)\n",
        "\n",
        "# Load departments\n",
        "departments = ee.FeatureCollection('projects/ee-pdt/assets/argentina/ar_dpto')\n",
        "\n",
        "# Function to compute expansion per department\n",
        "def compute_builtup(feature):\n",
        "    area_built = builtup_area_img.reduceRegion(\n",
        "        reducer=ee.Reducer.sum(),\n",
        "        geometry=feature.geometry(),\n",
        "        scale=30,\n",
        "        maxPixels=1e13\n",
        "    ).get('b1')  # band name\n",
        "\n",
        "    dept_area_km2 = feature.geometry().area().divide(1e6)\n",
        "    built_km2 = ee.Number(area_built)\n",
        "    built_norm = built_km2.divide(dept_area_km2)\n",
        "\n",
        "    # Normalize per 1000 km¬≤ and round to 2 decimals\n",
        "    built_norm_1000 = built_norm.multiply(1000).multiply(100).round().divide(100)\n",
        "\n",
        "    # The name of the feature should be NBUT_2010_2015,\n",
        "    # but for the sake of posterior analysis we choose NBUT_2015\n",
        "    return feature.set({'NBUT_2015': built_norm_1000})\n",
        "\n",
        "# Map over all departments\n",
        "result = departments.map(compute_builtup)"
      ],
      "metadata": {
        "id": "zFx2G1pO11CA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to GeoDataFrame and extract desired columns\n",
        "gdf_but_1015 = geemap.ee_to_gdf(result)\n",
        "df_but_1015 = gdf_but_1015[['IDDPTO', 'NBUT_2015']]"
      ],
      "metadata": {
        "id": "hE-ijZhp11CA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize dataframe\n",
        "init_notebook_mode(all_interactive=True)\n",
        "df_but_1015"
      ],
      "metadata": {
        "id": "gQnsB5F-11CA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Mapping the NBUT period 2010-2015\n",
        "\n",
        "In this section we will display vector data (GeoDataFrame with NBUT 2010-2015) using folium.Choropleth"
      ],
      "metadata": {
        "id": "p9SRc3KY11CA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create base map centered on Argentina\n",
        "m = folium.Map(location=[-38.4, -63.6], zoom_start=5, control_scale=True)\n",
        "\n",
        "# m = folium.Map(\n",
        "#     location=[-38.4, -63.6],\n",
        "#     zoom_start=5,\n",
        "#     control_scale=True,\n",
        "#     tiles='https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}',\n",
        "#     attr='Esri',\n",
        "#     name='Esri Satellite',\n",
        "#     overlay=False,\n",
        "#     control=True\n",
        "# )\n",
        "\n",
        "# Add Choropleth layer from gdf\n",
        "choropleth = folium.Choropleth(\n",
        "    geo_data=gdf_but_1015,\n",
        "    name='NBUT 2010-2015',\n",
        "    data=df_but_1015,\n",
        "    columns=['IDDPTO', 'NBUT_2015'],\n",
        "    key_on='feature.properties.IDDPTO',\n",
        "    fill_color='YlOrRd',\n",
        "    fill_opacity=0.7,\n",
        "    line_opacity=0.3,\n",
        "    nan_fill_color='gray',\n",
        "    legend_name=' Normalized Built-up transitions areas period 2010-2015'\n",
        ")\n",
        "choropleth.add_to(m)\n",
        "\n",
        "# Now add an interactive GeoJson layer with popups\n",
        "geojson = folium.GeoJson(\n",
        "    gdf_but_1015,\n",
        "    name='Interactive Layer',\n",
        "    style_function=lambda feature: {\n",
        "        'fillOpacity': 0,\n",
        "        'color': 'black',\n",
        "        'weight': 0.3,\n",
        "    },\n",
        "    tooltip=folium.GeoJsonTooltip(\n",
        "        fields=['IDDPTO', 'NBUT_2015'],\n",
        "        aliases=['Dept ID:', 'Expansion (/1000 km¬≤):'],\n",
        "        localize=True,\n",
        "        sticky=True,\n",
        "        labels=True\n",
        "    )\n",
        ").add_to(m)\n",
        "\n",
        "# Display expansion raster (binary_mask) as red overlay ---\n",
        "vis_params = {\n",
        "    'min': 0,\n",
        "    'max': 1,\n",
        "    'palette': ['#ffffff', '#000000']  # white = no change, red = expansion\n",
        "}\n",
        "\n",
        "# Get map tiles from Earth Engine image\n",
        "map_id_dict = binary_mask.getMapId(vis_params)\n",
        "\n",
        "# Create Folium TileLayer\n",
        "tile = folium.raster_layers.TileLayer(\n",
        "    tiles=map_id_dict['tile_fetcher'].url_format,\n",
        "    attr='Earth Engine',\n",
        "    name='GLAD transition Raster (Black)',\n",
        "    overlay=True,\n",
        "    control=True\n",
        ")\n",
        "\n",
        "# Add raster layer to folium map\n",
        "m.add_child(tile)\n",
        "\n",
        "# Add layer control\n",
        "folium.LayerControl().add_to(m)"
      ],
      "metadata": {
        "id": "o73vSx2h11CA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# display map\n",
        "m"
      ],
      "metadata": {
        "id": "rTYRdQ-t11CA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####  Checking results of NBUT period 2010-2015"
      ],
      "metadata": {
        "id": "K_yYTWLS11CA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section, we will extract the transition image where binary_mask is equal to 1 for the department with the highest NBUT (IDDPTO = \"50028\"). We will then verify whether pixel values correspond to transitions that end in, but do not start from any built-up class code (250, 251, 252, 253)"
      ],
      "metadata": {
        "id": "taPjhcM011CB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the feature with IDDPTO '50028'\n",
        "dept_50028 = departments.filter(ee.Filter.eq('IDDPTO', '50028')).first()\n",
        "\n",
        "# Clip the transitions image by the geometry of the selected department\n",
        "transitions_clipped = transition_1015_ar.clip(dept_50028.geometry())\n",
        "binary_mask_clipped = binary_mask.clip(dept_50028.geometry())\n",
        "\n",
        "# Get pixel values of the transitions image where binary_mask_clipped == 1\n",
        "# Define the reducer to get a list of pixel values\n",
        "reducer = ee.Reducer.toList()\n",
        "\n",
        "# Reduce the clipped transitions image using the clipped binary mask\n",
        "# We multiply the transitions image by the binary mask so only pixels where\n",
        "# the mask is 1 are included in the reduction.\n",
        "pixel_values = transitions_clipped.updateMask(binary_mask_clipped).reduceRegion(\n",
        "    reducer=reducer,\n",
        "    geometry=dept_50028.geometry(),\n",
        "    scale=30,  # Use the same scale as before\n",
        "    maxPixels=1e13\n",
        ")\n",
        "\n",
        "# Extract the list of pixel values\n",
        "list_of_values = pixel_values.get('b1').getInfo()"
      ],
      "metadata": {
        "id": "lQyDpQ4g11CB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get unique values of list_of_values\n",
        "unique_values = list(set(list_of_values))"
      ],
      "metadata": {
        "id": "AMV875wZ11CB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# list of values from classes\n",
        "lovf = []\n",
        "# verify the \"from\" class is not in target_classes\n",
        "target_classes = [250, 251, 252, 253]\n",
        "for value in unique_values:\n",
        "    if value // 256 in target_classes:\n",
        "        print(value)\n",
        "    else:\n",
        "        lovf.append(value)\n",
        "        if len(lovf) == len(unique_values):\n",
        "            print(\"No value of 'from' class is in target_classes\")\n"
      ],
      "metadata": {
        "id": "HWgfoOWO11CB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# list of values to classes\n",
        "lovt = []\n",
        "# verify the \"to\" class is in target_classes\n",
        "target_classes = [250, 251, 252, 253]\n",
        "for value in unique_values:\n",
        "    if value % 256 in target_classes:\n",
        "        lovt.append(value)\n",
        "        if len(lovt) == len(unique_values):\n",
        "            print(\"All values of 'to' class are in target_classes\")\n",
        "    else:\n",
        "        print(value)\n"
      ],
      "metadata": {
        "id": "EKWp8lh711CB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Imputing values betwwen 2010 and 2015\n",
        "\n",
        "For the time series analysis, we require NBUT data for each year between 2010 and 2015. Since no significant built-up gains are expected during this period, we will assume stability and impute the 2015 value backward from 2011 to 2014\n",
        "\n"
      ],
      "metadata": {
        "id": "QD4iD8v7mhlZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# impute missing years\n",
        "df_but_1015['NBUT_2011'] = df_but_1015['NBUT_2015']\n",
        "df_but_1015['NBUT_2012'] = df_but_1015['NBUT_2015']\n",
        "df_but_1015['NBUT_2013'] = df_but_1015['NBUT_2015']\n",
        "df_but_1015['NBUT_2014'] = df_but_1015['NBUT_2015']"
      ],
      "metadata": {
        "id": "1k54gZeWmhlZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# rearrange colums\n",
        "df_but_1015 = df_but_1015[['IDDPTO', 'NBUT_2011', 'NBUT_2012', 'NBUT_2013', 'NBUT_2014', 'NBUT_2015']]"
      ],
      "metadata": {
        "id": "5CiZTF7dmhla"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize data.frame\n",
        "init_notebook_mode(all_interactive=True)\n",
        "df_but_1015"
      ],
      "metadata": {
        "id": "QID2BUYdmhla"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Merge NBUT (2010-2015) with other features"
      ],
      "metadata": {
        "id": "FYb67aSu11CB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load geopackage with PM2.5, Burned areas an other datasets\n",
        "gdf = gpd.read_file(\"pdt/asthma_mortality/data/gpkg/tma_pm25_ba_pd_pdpm25_agrt_nwvt_nbut0010_2001_2022.gpkg\")"
      ],
      "metadata": {
        "id": "UXaqkCte11CB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform a left merge, preserving all rows from gdf\n",
        "gdf_nbut_1015 = gdf.merge(df_but_1015, on='IDDPTO', how='left')"
      ],
      "metadata": {
        "id": "vAdrVxx911CB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize gdf\n",
        "init_notebook_mode(all_interactive=True)\n",
        "gdf_nbut_1015.head()"
      ],
      "metadata": {
        "id": "s8bby5UO11CB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gdf_nbut_1015.shape"
      ],
      "metadata": {
        "id": "It-uc8QC11CC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save dataset with NBUT (2005-2010) as other features as a gpkg file\n",
        "gdf_nbut_1015.to_file(\"pdt/asthma_mortality/data/gpkg/tma_pm25_ba_pd_pdpm25_agrt_nwvt_nbut0015_2001_2022.gpkg\", driver=\"GPKG\")"
      ],
      "metadata": {
        "id": "yB7jZQzP11CC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Computing the NBUT for the period 2015-2020\n",
        "\n",
        "In this section, we will calculate the NBUT areas for the period 2015‚Äì2020. This includes all areas that changed from any class to built-up category between 2015 and 2020 (gainings). The resulting dataset will be aggregated by department, normalized by each department‚Äôs surface area, and then multiplied by 1,000 km¬≤ to enhance interpretability."
      ],
      "metadata": {
        "id": "B-h245Kl_zJZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load argentina boundaries\n",
        "ar_poly = ee.FeatureCollection('projects/ee-pdt/assets/argentina/ar_poly')"
      ],
      "metadata": {
        "id": "KoS0lwUT_zJZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load glad OceanMask\n",
        "landmask = ee.Image(\"projects/glad/OceanMask\").lte(1)"
      ],
      "metadata": {
        "id": "AMQ3T6yC_zJZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load glad lulc 2015\n",
        "m15 = ee.Image('projects/glad/GLCLU2020/v2/LCLUC_2015').updateMask(landmask)\n",
        "\n",
        "# clip m15 to ar_poly\n",
        "m15_ar = m15.clip(ar_poly)\n",
        "\n",
        "# load glad lulc 2020\n",
        "m20 = ee.Image('projects/glad/GLCLU2020/v2/LCLUC_2020').updateMask(landmask)\n",
        "\n",
        "# clip m20 to ar_poly\n",
        "m20_ar = m20.clip(ar_poly)\n",
        "\n",
        "# create a transition image where each pixel value of m15 is multiplied by 256 and the sum the pixel value of m20\n",
        "transition_1520_ar = m15_ar.multiply(256).add(m20_ar)"
      ],
      "metadata": {
        "id": "ubEI0BHh_zJZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define target built-up classes\n",
        "target_classes = [250]\n",
        "\n",
        "# Extract from and to classes\n",
        "from_class = transition_1520_ar.divide(256).floor().toInt()\n",
        "to_class = transition_1520_ar.mod(256).toInt()\n",
        "\n",
        "# Condition: to_class is in target_classes\n",
        "to_target = to_class.eq(target_classes[0])\n",
        "for cls in target_classes[1:]:\n",
        "    to_target = to_target.Or(to_class.eq(cls))\n",
        "\n",
        "# Condition: from_class is NOT in target_classes\n",
        "from_not_target = from_class.neq(target_classes[0])\n",
        "for cls in target_classes[1:]:\n",
        "    from_not_target = from_not_target.And(from_class.neq(cls))\n",
        "\n",
        "# Final mask: pixels that transitioned to built-up from a different class\n",
        "builtup_mask = to_target.And(from_not_target)\n",
        "\n",
        "# Binary mask image\n",
        "binary_mask = builtup_mask.selfMask()\n",
        "\n",
        "# Pixel area in km¬≤\n",
        "pixel_area_km2 = ee.Image.pixelArea().divide(1e6)\n",
        "\n",
        "# Multiply to get built-up area in km¬≤ per pixel\n",
        "builtup_area_img = binary_mask.multiply(pixel_area_km2)\n",
        "\n",
        "# Load departments\n",
        "departments = ee.FeatureCollection('projects/ee-pdt/assets/argentina/ar_dpto')\n",
        "\n",
        "# Function to compute expansion per department\n",
        "def compute_builtup(feature):\n",
        "    area_built = builtup_area_img.reduceRegion(\n",
        "        reducer=ee.Reducer.sum(),\n",
        "        geometry=feature.geometry(),\n",
        "        scale=30,\n",
        "        maxPixels=1e13\n",
        "    ).get('b1')  # band name\n",
        "\n",
        "    dept_area_km2 = feature.geometry().area().divide(1e6)\n",
        "    built_km2 = ee.Number(area_built)\n",
        "    built_norm = built_km2.divide(dept_area_km2)\n",
        "\n",
        "    # Normalize per 1000 km¬≤ and round to 2 decimals\n",
        "    built_norm_1000 = built_norm.multiply(1000).multiply(100).round().divide(100)\n",
        "\n",
        "    # The name of the feature should be NBUT_2015_2020,\n",
        "    # but for the sake of posterior analysis we choose NBUT_2020\n",
        "    return feature.set({'NBUT_2020': built_norm_1000})\n",
        "\n",
        "# Map over all departments\n",
        "result = departments.map(compute_builtup)"
      ],
      "metadata": {
        "id": "Bg7Ot0uw_zJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to GeoDataFrame and extract desired columns\n",
        "gdf_but_1520 = geemap.ee_to_gdf(result)\n",
        "df_but_1520 = gdf_but_1520[['IDDPTO', 'NBUT_2020']]"
      ],
      "metadata": {
        "id": "6f22T7y2_zJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize dataframe\n",
        "init_notebook_mode(all_interactive=True)\n",
        "df_but_1520"
      ],
      "metadata": {
        "id": "oaa40YiR_zJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Mapping the NBUT period 2015-2020\n",
        "\n",
        "In this section we will display vector data (GeoDataFrame with NBUT 2015-2020) using folium.Choropleth"
      ],
      "metadata": {
        "id": "aihWqdM3_zJa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create base map centered on Argentina\n",
        "m = folium.Map(location=[-38.4, -63.6], zoom_start=5, control_scale=True)\n",
        "\n",
        "# m = folium.Map(\n",
        "#     location=[-38.4, -63.6],\n",
        "#     zoom_start=5,\n",
        "#     control_scale=True,\n",
        "#     tiles='https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}',\n",
        "#     attr='Esri',\n",
        "#     name='Esri Satellite',\n",
        "#     overlay=False,\n",
        "#     control=True\n",
        "# )\n",
        "\n",
        "# Add Choropleth layer from gdf\n",
        "choropleth = folium.Choropleth(\n",
        "    geo_data=gdf_but_1520,\n",
        "    name='NBUT 2015-2020',\n",
        "    data=df_but_1520,\n",
        "    columns=['IDDPTO', 'NBUT_2020'],\n",
        "    key_on='feature.properties.IDDPTO',\n",
        "    fill_color='YlOrRd',\n",
        "    fill_opacity=0.7,\n",
        "    line_opacity=0.3,\n",
        "    nan_fill_color='gray',\n",
        "    legend_name=' Normalized Built-up transitions areas period 2015-2020'\n",
        ")\n",
        "choropleth.add_to(m)\n",
        "\n",
        "# Now add an interactive GeoJson layer with popups\n",
        "geojson = folium.GeoJson(\n",
        "    gdf_but_1520,\n",
        "    name='Interactive Layer',\n",
        "    style_function=lambda feature: {\n",
        "        'fillOpacity': 0,\n",
        "        'color': 'black',\n",
        "        'weight': 0.3,\n",
        "    },\n",
        "    tooltip=folium.GeoJsonTooltip(\n",
        "        fields=['IDDPTO', 'NBUT_2020'],\n",
        "        aliases=['Dept ID:', 'Expansion (/1000 km¬≤):'],\n",
        "        localize=True,\n",
        "        sticky=True,\n",
        "        labels=True\n",
        "    )\n",
        ").add_to(m)\n",
        "\n",
        "# Display expansion raster (binary_mask) as red overlay ---\n",
        "vis_params = {\n",
        "    'min': 0,\n",
        "    'max': 1,\n",
        "    'palette': ['#ffffff', '#000000']  # white = no change, red = expansion\n",
        "}\n",
        "\n",
        "# Get map tiles from Earth Engine image\n",
        "map_id_dict = binary_mask.getMapId(vis_params)\n",
        "\n",
        "# Create Folium TileLayer\n",
        "tile = folium.raster_layers.TileLayer(\n",
        "    tiles=map_id_dict['tile_fetcher'].url_format,\n",
        "    attr='Earth Engine',\n",
        "    name='GLAD transition Raster (Black)',\n",
        "    overlay=True,\n",
        "    control=True\n",
        ")\n",
        "\n",
        "# Add raster layer to folium map\n",
        "m.add_child(tile)\n",
        "\n",
        "# Add layer control\n",
        "folium.LayerControl().add_to(m)"
      ],
      "metadata": {
        "id": "UYFAg7T2_zJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# display map\n",
        "m"
      ],
      "metadata": {
        "id": "acd6ZO9N_zJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####  Checking results of NBUT period 2015-2020"
      ],
      "metadata": {
        "id": "VAHjBQcw_zJa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section, we will extract the transition image where binary_mask is equal to 1 for the department with the highest NBUT (IDDPTO = \"06247\"). We will then verify whether pixel values correspond to transitions that end in, but do not start from any built-up class code (250, 251, 252, 253)"
      ],
      "metadata": {
        "id": "a-NLoSaT_zJa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the feature with IDDPTO '06274'\n",
        "dept_06274 = departments.filter(ee.Filter.eq('IDDPTO', '06274')).first()\n",
        "\n",
        "# Clip the transitions image by the geometry of the selected department\n",
        "transitions_clipped = transition_1520_ar.clip(dept_06274.geometry())\n",
        "binary_mask_clipped = binary_mask.clip(dept_06274.geometry())\n",
        "\n",
        "# Get pixel values of the transitions image where binary_mask_clipped == 1\n",
        "# Define the reducer to get a list of pixel values\n",
        "reducer = ee.Reducer.toList()\n",
        "\n",
        "# Reduce the clipped transitions image using the clipped binary mask\n",
        "# We multiply the transitions image by the binary mask so only pixels where\n",
        "# the mask is 1 are included in the reduction.\n",
        "pixel_values = transitions_clipped.updateMask(binary_mask_clipped).reduceRegion(\n",
        "    reducer=reducer,\n",
        "    geometry=dept_06274.geometry(),\n",
        "    scale=30,  # Use the same scale as before\n",
        "    maxPixels=1e13\n",
        ")\n",
        "\n",
        "# Extract the list of pixel values\n",
        "list_of_values = pixel_values.get('b1').getInfo()"
      ],
      "metadata": {
        "id": "icKnoC5c_zJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get unique values of list_of_values\n",
        "unique_values = list(set(list_of_values))"
      ],
      "metadata": {
        "id": "r_vsECsV_zJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# list of values from classes\n",
        "lovf = []\n",
        "# verify the \"from\" class is not in target_classes\n",
        "target_classes = [250, 251, 252, 253]\n",
        "for value in unique_values:\n",
        "    if value // 256 in target_classes:\n",
        "        print(value)\n",
        "    else:\n",
        "        lovf.append(value)\n",
        "        if len(lovf) == len(unique_values):\n",
        "            print(\"No value of 'from' class is in target_classes\")\n"
      ],
      "metadata": {
        "id": "1JueKFq4_zJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# list of values to classes\n",
        "lovt = []\n",
        "# verify the \"to\" class is in target_classes\n",
        "target_classes = [250, 251, 252, 253]\n",
        "for value in unique_values:\n",
        "    if value % 256 in target_classes:\n",
        "        lovt.append(value)\n",
        "        if len(lovt) == len(unique_values):\n",
        "            print(\"All values of 'to' class are in target_classes\")\n",
        "    else:\n",
        "        print(value)\n"
      ],
      "metadata": {
        "id": "GpAJ8lYr_zJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Imputing values betwwen 2015 and 2020\n",
        "\n",
        "For the time series analysis, we require NBUT data for each year between 2015 and 2020. Since no significant built-up gains are expected during this period, we will assume stability and impute the 2020 value backward from 2016 to 2019, and forward to 2021\n",
        "\n"
      ],
      "metadata": {
        "id": "CUr49ajHpVE5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# impute missing years\n",
        "df_but_1520['NBUT_2016'] = df_but_1520['NBUT_2020']\n",
        "df_but_1520['NBUT_2017'] = df_but_1520['NBUT_2020']\n",
        "df_but_1520['NBUT_2018'] = df_but_1520['NBUT_2020']\n",
        "df_but_1520['NBUT_2019'] = df_but_1520['NBUT_2020']\n",
        "df_but_1520['NBUT_2021'] = df_but_1520['NBUT_2020']"
      ],
      "metadata": {
        "id": "6Qvwi0kTpVE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# rearrange colums\n",
        "df_but_1520 = df_but_1520[['IDDPTO', 'NBUT_2016', 'NBUT_2017', 'NBUT_2018', 'NBUT_2019', 'NBUT_2020', 'NBUT_2021']]"
      ],
      "metadata": {
        "id": "snx6ql1QpVE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize data.frame\n",
        "init_notebook_mode(all_interactive=True)\n",
        "df_but_1520"
      ],
      "metadata": {
        "id": "tz8IzFtHpVE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Merge NBUT (2015-2020) with other features"
      ],
      "metadata": {
        "id": "TyrJUTtE_zJb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load geopackage with PM2.5, Burned areas an other datasets\n",
        "gdf = gpd.read_file(\"pdt/asthma_mortality/data/gpkg/tma_pm25_ba_pd_pdpm25_agrt_nwvt_nbut0015_2001_2022.gpkg\")"
      ],
      "metadata": {
        "id": "Po6wgix3_zJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform a left merge, preserving all rows from gdf\n",
        "gdf_nbut_1520 = gdf.merge(df_but_1520, on='IDDPTO', how='left')"
      ],
      "metadata": {
        "id": "Gbw4t1rP_zJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize gdf\n",
        "init_notebook_mode(all_interactive=True)\n",
        "gdf_nbut_1520.head()"
      ],
      "metadata": {
        "id": "_ROgIKtk_zJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gdf_nbut_1520.shape"
      ],
      "metadata": {
        "id": "ptMEgGE7_zJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save dataset with NBUT (2005-2010) as other features as a gpkg file\n",
        "gdf_nbut_1520.to_file(\"pdt/asthma_mortality/data/gpkg/tma_pm25_ba_pd_pdpm25_agrt_nwvt_nbut0020_2001_2022.gpkg\", driver=\"GPKG\")"
      ],
      "metadata": {
        "id": "iVKm49mN_zJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Computing the NBUT for the period 2021-2022\n",
        "\n",
        "In this section, we will calculate the NBUT (Normalized Built-Up Transitions) areas for the period 2021‚Äì2022. We will use the [Dynamic World V1](https://developers.google.com/earth-engine/datasets/catalog/GOOGLE_DYNAMICWORLD_V1) (DW) availabe on GEE with 10m spatial resolution. This calculation includes all areas that transitioned from any land cover class to the built-up category during that time frame (i.e., gains). The resulting dataset will be aggregated by department, normalized by each department‚Äôs surface area, and multiplied by 1,000 km¬≤ to improve interpretability."
      ],
      "metadata": {
        "id": "eoxfdvTFouqf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Calculating the Built-up Transition Image (2021-2022)\n",
        "\n",
        "The size of the Dynamic World (DW) dataset exceeds the computational limits of a free Google Earth Engine (GEE) account. Therefore, we will begin by calculating the built-up transition image for the period 2021‚Äì2022. This image will be stored in our GEE Assets and subsequently used to compute the New Built-Up Transitions (NBUT) during this period.\n",
        "\n",
        "We will mask built-up areas and assign a pixel value of 1 to generate a binary built-up dominant image for each year. Then, using predefined dummy transition values (as explained below), we will compute the New Built-Up Transition (NBUT) areas for the period 2001 to 2022."
      ],
      "metadata": {
        "id": "p3W7qZYeT6AR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example on how to get a dummy transition value\n",
        "# From is the start year\n",
        "# To is the End year\n",
        "From = 0 # non-build-up\n",
        "To = 1 #  built-up\n",
        "value = (From * 2) + To\n",
        "print(\"Dummy transition value is:\",  value)"
      ],
      "metadata": {
        "id": "-ALlSlnH6kdZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get From and To value from dummie trasition value\n",
        "From_2 = value//2\n",
        "To_2 = value%2\n",
        "print(\"Value:\", value, \"From:\", From_2, \"To:\", To_2)"
      ],
      "metadata": {
        "id": "QWoTXF0n6kdZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Argentina boundary\n",
        "argentina = ee.FeatureCollection(\"projects/ee-pdt/assets/argentina/ar_poly\")\n",
        "\n",
        "# Define date ranges\n",
        "start_date1 = '2021-01-01'\n",
        "end_date1 = '2021-12-31'\n",
        "start_date2 = '2022-01-01'\n",
        "end_date2 = '2022-12-31'\n",
        "\n",
        "# Load and clip Dynamic World mean images\n",
        "dw_2021 = (\n",
        "    ee.ImageCollection(\"GOOGLE/DYNAMICWORLD/V1\")\n",
        "    .filterDate(start_date1, end_date1)\n",
        "    .max()\n",
        "    .clip(argentina)\n",
        ")\n",
        "\n",
        "dw_2022 = (\n",
        "    ee.ImageCollection(\"GOOGLE/DYNAMICWORLD/V1\")\n",
        "    .filterDate(start_date2, end_date2)\n",
        "    .max()\n",
        "    .clip(argentina)\n",
        ")\n",
        "\n",
        "# List of class bands in Dynamic World\n",
        "prob_bands = [\n",
        "    'water', 'trees', 'grass', 'flooded_vegetation', 'crops',\n",
        "    'shrub_and_scrub', 'built', 'bare', 'snow_and_ice'\n",
        "]\n",
        "\n",
        "# Built-dominant classification for 2021\n",
        "prob_array_2021 = dw_2021.select(prob_bands).toArray()\n",
        "max_prob_index_2021 = prob_array_2021.arrayArgmax().arrayGet([0])\n",
        "built_dominant_mask_2021 = max_prob_index_2021.eq(6)\n",
        "built_dominant_bin_2021 = built_dominant_mask_2021.rename('built_2021').unmask(0).uint8()\n",
        "\n",
        "# Built-dominant classification for 2022\n",
        "prob_array_2022 = dw_2022.select(prob_bands).toArray()\n",
        "max_prob_index_2022 = prob_array_2022.arrayArgmax().arrayGet([0])\n",
        "built_dominant_mask_2022 = max_prob_index_2022.eq(6)\n",
        "built_dominant_2022_bin = built_dominant_mask_2022.rename('built_2022').unmask(0).uint8()\n",
        "\n",
        "# Detect transitions from non-built to built\n",
        "built_2021_times2 = built_dominant_bin_2021.multiply(2)\n",
        "built_sum = built_2021_times2.add(built_dominant_2022_bin)\n",
        "built_up_transition_2021_2022 = built_sum.eq(1).rename('built_up_transition_2021_2022').uint8()\n",
        "\n",
        "# Mask pixels where transition = 1\n",
        "built_up_transition_masked = built_up_transition_2021_2022.updateMask(built_up_transition_2021_2022)"
      ],
      "metadata": {
        "id": "p--3rwG1SzOd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is not necessary to export the `built_up_transition_masked` image as an asset, since it has already been created and shared. However, if you wish to export it yourself, you can uncomment the code below and execute it.\n",
        "\n"
      ],
      "metadata": {
        "id": "Ribvv8dhWy_r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define export parameters\n",
        "# export_task = ee.batch.Export.image.toAsset(\n",
        "#     image=built_up_transition_masked,\n",
        "#     description='export_built_up_transition_masked 2021-2022',\n",
        "#     assetId='projects/ee-pdt/assets/built_up_transition_2021_2022',\n",
        "#     region=argentina.geometry(),\n",
        "#     scale=10,\n",
        "#     crs='EPSG:4326',\n",
        "#     maxPixels=1e13\n",
        "# )"
      ],
      "metadata": {
        "id": "oScPTwUzUB32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Start the task\n",
        "# export_task.start()\n",
        "# print(\"Export task started. Check the Tasks tab in the Earth Engine Code Editor.\")"
      ],
      "metadata": {
        "id": "whm83SaAUB6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Computing the NBUT in Cordoba Province (2020-2022)"
      ],
      "metadata": {
        "id": "BmRGW-v2F07J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Due to computational constraints, this analysis will be performed aprovincial level. We will start with the province of C√≥rdoba for visualization purposes, and then extend the calculation to all provinces using an iterative approach."
      ],
      "metadata": {
        "id": "z6_zS_TGTvMC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load C√≥rdoba province departments (IDPROV = 14)\n",
        "all_dptos = ee.FeatureCollection(\"projects/ee-pdt/assets/argentina/ar_prov_dpto\")\n",
        "cordoba_dptos = all_dptos.filter(ee.Filter.eq('IDPROV', \"14\"))\n",
        "\n",
        "# Load built-up transition image and mask it\n",
        "built_up_transition_masked = (\n",
        "    ee.Image(\"projects/ee-pdt/assets/dynamicworld/built_up_transition_2021_2022\")\n",
        "    .clip(cordoba_dptos)\n",
        "    .selfMask()\n",
        ")"
      ],
      "metadata": {
        "id": "dF_Ic7xjZEKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute built-up area per pixel in km¬≤\n",
        "pixel_area_km2 = ee.Image.pixelArea().divide(1e6)\n",
        "built_up_area_km2 = built_up_transition_masked.multiply(pixel_area_km2).rename('built_up_km2')\n",
        "\n",
        "# Sum built-up area per department\n",
        "zonal_stats = built_up_area_km2.reduceRegions(\n",
        "    collection=cordoba_dptos,\n",
        "    reducer=ee.Reducer.sum().unweighted(),\n",
        "    scale=10,\n",
        "    crs='EPSG:4326'\n",
        ")"
      ],
      "metadata": {
        "id": "qKO1vSJwO8uq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rename 'sum' to 'built_up_area_km2'\n",
        "zonal_stats_renamed = zonal_stats.map(lambda f: f.set('built_up_area_km2', ee.Number(f.get('sum'))))"
      ],
      "metadata": {
        "id": "stApx-gsZj9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate NBUT_2022\n",
        "def compute_nbut(feature):\n",
        "    built_area = ee.Number(feature.get('built_up_area_km2'))\n",
        "    depto_area_km2 = feature.geometry().area().divide(1e6)\n",
        "    nbut = ee.Algorithms.If(\n",
        "        built_area.gt(0),\n",
        "        built_area.divide(depto_area_km2).multiply(1000),\n",
        "        0\n",
        "    )\n",
        "    return feature.set('NBUT_2022', nbut)\n",
        "\n",
        "# apply the function\n",
        "zonal_stats_nbut = zonal_stats_renamed.map(compute_nbut)"
      ],
      "metadata": {
        "id": "JlDx7cTCZlA5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to GeoDataFrame and extract desired columns\n",
        "gdf_nbut_2022 = geemap.ee_to_gdf(zonal_stats_nbut).round(2)\n",
        "df_nbut_2022 = gdf_nbut_2022[['IDDPTO', 'NBUT_2022']].round(2)"
      ],
      "metadata": {
        "id": "TjNg6-8rQXlS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vissualize data.frame\n",
        "init_notebook_mode(all_interactive=True)\n",
        "df_nbut_2022"
      ],
      "metadata": {
        "id": "P2WE6kCcQ45-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get basic statistics of data.frame\n",
        "init_notebook_mode(all_interactive=True)\n",
        "df_nbut_2022.describe()"
      ],
      "metadata": {
        "id": "pRbRxU5_5eDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####  Mapping the NBUT 2020-2022 in Cordoba Province\n",
        "\n",
        "We will create an interactive map to display df_nbut_2022 as a choropleth map and built_up_transition_masked image in Cordoba Province\n"
      ],
      "metadata": {
        "id": "yfHwhIQZeBeI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define color bins and values\n",
        "# bins = [0, 0.5, 1.0, 1.5, 2.0, 2.5]\n",
        "bins = [1.33, 1.93, 3.12, 4.53, 8.53,  14.08]\n",
        "# colors = [\"#fef0d9\", \"#fdcc8a\", \"#fc8d59\", \"#e34a33\", \"#b30000\"]\n",
        "colors =[\"#FDE725\", \"#FDE725\", \"#B8DE29\",  \"#5DC962\",  \"#21918C\", \"#440154\"]\n",
        "\n",
        "# Create a step colormap for legend\n",
        "colormap = cm.StepColormap(colors=colors, vmin=bins[0], vmax=bins[-1], index=bins,\n",
        "                           caption='Normalized Built-up Transitions (NBUT) 2020‚Äì2022 (/1000 km¬≤)')\n",
        "\n",
        "# Function to assign color to each feature based on NBUT_2022 value\n",
        "def get_color(nbut):\n",
        "    if nbut is None:\n",
        "        return 'gray'\n",
        "    for i in range(len(bins) - 1):\n",
        "        if bins[i] <= nbut < bins[i + 1]:\n",
        "            return colors[i]\n",
        "    return colors[-1]\n",
        "\n",
        "# Initialize map\n",
        "m = folium.Map(location=[-31.3, -64.2], zoom_start=7, control_scale=True)\n",
        "\n",
        "# Add the styled NBUT GeoJson layer\n",
        "folium.GeoJson(\n",
        "    gdf_nbut_2022,\n",
        "    name='NBUT 2020-2022 (Custom Choropleth)',\n",
        "    style_function=lambda feature: {\n",
        "        'fillColor': get_color(feature['properties']['NBUT_2022']),\n",
        "        'color': 'black',\n",
        "        'weight': 0.3,\n",
        "        'fillOpacity': 0.6,\n",
        "    },\n",
        "    tooltip=folium.GeoJsonTooltip(\n",
        "        fields=['IDDPTO', 'NBUT_2022'],\n",
        "        aliases=['Department ID:', 'NBUT (/1000 km¬≤):'],\n",
        "        localize=True\n",
        "    )\n",
        ").add_to(m)\n",
        "\n",
        "# Add the colormap legend\n",
        "colormap.add_to(m)\n",
        "\n",
        "# Add built-up transition raster in black\n",
        "vis_params_built_up = {\n",
        "    'min': 0,\n",
        "    'max': 1,\n",
        "    'palette': ['#ffffff00', '#000000']\n",
        "}\n",
        "map_id_dict_built_up = built_up_transition_masked.getMapId(vis_params_built_up)\n",
        "\n",
        "folium.raster_layers.TileLayer(\n",
        "    tiles=map_id_dict_built_up['tile_fetcher'].url_format,\n",
        "    attr='Earth Engine',\n",
        "    name='Built-up Transition Raster (Black)',\n",
        "    overlay=True,\n",
        "    control=True,\n",
        "    opacity=1\n",
        ").add_to(m)\n",
        "\n",
        "# Add layer control\n",
        "folium.LayerControl().add_to(m)"
      ],
      "metadata": {
        "id": "4DS5d-mLiNpv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# display the map\n",
        "m"
      ],
      "metadata": {
        "id": "p19aZFS6ixgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Computing the NBUT for all provinces (2020-2022)"
      ],
      "metadata": {
        "id": "IGivyveD2cJb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the shapefile to get province id list\n",
        "shapefile_path = 'pdt/asthma_mortality/data/shp/ar_prov_dpto.shp'\n",
        "gdf = gpd.read_file(shapefile_path)\n",
        "\n",
        "# Get unique values of IDPROV\n",
        "province_ids = gdf['IDPROV'].unique().tolist()\n",
        "\n",
        "print(province_ids)"
      ],
      "metadata": {
        "id": "W-Ij9SRk9Eul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load all province-department features\n",
        "all_dptos = ee.FeatureCollection(\"projects/ee-pdt/assets/argentina/ar_prov_dpto\")"
      ],
      "metadata": {
        "id": "wjOdxYmX83Do"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the built-up transition image\n",
        "built_up_transition = ee.Image(\"projects/ee-pdt/assets/dynamicworld/built_up_transition_2021_2022\")"
      ],
      "metadata": {
        "id": "GITF5tlZ9ROo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute area per pixel in km¬≤\n",
        "pixel_area_km2 = ee.Image.pixelArea().divide(1e6)"
      ],
      "metadata": {
        "id": "JFt2wt1o9RQ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List to store DataFrames from each province\n",
        "df_list = []"
      ],
      "metadata": {
        "id": "4bD2_8eE9RTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop through each province ID\n",
        "for prov_id in province_ids:\n",
        "    print(\"Processing province: \", prov_id)\n",
        "    # ilter departments by province\n",
        "    prov_dptos = all_dptos.filter(ee.Filter.eq('IDPROV', prov_id))\n",
        "\n",
        "    # Clip and mask the built-up transition image\n",
        "    built_up_masked = built_up_transition.clip(prov_dptos).selfMask()\n",
        "\n",
        "    # Multiply by pixel area to get built-up area in km¬≤\n",
        "    built_up_area_km2 = built_up_masked.multiply(pixel_area_km2).rename('built_up_km2')\n",
        "\n",
        "    # Zonal statistics: sum built-up area by department\n",
        "    zonal_stats = built_up_area_km2.reduceRegions(\n",
        "        collection=prov_dptos,\n",
        "        reducer=ee.Reducer.sum().unweighted(),\n",
        "        scale=10,\n",
        "        crs='EPSG:4326'\n",
        "    )\n",
        "\n",
        "    # Rename 'sum' to 'built_up_area_km2'\n",
        "    zonal_stats_renamed = zonal_stats.map(lambda f: f.set('built_up_area_km2', ee.Number(f.get('sum'))))\n",
        "\n",
        "    # Compute NBUT_2022\n",
        "    def compute_nbut(feature):\n",
        "        built_area = ee.Number(feature.get('built_up_area_km2'))\n",
        "        depto_area_km2 = feature.geometry().area().divide(1e6)\n",
        "        nbut = ee.Algorithms.If(\n",
        "            built_area.gt(0),\n",
        "            built_area.divide(depto_area_km2).multiply(1000),\n",
        "            0\n",
        "        )\n",
        "        return feature.set('NBUT_2022', nbut)\n",
        "\n",
        "    zonal_stats_nbut = zonal_stats_renamed.map(compute_nbut)\n",
        "\n",
        "    # Convert to GeoDataFrame and filter only required columns\n",
        "    gdf = geemap.ee_to_gdf(zonal_stats_nbut).round(2)\n",
        "    df = gdf[['IDDPTO', 'NBUT_2022']]\n",
        "\n",
        "    # Append to list\n",
        "    df_list.append(df)"
      ],
      "metadata": {
        "id": "ZwHI2x8x9RWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge all provincial data into one DataFrame\n",
        "df_nbut_2022_all = pd.concat(df_list, ignore_index=True)"
      ],
      "metadata": {
        "id": "DroEQMI59RZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize data.frame\n",
        "init_notebook_mode(all_interactive=True)\n",
        "df_nbut_2022_all"
      ],
      "metadata": {
        "id": "71zurNF29Rby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get basic info of the data.frame\n",
        "df_nbut_2022_all.info()"
      ],
      "metadata": {
        "id": "vUnDONtiEi00"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test if df_nbut_2022_all[\"NBUT_2022\"] for cordoba province is the same as df_nbut_2022[\"NBUT_2022\"]\n",
        "\n",
        "# Filter df_nbut_2022_all for Cordoba province (IDPROV = '14')\n",
        "df_nbut_2022_all_cordoba = df_nbut_2022_all[df_nbut_2022_all['IDDPTO'].str.startswith('14')]\n",
        "\n",
        "# Sort both dataframes by 'IDDPTO' to ensure comparison alignment\n",
        "df_nbut_2022_all_cordoba_sorted = df_nbut_2022_all_cordoba.sort_values(by='IDDPTO').reset_index(drop=True)\n",
        "df_nbut_2022_cordoba_sorted = df_nbut_2022.sort_values(by='IDDPTO').reset_index(drop=True)\n",
        "\n",
        "# Test if the 'NBUT_2022' columns are the same\n",
        "are_equal = (df_nbut_2022_all_cordoba_sorted['NBUT_2022'] == df_nbut_2022_cordoba_sorted['NBUT_2022']).all()\n",
        "\n",
        "print(f\"Are the 'NBUT_2022' values for Cordoba province the same?: {are_equal}\")"
      ],
      "metadata": {
        "id": "2vcpKYmoEsAu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Merge NBUT (2020-2022) with other features"
      ],
      "metadata": {
        "id": "_O0zBvQoMPV7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load geopackage with PM2.5, Burned areas and other datasets\n",
        "gdf = gpd.read_file(\"pdt/asthma_mortality/data/gpkg/tma_pm25_ba_pd_pdpm25_agrt_nwvt_nbut0020_2001_2022.gpkg\")"
      ],
      "metadata": {
        "id": "o-YKomvTMPV7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform a left merge, preserving all rows from gdf\n",
        "gdf_nbut_2022 = gdf.merge(df_nbut_2022_all, on='IDDPTO', how='left')"
      ],
      "metadata": {
        "id": "hIWTEFFLMPV8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize gdf\n",
        "init_notebook_mode(all_interactive=True)\n",
        "gdf_nbut_2022.head()"
      ],
      "metadata": {
        "id": "5q5EORsrMPV8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check dataframe shape\n",
        "gdf_nbut_2022.shape"
      ],
      "metadata": {
        "id": "jmcEIhAJMPV8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save dataset with NBUT (2005-2010) as other features as a gpkg file\n",
        "gdf_nbut_2022.to_file(\"pdt/asthma_mortality/data/gpkg/tma_pm25_ba_pd_pdpm25_agrt_nwvt_nbut_2001_2022.gpkg\", driver=\"GPKG\")"
      ],
      "metadata": {
        "id": "wKOhHGDyMPV9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}