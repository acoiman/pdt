{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPNifTGGcgpGBFGBa2NGs6e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/acoiman/pdt/blob/main/asthma_mortality/notebooks/Python/11.1.Asthma_Mortality_RF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸŒ³ Predicting Asthma Mortality Rate using Random Forest\n",
        "\n"
      ],
      "metadata": {
        "id": "kZxCQdAv7GPa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest (RF) is an ensemble learning method that combines the output of multiple individual decision trees to make more accurate and stable predictions. It can be used for both classification (predicting categories) and regression (predicting continuous numbers) tasks\n",
        "\n",
        "This notebook explores the use of  RF  to predict the Normalized Asthma Mortality Rate (NAMR) across departments in Argentina. By leveraging historical time series data from 2001 to 2021 and incorporating relevant environmental and demographic covariates, the objective is to estimate asthma mortality rate for 2022 and evaluate model performance using multiple error metrics.\n"
      ],
      "metadata": {
        "id": "rOOiBCQVn5JO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ“š Import required libraries"
      ],
      "metadata": {
        "id": "fXevDbl0GYZh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dataframe libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# geospatial libraries\n",
        "import geopandas as gpd\n",
        "import mapclassify\n",
        "from libpysal.weights import Queen\n",
        "from esda.moran import Moran\n",
        "from pysal.explore import esda\n",
        "\n",
        "# plot libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "import seaborn as sns\n",
        "from matplotlib.patches import Patch\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
        "\n",
        "# sklearn libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error,r2_score,explained_variance_score,median_absolute_error, max_error\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# other libraries\n",
        "import os\n",
        "from joblib import Parallel, delayed\n",
        "import shap\n",
        "from itables import init_notebook_mode, show"
      ],
      "metadata": {
        "id": "xBh05cJz7J5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd work/"
      ],
      "metadata": {
        "id": "o700iVYSRUAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the PROJ_LIB path\n",
        "os.environ['PROJ_LIB'] = \"/opt/conda/envs/gds/share/proj\""
      ],
      "metadata": {
        "id": "V2QSVvb5ODyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Copy-on-Write\n",
        " pd.options.mode.copy_on_write = True"
      ],
      "metadata": {
        "id": "ylT_ezz31xLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ðŸ—‚ Load and transform the dataset"
      ],
      "metadata": {
        "id": "7nTd59iUcTEh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset with data per department\n",
        "gdf = gpd.read_file(\"pdt/asthma_mortality/data/gpkg/data.gpkg\")"
      ],
      "metadata": {
        "id": "HzyMWFwMEP51"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape df to ts long format\n",
        "years = range(2001, 2023)\n",
        "records = []"
      ],
      "metadata": {
        "id": "JJuoJj3bRXVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# drop geometry and PDPM25\n",
        "for _, row in gdf.iterrows():\n",
        "    iddpto = row[\"IDDPTO\"]\n",
        "    for year in years:\n",
        "        records.append({\n",
        "            \"IDDPTO\": iddpto,\n",
        "            \"YEAR\": year,\n",
        "            \"CA\": row.get(f\"CA_{year}\", np.nan),\n",
        "            \"PM25\": row.get(f\"PM25_{year}\", np.nan),\n",
        "            \"NBA\": row.get(f\"NBA_{year}\", np.nan),\n",
        "            \"PD\": row.get(f\"PD_{year}\", np.nan),\n",
        "            \"NAGRT\": row.get(f\"NAGRT_{year}\", np.nan),\n",
        "            \"NNWVT\": row.get(f\"NNWVT_{year}\", np.nan),\n",
        "            \"NBUT\": row.get(f\"NBUT_{year}\", np.nan),\n",
        "            \"ELEV\": row.get(f\"ELEV_{year}\", np.nan)\n",
        "            })"
      ],
      "metadata": {
        "id": "XzklGh6KRgl0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create new df from list\n",
        "df_ts = pd.DataFrame(records)"
      ],
      "metadata": {
        "id": "q4pGW5oZSRAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create lag variables (up to 2 years)\n",
        "def create_lags(df, var, max_lag=2):\n",
        "    for lag in range(1, max_lag+1):\n",
        "        df[f\"{var}_lag{lag}\"] = df[var].shift(lag)\n",
        "    return df"
      ],
      "metadata": {
        "id": "92_ceUAgLQMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for var in [\"NAGRT\", \"NNWVT\", \"NBUT\"]:\n",
        "    df_ts = create_lags(df_ts, var)"
      ],
      "metadata": {
        "id": "EjUa_plZLTN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop the initial rows with NaNs due to lagging\n",
        "df_ts = df_ts.dropna().reset_index(drop=True)"
      ],
      "metadata": {
        "id": "D9CN00caLYmh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize the dataframe\n",
        "init_notebook_mode(all_interactive=True)\n",
        "show(df_ts)"
      ],
      "metadata": {
        "id": "vkw4BuxmVPF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ðŸ“ˆ Random Forest modelling"
      ],
      "metadata": {
        "id": "BRr5kM7MulAu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section we will train a RF model using data from 2001 to 2002 to predict NAMR (CA) in 2022"
      ],
      "metadata": {
        "id": "1-ftDhEpuoVK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split train  and test sets"
      ],
      "metadata": {
        "id": "MQDwoR-d35_N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split train (2001â€“2021) and test (2022)\n",
        "train = df_ts[(df_ts['YEAR'] >= 2001) & (df_ts['YEAR'] <= 2021)]\n",
        "test  = df_ts[df_ts['YEAR'] == 2022]"
      ],
      "metadata": {
        "id": "pP6VGbS2unvf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Select features (exclude IDDPTO, YEAR, and CA)\n",
        "exclude_cols = ['IDDPTO', 'YEAR', 'CA']\n",
        "features = [c for c in df_ts.columns if c not in exclude_cols]\n",
        "\n",
        "X_train = train[features]\n",
        "y_train = train['CA']\n",
        "X_test  = test[features]"
      ],
      "metadata": {
        "id": "RyaWKBBlvwgf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize feautes\n",
        "init_notebook_mode(all_interactive=True)\n",
        "X_train.head()"
      ],
      "metadata": {
        "id": "kDXSmttzvwtt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize feautes\n",
        "init_notebook_mode(all_interactive=True)\n",
        "y_train.head()"
      ],
      "metadata": {
        "id": "rA99K6R5vw3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize feautes\n",
        "init_notebook_mode(all_interactive=True)\n",
        "X_test.head()"
      ],
      "metadata": {
        "id": "UZGLMKZ00c65"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training RF"
      ],
      "metadata": {
        "id": "oms_2en64Cic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Random Forest with default hiperparameters\n",
        "rf = RandomForestRegressor(\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        ")\n",
        "rf.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "F4pSG6B_0dIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predicting NAMR for 2022"
      ],
      "metadata": {
        "id": "K-JAGZuK4RBc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict CA for 2022\n",
        "test['CA_2022_pred'] = rf.predict(X_test)"
      ],
      "metadata": {
        "id": "3rAD2qHe1Brw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Output predictions\n",
        "pred_2022 = test[['IDDPTO', 'YEAR', \"CA\", 'CA_2022_pred']]\n",
        "# rename \"CA\" to \"CA_2022\"\n",
        "pred_2022.rename(columns={'CA': 'CA_2022'}, inplace=True)"
      ],
      "metadata": {
        "id": "nGYeI08P1CAG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize pred_2022\n",
        "init_notebook_mode(all_interactive=True)\n",
        "show(pred_2022)"
      ],
      "metadata": {
        "id": "ZXhR9yS_0dQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluating model performance"
      ],
      "metadata": {
        "id": "t_JCavwp4IiR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# True vs Predicted vectors\n",
        "y_true = pred_2022['CA_2022'].values\n",
        "y_pred = pred_2022['CA_2022_pred'].values"
      ],
      "metadata": {
        "id": "2p_hVS9a3NS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Metrics\n",
        "MAE  = mean_absolute_error(y_true, y_pred)\n",
        "RMSE = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "R2 = r2_score(y_true, y_pred)"
      ],
      "metadata": {
        "id": "B7WcK7A14hE1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Model Performance on 2022 Prediction\")\n",
        "print(\"------------------------------------\")\n",
        "print(f\"MAE  : {MAE:.4f}\")\n",
        "print(f\"RMSE : {RMSE:.4f}\")\n",
        "print(f\"RÂ²   : {R2:.4f}\")"
      ],
      "metadata": {
        "id": "oTRBzw3J44fG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a scatterplot between CA_2022 vs CA_2022_Pred\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(pred_2022['CA_2022'], pred_2022['CA_2022_pred'])\n",
        "plt.xlabel('CA_2022 (Actual)')\n",
        "plt.ylabel('CA_2022_Pred (Predicted)')\n",
        "plt.title('Scatter Plot of Actual vs. Predicted Mortality Rates (2022)')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3i4MC26k0dV3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The evaluation metrics indicate that the Random Forest model has weak predictive performance for estimating asthma mortality rates in 2022.\n",
        "\n",
        "* A MAE of 1.61 and RMSE of 2.21 show that prediction errors are relatively large compared to the scale of the target variable.\n",
        "\n",
        "* The negative RÂ² (-0.08) indicates that the model performs worse than simply predicting the mean of CA for all departments.\n",
        "\n",
        "The scatter plot confirms this: predictions cluster in a narrow range (mostly between 1 and 2), while actual values span a much wider range, including many zeros and several high counts. This suggests that the model fails to capture variability, especially the zero-inflation and right tail, leading to underestimation of high values and overestimation of zeros.\n",
        "\n",
        "Overall, the model struggles with the distributional characteristics of the data, indicating the need for zero-inflated, two-stage (hurdle) models or alternative approaches better suited for sparse count-like outcomes."
      ],
      "metadata": {
        "id": "4rYIBOYV5Deo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  ðŸš§ Hurdle-type RF modelling\n",
        "\n",
        "Hurdle-type modeling is a statistical approach designed to analyze count data, particularly when there is an excess of zeros. This model operates in two stages: the first stage determines whether the count is zero or positive using a binary classification, while the second stage models only the positive counts, often employing a regression models.[1]"
      ],
      "metadata": {
        "id": "H4ScgRMXvSCR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part 1 â€“ RF Classification Model\n",
        "\n",
        "In this section, we will train and evaluate a Random Forest (RF) classification model to predict whether the Normalized Asthma Mortality Rate (NAMR, represented by the variable CA) indicates the nonoccurrence (0) or occurrence (1) of asthma mortality (binary classification). We will apply a walk-forward (expanding window) validation approach, which is appropriate for epidemiological studies involving time series data.[2] We will start by training the RF classification model using data from 2001 to 2006 (a 5-year window) and testing it with data from 2007. The training window will then be expanded by one year at each iteration until it spans from 2001 to 2021, with 2022 data used for testing.\n"
      ],
      "metadata": {
        "id": "FviPCsCgeazB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Loading and transforming the data"
      ],
      "metadata": {
        "id": "3wqHcRPCRzIq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Binary target\n",
        "df_ts['CA_bin'] = (df_ts['CA'] > 0).astype(int)"
      ],
      "metadata": {
        "id": "lZaN4hpWT8x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visusalize the dataframe\n",
        "init_notebook_mode(all_interactive=True)\n",
        "df_ts.head()"
      ],
      "metadata": {
        "id": "Y2fSO2FRThne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training and Testing a RF Classification Model"
      ],
      "metadata": {
        "id": "rmaljiP9yO9M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = []  # results list\n",
        "\n",
        "for i in range(2006, 2022):  # start walk-forward from year 2006 to 2021\n",
        "    train_years = list(range(2001, i + 1))  # expanding window\n",
        "    test_year = i + 1\n",
        "    print(f\"Training: {train_years[0]}â€“{train_years[-1]}, Testing: {test_year}\")\n",
        "\n",
        "    # Split train/test by year\n",
        "    train_df = df_ts[df_ts['YEAR'].isin(train_years)]\n",
        "    test_df = df_ts[df_ts['YEAR'] == test_year]\n",
        "\n",
        "    # Define features and target\n",
        "    features = ['PM25', 'NBA', 'PD', 'NAGRT', 'NNWVT', 'NBUT', 'ELEV',\n",
        "              'NAGRT_lag1', 'NAGRT_lag2', 'NNWVT_lag1', 'NNWVT_lag2',\n",
        "              'NBUT_lag1','NBUT_lag2']\n",
        "    target = 'CA_bin'\n",
        "\n",
        "    X_train = train_df[features]\n",
        "    y_train = train_df[target]\n",
        "    X_test = test_df[features]\n",
        "    y_test = test_df[target]\n",
        "\n",
        "    # Train classification model with default hiperparameters\n",
        "    model = RandomForestClassifier(n_jobs=-1, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predict (labels)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Classification metrics\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    prec = precision_score(y_test, y_pred, zero_division=0)\n",
        "    rec = recall_score(y_test, y_pred, zero_division=0)\n",
        "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
        "\n",
        "    # Store results\n",
        "    results.append({\n",
        "        'train_years': f\"{train_years[0]}-{train_years[-1]}\",\n",
        "        'test_year': test_year,\n",
        "        'Accuracy': acc,\n",
        "        'Precision': prec,\n",
        "        'Recall': rec,\n",
        "        'F1_Score': f1\n",
        "    })"
      ],
      "metadata": {
        "id": "QpzJKkrZf1CH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert results into a dataframe\n",
        "results_df = pd.DataFrame(results)"
      ],
      "metadata": {
        "id": "MfQ2YyQkdYMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize the results\n",
        "init_notebook_mode(all_interactive=True)\n",
        "results_df"
      ],
      "metadata": {
        "id": "PynMwBM8dYPy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate and display the mean and standard deviation for each evaluation metric\n",
        "mean_metrics = results_df[['Accuracy', 'Precision', 'Recall', 'F1_Score']].mean()\n",
        "std_metrics = results_df[['Accuracy', 'Precision', 'Recall', 'F1_Score']].std()\n",
        "\n",
        "print(\"Mean of Evaluation Metrics:\")\n",
        "print(mean_metrics)\n",
        "print(\"\\nStandard Deviation of Evaluation Metrics:\")\n",
        "print(std_metrics)"
      ],
      "metadata": {
        "id": "w4-M16ST0b5Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metric Value\tInterpretation\n",
        "* Accuracy\t0.770 Â± 0.014.\tOn average, the classifier correctly identified whether CA was 0 or 1 about 77 % Â± 1.4% of the time. This is decent but may be misleading if there is class imbalance (e.g., many zeros).\n",
        "* Precision\t0.664 Â±  0.032.\tOn average, of all the cases where the classifier predicted CA > 0, 66.4% Â± 3.2% were correct. Upper moderate precision means some false positives (it sometimes predicts CA as 1 when the true value is 0).\n",
        "* Recall 0.599 Â± 0.036.\tOn average, the model only identified 59.9%  Â± 3.6% of true CA > 0 cases .  So it's missing nearly a third of the true positives (false negatives are moderate).\n",
        "* F1 Score\t0.629 Â± 0.023.\tThe harmonic mean of precision and recall. This moderate value indicates a trade-off between missing positives and over-predicting them."
      ],
      "metadata": {
        "id": "_uxoPiB2_ktm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a plot of each metric by year:\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "for metric in ['Accuracy', 'Precision', 'Recall', 'F1_Score']:\n",
        "    ax.plot(results_df['test_year'], results_df[metric], marker='o', label=metric)\n",
        "\n",
        "ax.set_xlabel(\"Test Year\")\n",
        "ax.set_ylabel(\"Score\")\n",
        "ax.set_title(\"Walk-Forward Validation Metrics (2007â€“2022)\")\n",
        "ax.legend()\n",
        "ax.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5LYlT0zR6vkm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### RF Classification Model Parameter Tuning"
      ],
      "metadata": {
        "id": "K8PM_t-m3sV5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define hyperparameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200], # The number of trees in the forest\n",
        "    'max_depth': [None, 5, 10], # The maximum depth of the tree\n",
        "    'min_samples_split': [2, 5], # The minimum number of samples required to split an internal node\n",
        "    'min_samples_leaf': [1, 2] # The minimum number of samples required to be at a leaf node.\n",
        "}"
      ],
      "metadata": {
        "id": "Hq5yKReQdYU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = []  # clear results list before starting\n",
        "\n",
        "for i in range(2006, 2022):  # walk-forward from 2006 to 2021\n",
        "    train_years = list(range(2001, i + 1))  # expanding window\n",
        "    test_year = i + 1\n",
        "    print(f\"Training: {train_years[0]}â€“{train_years[-1]}, Testing: {test_year}\")\n",
        "\n",
        "    # Split train/test by year\n",
        "    train_df = df_ts[df_ts['YEAR'].isin(train_years)]\n",
        "    test_df = df_ts[df_ts['YEAR'] == test_year]\n",
        "\n",
        "    # Define features and target\n",
        "    features = ['PM25', 'NBA', 'PD', 'NAGRT', 'NNWVT', 'NBUT', 'ELEV',\n",
        "              'NAGRT_lag1', 'NAGRT_lag2', 'NNWVT_lag1', 'NNWVT_lag2',\n",
        "              'NBUT_lag1','NBUT_lag2']\n",
        "    target = 'CA_bin'\n",
        "\n",
        "    X_train = train_df[features]\n",
        "    y_train = train_df[target]\n",
        "    X_test = test_df[features]\n",
        "    y_test = test_df[target]\n",
        "\n",
        "    # Grid Search with 3-fold CV\n",
        "    grid_search = GridSearchCV(\n",
        "        estimator=RandomForestClassifier(random_state=42),\n",
        "        param_grid=param_grid,\n",
        "        scoring='recall',\n",
        "        cv=3,\n",
        "        n_jobs=-1,\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    best_model = grid_search.best_estimator_\n",
        "\n",
        "    # Predict on test set\n",
        "    y_pred = best_model.predict(X_test)\n",
        "\n",
        "    # Evaluation metrics\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    prec = precision_score(y_test, y_pred, zero_division=0)\n",
        "    rec = recall_score(y_test, y_pred, zero_division=0)\n",
        "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
        "\n",
        "    # Store results and best params\n",
        "    results.append({\n",
        "        'train_years': f\"{train_years[0]}-{train_years[-1]}\",\n",
        "        'test_year': test_year,\n",
        "        'Accuracy': acc,\n",
        "        'Precision': prec,\n",
        "        'Recall': rec,\n",
        "        'F1_Score': f1,\n",
        "        'Best_Params': grid_search.best_params_\n",
        "    })\n"
      ],
      "metadata": {
        "id": "4t-prDNhoXPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert results into a dataframe\n",
        "resultspt_df = pd.DataFrame(results)"
      ],
      "metadata": {
        "id": "4PnM-joGoXSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize dataframe\n",
        "init_notebook_mode(all_interactive=True)\n",
        "resultspt_df"
      ],
      "metadata": {
        "id": "5ROi0CWboXU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate and display the mean and standard deviation for each evaluation metric\n",
        "mean_metrics = resultspt_df[['Accuracy', 'Precision', 'Recall', 'F1_Score']].mean()\n",
        "std_metrics = resultspt_df[['Accuracy', 'Precision', 'Recall', 'F1_Score']].std()\n",
        "\n",
        "print(\"Mean of Evaluation Metrics:\")\n",
        "print(mean_metrics)\n",
        "print(\"\\nStandard Deviation of Evaluation Metrics:\")\n",
        "print(std_metrics)"
      ],
      "metadata": {
        "id": "o3rWzr_GdYXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metric Value\tInterpretation\n",
        "* Accuracy\t0.773 Â± 0.012.\tOn average, the classifier correctly identified whether CA was 0 or 1 about 77.3% Â± 1.2% of the time. This is decent but may be misleading if there is class imbalance (e.g., many zeros).\n",
        "* Precision\t0.667 Â±  0.039.\tOn average, of all the cases where the classifier predicted CA > 0, 66.4% Â± 3.9% were correct. Upper moderate precision means some false positives (it sometimes predicts CA as 1 when the true value is 0).\n",
        "* Recall 0.610 Â± 0.037.\tOn average, the model only identified 61%  Â± 3.7% of true CA > 0 cases .  So it's missing nearly a third of the true positives (false negatives are moderate).\n",
        "* F1 Score\t0.636 Â± 0.026.\tThe harmonic mean of precision and recall. This moderate value indicates a trade-off between missing positives and over-predicting them.\n",
        "\n",
        "Parameter tuning  improveed slightly model performance"
      ],
      "metadata": {
        "id": "VPs1WSjQ5ce5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a plot of each metric by year:\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "for metric in ['Accuracy', 'Precision', 'Recall', 'F1_Score']:\n",
        "    ax.plot(results_df['test_year'], resultspt_df[metric], marker='o', label=metric)\n",
        "\n",
        "ax.set_xlabel(\"Test Year\")\n",
        "ax.set_ylabel(\"Score\")\n",
        "ax.set_title(\"Walk-Forward Validation Metrics (2007â€“2022) with Parameter Tuning\")\n",
        "ax.legend()\n",
        "ax.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fVdR4PNC6_6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training RF Classification Model on 2001â€“2021 and Predict 2022\n",
        "\n",
        "In this section, for the SHAP analysis, we will train the RF classification model on data from 2001â€“2021 and predict, for 2022, whether the Normalized Asthma Mortality Rate (NAMR, represented by the variable CA) indicates nonoccurrence (0) or occurrence (1) of asthma mortality (binary classification)"
      ],
      "metadata": {
        "id": "N_J9hX8q8tYf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define features and target\n",
        "features = ['PM25', 'NBA', 'PD', 'NAGRT', 'NNWVT', 'NBUT', 'ELEV',\n",
        "            'NAGRT_lag1', 'NAGRT_lag2', 'NNWVT_lag1', 'NNWVT_lag2',\n",
        "            'NBUT_lag1','NBUT_lag2']\n",
        "target = 'CA_bin'"
      ],
      "metadata": {
        "id": "xCfO8HQYIfCU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training and test sets\n",
        "train_df = df_ts[df_ts['YEAR'] <= 2021].dropna(subset=features + [target])\n",
        "test_df = df_ts[df_ts['YEAR'] == 2022].dropna(subset=features + [target])"
      ],
      "metadata": {
        "id": "DLQ413_eMxIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define inputs\n",
        "X_train = train_df[features]\n",
        "y_train = train_df[target]\n",
        "\n",
        "# Keep IDDPTO in test set\n",
        "X_test_full = test_df[['IDDPTO'] + features+ ['CA_bin']].copy()\n",
        "y_test = test_df[target].reset_index(drop=True)"
      ],
      "metadata": {
        "id": "nW6WK0dUM3UK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fccd5750"
      },
      "source": [
        "# get the tuned hiperpameter of the training 2001-2021\n",
        "last_row_params = resultspt_df.iloc[-1]['Best_Params']\n",
        "formatted_params = str(last_row_params).replace(\"'\", \"\").replace(\":\", \"=\")\n",
        "print(formatted_params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model\n",
        "clf = RandomForestClassifier(max_depth= None, min_samples_leaf= 2, min_samples_split= 2, n_estimators= 100, random_state=42)\n",
        "clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "EshhB9FhM3Wq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict using only feature columns\n",
        "y_pred = clf.predict(X_test_full[features])\n",
        "\n",
        "#  Add prediction to test set with IDDPTO\n",
        "X_test_full['CA_bin_pred'] = y_pred"
      ],
      "metadata": {
        "id": "mLu3UpuzNiJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate prediction\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, zero_division=0)\n",
        "recall = recall_score(y_test, y_pred, zero_division=0)\n",
        "f1 = f1_score(y_test, y_pred, zero_division=0)\n",
        "\n",
        "# Print metrics\n",
        "print(f\"Prediction Results for 2022:\")\n",
        "print(f\"Accuracy:  {accuracy:.3f}\")\n",
        "print(f\"Precision: {precision:.3f}\")\n",
        "print(f\"Recall:    {recall:.3f}\")\n",
        "print(f\"F1 Score:  {f1:.3f}\")"
      ],
      "metadata": {
        "id": "4a-0Ox1HM3Zq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metric Value\tInterpretation\n",
        "* Accuracy\t0.765:\tThe classifier correctly predicted whether CA was 0 or 1 in 2022 in about 76.5% of the time. This is decent but may be misleading if there is class imbalance (e.g., many zeros).\n",
        "* Precision\t0.669:\tOf all the cases where the classifier predicted CA > 0 in 2022, 66.9 % were correct. This precision means a few false positives (it sometimes predicts CA as 1 when the true value is 0).\n",
        "* Recall 0.582:\tThe model only identified 58.2%  of true CA > 0 cases.  So it's missing nearly a third of the true positives (false negatives are high).\n",
        "* F1 Score\t0.623:\tThe harmonic mean of precision and recall. This moderate value indicates a trade-off between missing positives and over-predicting them."
      ],
      "metadata": {
        "id": "pobVGpCMnkTW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preserve only IDDPTO, CA_bin, and CA_bin_pred from X_test_full\n",
        "bin_pred_result = X_test_full[['IDDPTO', 'CA_bin', 'CA_bin_pred']].copy()"
      ],
      "metadata": {
        "id": "3dxD1PjhNpoy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the new DataFrame\n",
        "init_notebook_mode(all_interactive=True)\n",
        "show(bin_pred_result)"
      ],
      "metadata": {
        "id": "MS4qUKc1IfFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### SHAP (SHapley Additive Explanations)\n",
        "\n",
        "In this section we will interpret the contribution of each independent variable to the final predition of the RF classification model using the SHAP method"
      ],
      "metadata": {
        "id": "OlZzuaJVYLwG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SHAP for Binary Classifier\n",
        "# Use TreeExplainer (optimized for RandomForest)\n",
        "explainer = shap.TreeExplainer(clf)"
      ],
      "metadata": {
        "id": "6hQEBSfmYLwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get the test set\n",
        "X = test_df[features]"
      ],
      "metadata": {
        "id": "BhlFOlbFYLwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to compute SHAP values for a single row\n",
        "def compute_shap(row):\n",
        "    return explainer.shap_values(row)"
      ],
      "metadata": {
        "id": "QMfvgKByYLwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parallel computation\n",
        "shap_values_list = Parallel(n_jobs=-1)(\n",
        "    delayed(compute_shap)(X.iloc[[i]]) for i in range(len(X))\n",
        ")"
      ],
      "metadata": {
        "id": "ecmEZI2uYLwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine SHAP values for Class 1 into a single array\n",
        "shap_values = np.vstack([vals[0][:, 1] for vals in shap_values_list])  # Class 1 SHAPs\n"
      ],
      "metadata": {
        "id": "mt1gWliX1oeR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a SHAP summary plot to visualize the impact of features on the model's predictions\n",
        "shap.summary_plot(shap_values, X, feature_names=features,\n",
        "                  show= False, cmap = \"plasma\")\n",
        "plt.title(\"(a) SHAP Summary Plot RF Classification\", fontsize=17)\n",
        "plt.xlabel(\"SHAP Values\", size=12)\n",
        "plt.ylabel(\"Features\", size=12)\n",
        "plt.ylabel(\"Features\")\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "nMXc1dX2YLwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The SHAP summary plot shows that no predictor has a strong, consistent influence on the Random Forest classifier. Most SHAP values cluster tightly around zero, indicating weak contributions to predicting asthma mortality occurrence. Population density (PD) shows the widest spread, suggesting it has the most variable effect, while elevation (ELEV), NBUT, NNWVT, and their lagged versions have only small, mixed impacts. Overall, the model relies on many features with low predictive power, aligning with the modest classification performance observed."
      ],
      "metadata": {
        "id": "uufpTZt8fa-v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Part 2 â€“ Regression Model\n",
        "\n",
        "\n",
        "In this section, we will train and evaluate a Random Forest (RF) regression model to predict NAMR values where it is present  (CA_bin == 1 or NAMR values > 0). We will apply a walk-forward (expanding window) validation approach, which is appropriate for epidemiological studies involving time series dataÂ¹. We will start by training the RF regression model using data from 2001 to 2006 (a 5-year window) and testing it with data from 2007. The training window will then be expanded by one year at each iteration until it spans from 2001 to 2021, with 2022 data used for testing."
      ],
      "metadata": {
        "id": "J_uk1xOhj-1W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter bin_pred_result to keep only rows where CA_bin is 1\n",
        "bin_positive = df_ts[(df_ts['CA_bin'] == 1)]"
      ],
      "metadata": {
        "id": "rTQprraPNtWW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the filtered DataFrame\n",
        "init_notebook_mode(all_interactive=True)\n",
        "show(bin_positive)"
      ],
      "metadata": {
        "id": "w7c0-86ZRh04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training and Testing a RF Regression Model"
      ],
      "metadata": {
        "id": "duzZd-SCVJ-y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = []  # store results\n",
        "\n",
        "for i in range(2006, 2022):  # walk-forward from 2006 to 2021\n",
        "    train_years = list(range(2001, i + 1))  # expanding window\n",
        "    test_year = i + 1\n",
        "    print(f\"Training: {train_years[0]}â€“{train_years[-1]}, Testing: {test_year}\")\n",
        "\n",
        "    # Filter by year\n",
        "    train_df = df_ts[df_ts['YEAR'].isin(train_years)]\n",
        "    test_df = df_ts[df_ts['YEAR'] == test_year]\n",
        "\n",
        "    # Filter by CA_bin == 1\n",
        "    train_pos = train_df[train_df['CA_bin'] == 1].copy()\n",
        "    test_pos = test_df[test_df['CA_bin'] == 1].copy()\n",
        "\n",
        "    # Skip iteration if empty (avoid errors)\n",
        "    if train_pos.empty or test_pos.empty:\n",
        "        print(f\"Skipped: No positive cases in train or test for {test_year}\")\n",
        "        continue\n",
        "\n",
        "    # Features and regression target\n",
        "    features = ['PM25', 'NBA', 'PD', 'NAGRT', 'NNWVT', 'NBUT', 'ELEV',\n",
        "                'NAGRT_lag1', 'NAGRT_lag2', 'NNWVT_lag1', 'NNWVT_lag2',\n",
        "                'NBUT_lag1','NBUT_lag2']\n",
        "    target = 'CA'  # regression target\n",
        "\n",
        "    X_train = train_pos[features]\n",
        "    y_train = train_pos[target]\n",
        "    X_test = test_pos[features]\n",
        "    y_test = test_pos[target]\n",
        "\n",
        "    # Train regression model with default hiperparameters\n",
        "    model = RandomForestRegressor(n_jobs=-1, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predict and evaluate\n",
        "    y_pred = model.predict(X_test)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
        "\n",
        "    # Save results\n",
        "    results.append({\n",
        "        'train_years': f\"{train_years[0]}-{train_years[-1]}\",\n",
        "        'test_year': test_year,\n",
        "        'MAE': mae,\n",
        "        'RMSE': rmse,\n",
        "        'R2': r2\n",
        "    })\n"
      ],
      "metadata": {
        "id": "LdBXM7ufM6h8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert the results into a data frame\n",
        "results_df = pd.DataFrame(results)"
      ],
      "metadata": {
        "id": "qOfocX5nM6lW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "init_notebook_mode(all_interactive=True)\n",
        "results_df"
      ],
      "metadata": {
        "id": "iGmRLJLdM6oL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate and display the mean and standard deviation for each evaluation metric\n",
        "mean_metrics = results_df[['R2', \"MAE\", \"RMSE\"]].mean()\n",
        "std_metrics = results_df[['R2', \"MAE\", \"RMSE\"]].std()\n",
        "\n",
        "print(\"Mean of Evaluation Metrics:\")\n",
        "print(mean_metrics)\n",
        "print(\"\\nStandard Deviation of Evaluation Metrics:\")\n",
        "print(std_metrics)"
      ],
      "metadata": {
        "id": "ifYW4mpfM6q8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The evaluation metrics indicate that the Random Forest regression model achieves moderate predictive performance, with a mean RÂ² of 0.45  Â± 0.13, suggesting it explains roughly half of the variance in asthma mortality across departments. The average errors are relatively low in magnitude (MAE â‰ˆ 1.38  Â± 0.17 deaths, RMSE â‰ˆ 2.06  Â±  0.33 deaths), but the gap between MAE and RMSE shows that some departments experience larger residual errors. The standard deviationsâ€”particularly for RÂ² (~0.14)â€”suggest notable variability across folds, meaning the modelâ€™s performance is somewhat inconsistent depending on the trainingâ€“testing split. Overall, the model captures meaningful patterns but shows instability and room for improvement, especially in predicting extreme mortality values or highly heterogeneous departments."
      ],
      "metadata": {
        "id": "ZrycQ4XqSdJ4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RF Regression Model Parameter Tuning"
      ],
      "metadata": {
        "id": "8lyO1cGFX0kc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define feature list and hyperparameter grid\n",
        "features = ['PM25', 'NBA', 'PD', 'NAGRT', 'NNWVT', 'NBUT', 'ELEV',\n",
        "                'NAGRT_lag1', 'NAGRT_lag2', 'NNWVT_lag1', 'NNWVT_lag2',\n",
        "                'NBUT_lag1','NBUT_lag2']\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200], # The number of trees in the forest\n",
        "    'max_depth': [None, 10], # The maximum depth of the tree. I\n",
        "    'min_samples_leaf': [1, 2] # The minimum number of samples required to be at a leaf node\n",
        "}"
      ],
      "metadata": {
        "id": "3GApD5twUvUY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "\n",
        "for i in range(2006, 2022):  # walk-forward from 2006 to 2021\n",
        "    train_years = list(range(2001, i + 1))\n",
        "    test_year = i + 1\n",
        "    print(f\"Training: {train_years[0]}â€“{train_years[-1]}, Testing: {test_year}\")\n",
        "\n",
        "    # Filter by year\n",
        "    train_df = df_ts[df_ts['YEAR'].isin(train_years)]\n",
        "    test_df = df_ts[df_ts['YEAR'] == test_year]\n",
        "\n",
        "    # Filter to CA_bin == 1\n",
        "    train_pos = train_df[train_df['CA_bin'] == 1].copy()\n",
        "    test_pos = test_df[test_df['CA_bin'] == 1].copy()\n",
        "\n",
        "    # Skip if empty\n",
        "    if train_pos.empty or test_pos.empty:\n",
        "        print(f\"Skipped: No positive cases in train or test for {test_year}\")\n",
        "        continue\n",
        "\n",
        "    X_train = train_pos[features]\n",
        "    y_train = train_pos['CA']\n",
        "    X_test = test_pos[features]\n",
        "    y_test = test_pos['CA']\n",
        "\n",
        "    # Grid search for best model\n",
        "    grid_search = GridSearchCV(\n",
        "        estimator=RandomForestRegressor(random_state=42),\n",
        "        param_grid=param_grid,\n",
        "        scoring='r2',\n",
        "        cv=3,\n",
        "        n_jobs=-1,\n",
        "        verbose=0\n",
        "    )\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    best_model = grid_search.best_estimator_\n",
        "\n",
        "    # Predict and evaluate\n",
        "    y_pred = best_model.predict(X_test)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
        "\n",
        "    # Store result\n",
        "    results.append({\n",
        "        'train_years': f\"{train_years[0]}-{train_years[-1]}\",\n",
        "        'test_year': test_year,\n",
        "        'MAE': mae,\n",
        "        'RMSE': rmse,\n",
        "        'R2': r2,\n",
        "        'Best_Params': grid_search.best_params_\n",
        "    })"
      ],
      "metadata": {
        "id": "_6lppZxRUvWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert results into a dataframe\n",
        "resultspt_df = pd.DataFrame(results)"
      ],
      "metadata": {
        "id": "mbG3URuzZHRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize dataframe\n",
        "init_notebook_mode(all_interactive=True)\n",
        "resultspt_df"
      ],
      "metadata": {
        "id": "AoJz4U8vZHRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate and display the mean and standard deviation for each evaluation metric\n",
        "mean_metrics = results_df[['R2', \"MAE\", \"RMSE\"]].mean()\n",
        "std_metrics = results_df[['R2', \"MAE\", \"RMSE\"]].std()\n",
        "\n",
        "print(\"Mean of Evaluation Metrics:\")\n",
        "print(mean_metrics)\n",
        "print(\"\\nStandard Deviation of Evaluation Metrics:\")\n",
        "print(std_metrics)"
      ],
      "metadata": {
        "id": "nOsJ5n5mUvc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "On average, parameter tuning did not improve the modelâ€™s performance. However, for the 2001â€“2021 training period, it did lead to better results. Therefore, we will use the tuned parameters in the next section."
      ],
      "metadata": {
        "id": "kaZUQ3xLZ26j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training RF Regression Model on 2001â€“2021 and Predict 2022\n",
        "\n",
        "In this section, for the SHAP analysis and mapping, we will train the RF regression model on data from 2001â€“2021 and predict the 2022 Normalized Asthma Mortality Rate in departments where it is present (CA_bin = 1 or NAMR > 0)."
      ],
      "metadata": {
        "id": "XSH3VX7XaiU_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define features and target\n",
        "features = ['PM25', 'NBA', 'PD', 'NAGRT', 'NNWVT', 'NBUT', 'ELEV',\n",
        "                'NAGRT_lag1', 'NAGRT_lag2', 'NNWVT_lag1', 'NNWVT_lag2',\n",
        "                'NBUT_lag1','NBUT_lag2']\n",
        "target = 'CA'"
      ],
      "metadata": {
        "id": "gZmdPCBuZvnF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare training and test sets\n",
        "train_df = df_ts[df_ts['YEAR'] <= 2021].dropna(subset=features + [target])\n",
        "test_df = df_ts[df_ts['YEAR'] == 2022].dropna(subset=features + [target])"
      ],
      "metadata": {
        "id": "D597ptEDhuPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter for positive cases (CA_bin == 1)\n",
        "train_pos = train_df[train_df['CA_bin'] == 1].copy()\n",
        "test_pos = test_df[test_df['CA_bin'] == 1].copy()"
      ],
      "metadata": {
        "id": "xo1D6UAuhuRg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define inputs\n",
        "X_train = train_pos[features]\n",
        "y_train = train_pos[target]"
      ],
      "metadata": {
        "id": "h5EOUUvBhuUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Keep IDDPTO and make prediction-ready copy\n",
        "X_test_full = test_pos[['IDDPTO'] + features + [target]].copy()\n",
        "X_test = X_test_full[features]\n",
        "y_test = test_pos[target].reset_index(drop=True)"
      ],
      "metadata": {
        "id": "2fodtm3EhuW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get the tuned hiperpameter of the training 2001-2021\n",
        "last_row_params = resultspt_df.iloc[-1]['Best_Params']\n",
        "formatted_params = str(last_row_params).replace(\"'\", \"\").replace(\":\", \"=\")\n",
        "print(formatted_params)"
      ],
      "metadata": {
        "id": "9mi_N436lEIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train regression model\n",
        "reg = RandomForestRegressor(max_depth= 10, min_samples_leaf= 2, n_estimators= 200, n_jobs=-1, random_state=42)\n",
        "reg.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "0K-50v7lhuZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict using feature columns\n",
        "y_pred = reg.predict(X_test)"
      ],
      "metadata": {
        "id": "1S3MTF3uh6Ev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Store prediction in column CA_pred\n",
        "X_test_full['CA_pred'] = y_pred"
      ],
      "metadata": {
        "id": "fFXsy3UBh6HN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "rmse = mean_squared_error(y_test, y_pred, squared=False)"
      ],
      "metadata": {
        "id": "L_ouKt8ZcPUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print evaluation\n",
        "print(\"Prediction Results for 2022:\")\n",
        "print(f\"RÂ²: {r2:.3f}, MAE: {mae:.3f}, RMSE: {rmse:.3f}\")"
      ],
      "metadata": {
        "id": "HXj1T1aah6KE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metric Value\tInterpretation:\n",
        "\n",
        "The Random Forest regression model trained only on positive asthma mortality\n",
        "cases (CA_bin = 1) achieved a  RÂ² of 0.636. The model explains about 63.6% of the variability in asthma mortality among departments where mortality actually occurred. This indicates good predictive capacity in estimating asthma mortality rates in 2022."
      ],
      "metadata": {
        "id": "OIPxOOvtkce6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# select IDDPTO, CA and CA_pred from X_test_full\n",
        "reg_pred_result = X_test_full[['IDDPTO', 'CA', 'CA_pred']].copy()"
      ],
      "metadata": {
        "id": "eGCQ6OEKjXB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize the reults\n",
        "init_notebook_mode(all_interactive=True)\n",
        "reg_pred_result"
      ],
      "metadata": {
        "id": "dt5jRqFYh6M1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a scatterplot between CA_2022 vs CA_2022_Pred\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(reg_pred_result['CA'], reg_pred_result['CA_pred'])\n",
        "plt.xlabel('CA_2022 (Actual)')\n",
        "plt.ylabel('CA_2022_Pred (Predicted)')\n",
        "plt.title('Scatter Plot of Actual vs. Predicted Mortality Rates (2022)')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CJ9KDm4RdUOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Although the model underestimates high mortality and overestimates low mortality, the RF regression model trained on NAMR > 0 captures the true distribution of asthma mortality more accurately than the model trained on the full dataset."
      ],
      "metadata": {
        "id": "zKwEuiRkgbTO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SHAP (SHapley Additive Explanations)\n",
        "\n",
        "In this section we will interpret the contribution of each independent variable to the final predition of the RF regression model using the SHAP method"
      ],
      "metadata": {
        "id": "8WJTv7uN8Xgj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SHAP for Regression\n",
        "# Use TreeExplainer (optimized for RandomForest)\n",
        "explainer = shap.TreeExplainer(reg)\n",
        "\n",
        "# get test set\n",
        "X = test_pos[features]\n",
        "\n",
        "# Function to compute SHAP values for a single row\n",
        "def compute_shap(row):\n",
        "    # For regression, shap_values returns a single 1D array\n",
        "    return explainer.shap_values(row)\n",
        "\n",
        "# Parallel computation (adjust n_jobs as needed)\n",
        "shap_values_list = Parallel(n_jobs=-1)(\n",
        "    delayed(compute_shap)(X.iloc[[i]]) for i in range(len(X))\n",
        ")\n",
        "\n",
        "# Stack the 1D SHAP value arrays vertically\n",
        "# No need to index [:, 1] as there's only one set of SHAP values for regression\n",
        "shap_values = np.vstack(shap_values_list)"
      ],
      "metadata": {
        "id": "yfQ6RYfoL6_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a SHAP summary plot to visualize the impact of features on the model's predictions\n",
        "shap.summary_plot(shap_values, X, feature_names=features,\n",
        "                  show= False,  cmap = \"plasma\")\n",
        "plt.title(\"(b) SHAP Summary Plot RF Regression\", fontsize=17)\n",
        "plt.xlabel(\"SHAP Values\", size=12)\n",
        "plt.ylabel(\"Features\", size=12)\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "zSPXIag7Kg3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We observe low PD values were associated with higher predicted NAMR in the regression model. This may reflect limited access to healthcare services and larger emergency response times in sparsely populated areas [3]. Rural areas often have limited access to healthcare facilities and professionals, which can delay diagnosis and treatment, leading to higher mortality rates[4]. However, it could also be influenced by the â€˜small countsâ€™ issue common in epidemiological studies, where low population numbers lead to unstable or unreliable rate estimates. [5]"
      ],
      "metadata": {
        "id": "5WCDvBAl2bm3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸŒ Mapping actual vs predicted asthma mortality rate\n",
        "\n",
        "As explained above, since our dataset contains a high proportion of zero values, we will map the predicted NAMR for 2022 only in departments where the actual values are greater than zero. Departments with an actual NAMR value of zero will retain a predicted value of zero."
      ],
      "metadata": {
        "id": "ATMk6nJjNlKG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparing data for mapping"
      ],
      "metadata": {
        "id": "wsxmUbI9iEDT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from df_ts get filter 2022 and CA_bin equal to 0\n",
        "dpto_zero = df_ts[df_ts['YEAR'] == 2022]\n",
        "dpto_zero = dpto_zero[dpto_zero['CA_bin'] == 0]"
      ],
      "metadata": {
        "id": "xi0gg34miIcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# keep IDDPTO and CA_bin columns\n",
        "dpto_zero = dpto_zero[['IDDPTO', 'CA_bin']]"
      ],
      "metadata": {
        "id": "VxVGoBgxiIcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# rename CA_bin to CA and copy the column as CA_pred\n",
        "dpto_zero.rename(columns={'CA_bin': 'CA'}, inplace=True)\n",
        "dpto_zero['CA_pred'] = dpto_zero['CA'].copy()"
      ],
      "metadata": {
        "id": "BedfgYi9izSK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize dataframe\n",
        "init_notebook_mode(all_interactive=True)\n",
        "show(dpto_zero)"
      ],
      "metadata": {
        "id": "yizqYqwoiIcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get df info\n",
        "dpto_zero.info()"
      ],
      "metadata": {
        "id": "unDLUU-UjLfP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# concat reg_pred_result with dpto_zero\n",
        "df_concat = pd.concat([reg_pred_result, dpto_zero])"
      ],
      "metadata": {
        "id": "zQRQxD5wjhMy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get df info\n",
        "df_concat.info()"
      ],
      "metadata": {
        "id": "6z_JN0oujha6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize dataframe\n",
        "init_notebook_mode(all_interactive=True)\n",
        "show(df_concat)"
      ],
      "metadata": {
        "id": "Lf-Uk6CDkPkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset with data per department\n",
        "gdf = gpd.read_file(\"pdt/asthma_mortality/data/gpkg/data.gpkg\")"
      ],
      "metadata": {
        "id": "udrByK-rkPnj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# keep IDDPTO and geometry of the gdf\n",
        "dpto_geom = gdf[['IDDPTO', 'geometry']]"
      ],
      "metadata": {
        "id": "U3Ezn0G9kRU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# merge df_concat and dpto_geom by IDDPTO preserve  df_concat data\n",
        "df_map = pd.merge(df_concat, dpto_geom, on='IDDPTO', how='left')"
      ],
      "metadata": {
        "id": "t832QFA7kRuD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# rename CA as CA_2022 and CA_pred as CA_2022_PRED\n",
        "df_map.rename(columns={'CA': 'CA_2022', 'CA_pred': 'CA_2022_PRED'}, inplace=True)"
      ],
      "metadata": {
        "id": "_qx1yeAamcKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# round CA_2022_PRED to two decimal places\n",
        "df_map['CA_2022_PRED'] = df_map['CA_2022_PRED'].round(2)"
      ],
      "metadata": {
        "id": "i-38Rg4snI5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert df_map to a gdf\n",
        "gdf_map = gpd.GeoDataFrame(df_map, geometry='geometry')"
      ],
      "metadata": {
        "id": "fkncrTETnral"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize geodataframe\n",
        "init_notebook_mode(all_interactive=True)\n",
        "show(gdf_map)"
      ],
      "metadata": {
        "id": "H5bM-ZZdlqtq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save df_map as gpkg file\n",
        "gdf_map.to_file(\"pdt/asthma_mortality/data/gpkg/results_RF.gpkg\", driver=\"GPKG\")"
      ],
      "metadata": {
        "id": "MemjyiM3VyWh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculate classification schema for mapping"
      ],
      "metadata": {
        "id": "clFu3h07LM8w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use [Pysal](https://pysal.org/)'s [mapclassify](https://pysal.org/mapclassify/index.html) library to determine the best classifier for the choropleth map.\n",
        "\n",
        "We will use the map classifier with the best ACDM (mean Absolute Deviation Around the class Median). In Pysal, ACDM refers to the mean absolute deviation around the class median. It is a measure of a classifier's fit to the data, specifically by evaluating the average distance between each data point and the median value of the assigned class."
      ],
      "metadata": {
        "id": "_vR6QhT5MSgU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# open results_RF.gpkg as a gdf\n",
        "df_cl = gpd.read_file(\"pdt/asthma_mortality/data/gpkg/results_RF.gpkg\")"
      ],
      "metadata": {
        "id": "dLVaBhNCn-ux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize the dataframe\n",
        "init_notebook_mode(all_interactive=True)\n",
        "show(df_cl)"
      ],
      "metadata": {
        "id": "WAtE2YAvX6__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get df basic info\n",
        "df_cl.info()"
      ],
      "metadata": {
        "id": "RfWbAYX4N9N8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the length of the dataframe 'df_cl'\n",
        "len(df_cl)"
      ],
      "metadata": {
        "id": "g0F-jKiQNxvV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select data to analize\n",
        "selected_data = df_cl.loc[:,[\"CA_2022\", \"CA_2022_PRED\"]]"
      ],
      "metadata": {
        "id": "8mOWh83wMtb9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classify the data into 4 quantile groups\n",
        "q4 = mapclassify.Quantiles(selected_data, k=4)\n",
        "q4"
      ],
      "metadata": {
        "id": "xaxBNjrgM8wd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Equal Interval Classification\n",
        "ei5 = mapclassify.EqualInterval(selected_data, k=5)\n",
        "ei5"
      ],
      "metadata": {
        "id": "1OSGjbdRNepG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classify the data into groups based on the head/tail breaks algorithm\n",
        "ht = mapclassify.HeadTailBreaks(selected_data)\n",
        "ht"
      ],
      "metadata": {
        "id": "LdJq40eONexG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MaximumBreaks classification method\n",
        "mb5 = mapclassify.MaximumBreaks(selected_data, k=5)\n",
        "mb5"
      ],
      "metadata": {
        "id": "_4svptQ_Nezr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the Standard Deviation and Mean classification method to the selected data.\n",
        "msd = mapclassify.StdMean(selected_data)\n",
        "msd"
      ],
      "metadata": {
        "id": "Nc0MZ-vdNe2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply Fisher-Jenks classification with 5 classes\n",
        "fj5 = mapclassify.FisherJenks(selected_data, k=5)\n",
        "fj5"
      ],
      "metadata": {
        "id": "MJ-oXygNObrk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ACDM(mean Absolute Deviation Around the class Median) visualization"
      ],
      "metadata": {
        "id": "umQ-3FECNNXz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bunch classifier objects\n",
        "class5 = q4, ei5, ht, mb5, msd, fj5\n",
        "# Collect ADCM for each classifier\n",
        "fits = np.array([c.adcm for c in class5])\n",
        "# Convert ADCM scores to a DataFrame\n",
        "adcms = pd.DataFrame(fits)\n",
        "# Add classifier names\n",
        "adcms[\"classifier\"] = [c.name for c in class5]\n",
        "# Add column names to the ADCM\n",
        "adcms.columns = [\"ADCM\", \"Classifier\"]\n",
        "ax = sns.barplot(\n",
        "    y=\"Classifier\", x=\"ADCM\", data=adcms, hue= adcms[\"Classifier\"],  legend=False\n",
        ")\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "2ksylA_zG8VN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create choropleth maps"
      ],
      "metadata": {
        "id": "MsI6Mtjcl85R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Two classifiers have the lowest ACDM: FisherJenks and HeadTailBreaks. We'll select FisherJenks as the classifier to create the choropleth maps."
      ],
      "metadata": {
        "id": "EXSn0psmO5kU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the bins to a list for further processing\n",
        "bins = fj5.bins.tolist()\n",
        "bins"
      ],
      "metadata": {
        "id": "Qa6eGH-RO4_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# insert 0 at 0 position\n",
        "bins.insert(0, 0.0)\n",
        "bins"
      ],
      "metadata": {
        "id": "e1qlFA1NRF6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use the bins calculated during the EDA of the target variable using the full time series (2001â€“2022), as this approach captures the entire variability of the target."
      ],
      "metadata": {
        "id": "M-7NBejUlPvq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# bins from EDA of the target variable NAMR by department (choropleth map)\n",
        "bins = [0.0, 1.15, 3.83, 7.97, 14.81, 39.02]"
      ],
      "metadata": {
        "id": "-lJTCGeRgMdH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a custom classification using UserDefined for actual values\n",
        "classi_actual = mapclassify.UserDefined(df_cl[\"CA_2022\"], bins)"
      ],
      "metadata": {
        "id": "G8I-KbzeRNQS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a custom classification using UserDefined for predicted values\n",
        "classi_pred = mapclassify.UserDefined(df_cl[\"CA_2022_PRED\"], bins)"
      ],
      "metadata": {
        "id": "0pRkvgeeiZE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(12, 8))\n",
        "fig.subplots_adjust(hspace=0, wspace=-0.9)\n",
        "plt.suptitle('Normalized Asthma Mortality Rate 2022', fontsize=14, y=1)\n",
        "\n",
        "# Plot classi_actual\n",
        "classi_actual.plot(\n",
        "    df_cl,\n",
        "    legend=False,  # We'll build it manually\n",
        "    axis_on=False,\n",
        "    border_color='black',\n",
        "    cmap=\"viridis_r\",\n",
        "    ax=axes[0]\n",
        ")\n",
        "\n",
        "# Plot classi_pred\n",
        "classi_pred.plot(\n",
        "    df_cl,\n",
        "    legend=False,  # We'll build it manually\n",
        "    axis_on=False,\n",
        "    border_color='black',\n",
        "    cmap=\"viridis_r\",\n",
        "    ax=axes[1]\n",
        ")\n",
        "\n",
        "\n",
        "# Custom bin labels and colors\n",
        "#bin_labels = [\"0.00\", \"0.00-0.65\", \"0.65-2.16\", \"2.16-4.13\", \"4.13-7.49\", \"7.49-14.15\"]\n",
        "bin_labels = [\"0.00\", \"0-1.15\", \"1.15-3.83\", \"3.83-7.97\", \"7.97-14.81\", \"14.81-39.02\"]\n",
        "n_bins = len(bin_labels)\n",
        "# cmap = mpl.cm.get_cmap(\"viridis_r\", n_bins)\n",
        "cmap = mpl.colormaps.get_cmap(\"viridis_r\").resampled(n_bins)\n",
        "colors = [mpl.colors.to_hex(cmap(i)) for i in range(cmap.N)]\n",
        "\n",
        "# Create legend patches for bins\n",
        "bin_patches = [Patch(facecolor=color, edgecolor='black', label=label)\n",
        "               for color, label in zip(colors, bin_labels)]\n",
        "\n",
        "\n",
        "# Combine all patches\n",
        "all_patches = bin_patches\n",
        "\n",
        "# Display custom legend\n",
        "#axes[0].legend(handles=all_patches, loc='upper right', bbox_to_anchor=(1.1, 0.4), fontsize=8)\n",
        "axes[1].legend(handles=all_patches, loc='upper right', bbox_to_anchor=(0.9, 0.25), fontsize=10)\n",
        "\n",
        "# Set titles\n",
        "axes[0].set_title('Actual', fontsize=12)\n",
        "axes[1].set_title('Predicted', fontsize=12)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "HQR2id95gs6i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ“š References"
      ],
      "metadata": {
        "id": "NIYaZLxTt9UT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[1] Hasanah, S., S. Abdullah, and Dian Lestari. \"Bayesian method for hurdle regression.\" ICSA-Int. Conf. Stat. Anal. Vol. 2019. 2019.\n",
        "\n",
        "[2] Utku, A., & Akcayol, M. A. (2024). Spread patterns of COVID-19 in European countries: hybrid deep learning model for prediction and transmission analysis. Neural Computing and Applications, 36(17), 10201-10217.\n",
        "\n",
        "[3] J. E. Garrett, â€œHealth service accessibility and deaths\n",
        "from asthma,â€ Thorax, vol. 52, no. 3, pp. 205â€“206, 1997,\n",
        "doi: 10.1136/thx.52.3.205\n",
        "\n",
        "[4] Thompson, J. A., Mudaranthakam, D. P., &#38; Chollet-Hinton, L. (2023). The rural mortality penalty in U.S. hospital patients with COVID-19. <i>Research Square</i>. https://doi.org/10.21203/rs.3.rs-3467683/v1>\n",
        "\n",
        "[5] W. S. D. of Health, â€œGuidelines for using confidence\n",
        "intervals for public health assessment,â€ 2012. [Online].\n",
        "Available: https://doh.wa.gov/sites/default/files/legacy/Documents/1\n",
        "500/ConfIntGuide.pdf\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_L6lbg14uUvp"
      }
    }
  ]
}