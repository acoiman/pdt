{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOuOG6AkCK3rllQBorAKvuV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/acoiman/pdt/blob/main/asthma_mortality/notebooks/colab/08_2Asthma_Mortality_RF_RPIC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predicting Asthma Mortality in Argentina using Remote Sensing Data and Machine Learning\n",
        "\n"
      ],
      "metadata": {
        "id": "kZxCQdAv7GPa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we will use remote sensing data and Random Forest (RF) to predict asthma mortality in Argentina at departmental level from 2001 to 2022. We will model the Normalized Asthma Mortality Rate (NAMR) in a two-stage RF approach—classification followed by regression—using predictor variables derived from satellite-based observations such as burned areas, and Particulate Matter with 2.5 micrometers in diameter or less (PM2.5), along with Population Density (PD), and lagged and feature engineered variables."
      ],
      "metadata": {
        "id": "boJNPAKpFs7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import required libraries"
      ],
      "metadata": {
        "id": "fXevDbl0GYZh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dataframe libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# geospatial libraries\n",
        "import geopandas as gpd\n",
        "import mapclassify\n",
        "from libpysal.weights import Queen\n",
        "from esda.moran import Moran\n",
        "from pysal.explore import esda\n",
        "\n",
        "# plot libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "import seaborn as sns\n",
        "from matplotlib.patches import Patch\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
        "\n",
        "# modelling libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error,r2_score,explained_variance_score,median_absolute_error, max_error\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# other libraries\n",
        "from joblib import Parallel, delayed\n",
        "import shap\n",
        "from itables import init_notebook_mode, show"
      ],
      "metadata": {
        "id": "xBh05cJz7J5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load and reduce data"
      ],
      "metadata": {
        "id": "IbsFWZPlZAnr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd work/"
      ],
      "metadata": {
        "id": "o700iVYSRUAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset with data per department\n",
        "gdf = gpd.read_file(\"pdt/asthma_mortality/data/gpkg/tma_pm25_ba_pd_pdpm25_2001_2022.gpkg\")"
      ],
      "metadata": {
        "id": "-2n88TuBySeZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop geometry if only panel analysis is needed\n",
        "df = gdf.drop(columns=\"geometry\")"
      ],
      "metadata": {
        "id": "GpwOavZXySrG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape df to long format\n",
        "years = range(2001, 2023)\n",
        "records = []"
      ],
      "metadata": {
        "id": "1sArwXOhycxt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for _, row in df.iterrows():\n",
        "    iddpto = row[\"IDDPTO\"]\n",
        "    for year in years:\n",
        "        records.append({\n",
        "            \"IDDPTO\": iddpto,\n",
        "            \"YEAR\": year,\n",
        "            \"CA\": row.get(f\"CA_{year}\", np.nan),\n",
        "            \"PM25\": row.get(f\"PM25_{year}\", np.nan),\n",
        "            \"NBA\": row.get(f\"NBA_{year}\", np.nan),\n",
        "            \"PD\": row.get(f\"PD_{year}\", np.nan),\n",
        "            \"PDPM25\": row.get(f\"PDPM25_{year}\", np.nan)\n",
        "            })"
      ],
      "metadata": {
        "id": "QcFq8Nybyc0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create new df from list and sort\n",
        "panel_df = pd.DataFrame(records)"
      ],
      "metadata": {
        "id": "tjF9UTvxyiJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort and reset index\n",
        "panel_df = panel_df.sort_values(by=[\"IDDPTO\", \"YEAR\"]).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "-gY9XrPXymxS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploratory Data Analysis (EDA)"
      ],
      "metadata": {
        "id": "OZSDIWyhsttE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a copy of the panel_df DataFrame for exploratory data analysis (EDA)\n",
        "df_eda = panel_df.copy()"
      ],
      "metadata": {
        "id": "cwaLM9Tym9ql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the 'YEAR' column in panel_df to datetime format and assign it to df_eda\n",
        "df_eda['YEAR'] = pd.to_datetime(panel_df['YEAR'], format='%Y')"
      ],
      "metadata": {
        "id": "pL2C0bKOmgkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize the first rows\n",
        "init_notebook_mode(all_interactive=True)\n",
        "show(df_eda)"
      ],
      "metadata": {
        "id": "NMiJpZ_0ymz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get the number of rows\n",
        "len(df_eda)"
      ],
      "metadata": {
        "id": "AeqINbgpyiSG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter the year 2022 (Test set)\n",
        "df_eda_2022 = df_eda[df_eda['YEAR'] == pd.to_datetime(2022, format='%Y')]"
      ],
      "metadata": {
        "id": "uVbw3LtTl6XK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize the first rows\n",
        "init_notebook_mode(all_interactive=False)\n",
        "df_eda_2022.CA.describe()"
      ],
      "metadata": {
        "id": "dUPwi-8AhHMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a box plot for CA column\n",
        "sns.boxplot(x=df_eda_2022['CA'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xnGE4NeQg00D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a barplot showing the distribution  pf CA column\n",
        "sns.histplot(df_eda_2022['CA'], bins=25)\n",
        "plt.xlabel('CA')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Distribution of NAMR')\n",
        "plt.xlabel(\"NAMR\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oaxGEkoxg0_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# how many zero values are there for CA column\n",
        "df_eda_2022[df_eda_2022['CA'] == 0].shape[0]"
      ],
      "metadata": {
        "id": "fbcOBLy9iuCL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# in percentage\n",
        "round(((df_eda_2022[df_eda_2022['CA'] == 0].shape[0] / len(df_eda_2022)) * 100), 2)"
      ],
      "metadata": {
        "id": "-b99xt-kg1Gn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter out the year 2022\n",
        "df_eda_0121 = df_eda[df_eda['YEAR'] < pd.to_datetime(2022, format='%Y')]"
      ],
      "metadata": {
        "id": "lp9d7vTcp1Oi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the 'YEAR' column as the index for the DataFrame\n",
        "df_eda_0121.set_index('YEAR', inplace=True)"
      ],
      "metadata": {
        "id": "5xTwCZEei4zl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot mortality rate over time\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.lineplot(data=df_eda_0121, x=df_eda_0121.index, y='CA', marker='o', estimator='mean')\n",
        "plt.title('Mean Mortality Rate Over Time')\n",
        "plt.ylabel('Mean NAMR')\n",
        "plt.xlabel('Year')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ozn-svl0i42P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ACF and PACF plots\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
        "\n",
        "plot_pacf(df_eda_0121['CA'], ax=axes[0], lags=21, title='Partial Autocorrelation (PACF)')\n",
        "plot_acf(df_eda_0121['CA'], ax=axes[1], lags=21, title='Autocorrelation (ACF)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "u6XCGxWRi45I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exploratory Spatial  Data Analysis (ESDA)"
      ],
      "metadata": {
        "id": "s30rJPMg3mzn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset with data per department\n",
        "gdf = gpd.read_file(\"pdt/asthma_mortality/data/gpkg/tma_pm25_ba_pd_pdpm25_2001_2022.gpkg\")"
      ],
      "metadata": {
        "id": "LFPCmdS83lsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape gdf to long format\n",
        "years = range(2001, 2023)\n",
        "records = []"
      ],
      "metadata": {
        "id": "a2mzrcX23lsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for _, row in gdf.iterrows():\n",
        "    iddpto = row[\"IDDPTO\"]\n",
        "    geometry = row[\"geometry\"]\n",
        "    for year in years:\n",
        "        records.append({\n",
        "            \"IDDPTO\": iddpto,\n",
        "            \"YEAR\": year,\n",
        "            \"CA\": row.get(f\"CA_{year}\", np.nan),\n",
        "            \"PM25\": row.get(f\"PM25_{year}\", np.nan),\n",
        "            \"NBA\": row.get(f\"NBA_{year}\", np.nan),\n",
        "            \"PD\": row.get(f\"PD_{year}\", np.nan),\n",
        "            \"PDPM25\": row.get(f\"PDPM25_{year}\", np.nan),\n",
        "            \"geometry\": geometry # Add geometry\n",
        "            })"
      ],
      "metadata": {
        "id": "Orqq2xcd3lsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create new df from list and sort\n",
        "panel_gdf = pd.DataFrame(records)"
      ],
      "metadata": {
        "id": "7GbOZKNj3lsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort and reset index\n",
        "panel_gdf = panel_gdf.sort_values(by=[\"IDDPTO\", \"YEAR\"]).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "j3fbgLZp3lsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize the fisrt rows\n",
        "init_notebook_mode(all_interactive=True)\n",
        "show(panel_gdf)"
      ],
      "metadata": {
        "id": "Vx3JdCS64U_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter the DataFrame to include rows where 'YEAR' is less than 2022 and create a copy\n",
        "gdf_esda_0121 = panel_gdf[panel_gdf['YEAR'] < 2022].copy()"
      ],
      "metadata": {
        "id": "obNKES0u5UeQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define spatial weights matrix using Queen contiguity\n",
        "w = Queen.from_dataframe(gdf_esda_0121)\n",
        "w.transform = 'R'"
      ],
      "metadata": {
        "id": "jedPW4GN1nit"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute Moran's I for each mean feature\n",
        "moran_results = {}\n",
        "for col in ['CA', 'PM25', 'NBA', 'PD', 'PDPM25']:\n",
        "    moran = Moran(gdf_esda_0121[col], w)\n",
        "    moran_results[col] = {'Moran_I': moran.I, 'Moran_p_sim': moran.p_sim}\n",
        "# Create a table (DataFrame) from the results\n",
        "moran_df = pd.DataFrame.from_dict(moran_results, orient='index')"
      ],
      "metadata": {
        "id": "zznS94a82b9M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the table\n",
        "init_notebook_mode(all_interactive=True)\n",
        "show(moran_df)"
      ],
      "metadata": {
        "id": "EGA09b0f6Nr3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1 – Classification Model\n",
        "\n",
        "In this section we will  train and evaluate a classification model to predict whether NAMR is classified as an absence (0) or a presence (1) of asthma mortality (binary classification)"
      ],
      "metadata": {
        "id": "FviPCsCgeazB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a copy of the DataFrame to preserve the original data\n",
        "df_ts = panel_df.copy()"
      ],
      "metadata": {
        "id": "VvbjmPeX8KeR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create lag variables (up to 2 years)\n",
        "def create_lags(df, var, max_lag=2):\n",
        "    for lag in range(1, max_lag+1):\n",
        "        df[f\"{var}_lag{lag}\"] = df[var].shift(lag)\n",
        "    return df"
      ],
      "metadata": {
        "id": "kUE_4MC78Jr8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for var in [\"PM25\", \"NBA\", \"PD\", \"PDPM25\"]:\n",
        "    df_ts = create_lags(df_ts, var)"
      ],
      "metadata": {
        "id": "t33aEHI48Tgi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for var in [\"CA\"]:\n",
        "    df_ts = create_lags(df_ts, var,  max_lag=4)"
      ],
      "metadata": {
        "id": "xY5QgpQIrtFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop the initial rows with NaNs due to lagging\n",
        "df_ts = df_ts.dropna().reset_index(drop=True)"
      ],
      "metadata": {
        "id": "hO8mOP018Z-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Binary target\n",
        "df_ts['CA_bin'] = (df_ts['CA'] > 0).astype(int)"
      ],
      "metadata": {
        "id": "b3wi4OCfB7tG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split train and test\n",
        "train = df_ts[df_ts['YEAR'] < 2022].copy()\n",
        "test = df_ts[df_ts['YEAR'] == 2022].copy()"
      ],
      "metadata": {
        "id": "yk5oCfRE7RKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize the first rows\n",
        "init_notebook_mode(all_interactive=True)\n",
        "show(train)"
      ],
      "metadata": {
        "id": "PcwJDfHx7gMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the list of predictor variables for the model\n",
        "predictors = ['PM25', 'NBA', 'PD', 'PDPM25',\n",
        "              'PM25_lag1', 'PM25_lag2', 'NBA_lag1','NBA_lag2',\n",
        "              'PD_lag1', 'PD_lag2', 'PDPM25_lag1','PDPM25_lag2',\n",
        "              'CA_lag1', 'CA_lag2', 'CA_lag3','CA_lag4']"
      ],
      "metadata": {
        "id": "I2LIzu-zBxFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a RandomForestClassifier with a fixed random state for reproducibility and fit it to the training data\n",
        "clf = RandomForestClassifier(random_state=42,\n",
        "                             n_estimators=100)\n",
        "clf.fit(train[predictors], train['CA_bin'])"
      ],
      "metadata": {
        "id": "zF34gNZQCVUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict probability of CA > 0 in 2022\n",
        "test['CA_bin_pred'] = clf.predict(test[predictors])"
      ],
      "metadata": {
        "id": "MKiMG4B1CVXp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize the first rows\n",
        "init_notebook_mode(all_interactive=True)\n",
        "show(test)"
      ],
      "metadata": {
        "id": "zB35Cjr7CuLP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate and evaluate classification metrics for the model's predictions\n",
        "y_true = test['CA_bin']        # Ground truth: binary target variable\n",
        "y_pred = test[\"CA_bin_pred\"]   # Model's predicted binary values\n",
        "\n",
        "# Compute accuracy score\n",
        "acc = accuracy_score(y_true, y_pred)  # Proportion of correct predictions\n",
        "\n",
        "# Compute precision score\n",
        "prec = precision_score(y_true, y_pred)  # Proportion of true positives among predicted positives\n",
        "\n",
        "# Compute recall score\n",
        "rec = recall_score(y_true, y_pred)  # Proportion of true positives among actual positives\n",
        "\n",
        "# Compute F1 score\n",
        "f1 = f1_score(y_true, y_pred)  # Harmonic mean of precision and recall\n",
        "\n",
        "# Print the calculated metrics with formatting\n",
        "print(f\"Accuracy  = {acc:.3f}\")   # Display accuracy with 3 decimal places\n",
        "print(f\"Precision = {prec:.3f}\")  # Display precision with 3 decimal places\n",
        "print(f\"Recall    = {rec:.3f}\")   # Display recall with 3 decimal places\n",
        "print(f\"F1 Score  = {f1:.3f}\")    # Display F1 score with 3 decimal places"
      ],
      "metadata": {
        "id": "BllEi3R0kOod"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metric\tValue\tInterpretation\n",
        "* Accuracy\t0.75.\tOverall, the classifier correctly identified whether CA was 0 or >0 about 75% of the time. This is decent but may be misleading if there is class imbalance (e.g., many zeros).\n",
        "* Precision\t0.677.\tOf all the cases where the classifier predicted CA > 0, 67% were correct. Moderate precision means a fair amount of false positives (it sometimes predicts CA when the true value is 0).\n",
        "* Recall\t0.518.\tThe model only identified 51.8% of true CA > 0 cases. So it's missing nearly half of the true positives (false negatives are high).\n",
        "* F1 Score\t0.587.\tThe harmonic mean of precision and recall. This moderate value indicates a trade-off between missing positives and over-predicting them."
      ],
      "metadata": {
        "id": "pobVGpCMnkTW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Part 2 – Regression Model\n",
        "\n",
        "In this section, we will train and evaluate a RF regression model to estimate NAMR values where it is present"
      ],
      "metadata": {
        "id": "J_uk1xOhj-1W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train only on CA > 0\n",
        "train_pos = train[train['CA'] > 0].copy()"
      ],
      "metadata": {
        "id": "5bQg_BrqDyvZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize the first rows\n",
        "init_notebook_mode(all_interactive=True)\n",
        "show(train_pos)"
      ],
      "metadata": {
        "id": "MIjx-t23D9M_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train a Random Forest Regressor model with 100 estimators and a fixed random state for reproducibility\n",
        "reg = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "reg.fit(train_pos[predictors], train_pos['CA'])"
      ],
      "metadata": {
        "id": "gaIa_0XRD4c8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict only for departments where classifier said CA > 0\n",
        "test['CA_pred'] = 0.0  # Initialize the 'CA_pred' column with a default value of 0.0\n",
        "mask = (test['CA_bin_pred'] == 1) | (test['CA_bin'] == 1)  # Create a mask for rows where either 'CA_bin_pred' or 'CA_bin' equals 1\n",
        "test.loc[mask, 'CA_pred'] = reg.predict(test.loc[mask, predictors])  # Use the model to predict 'CA_pred' for rows matching the mask"
      ],
      "metadata": {
        "id": "swJ17Li3EM-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the true values from the test dataset for the 'CA' column\n",
        "true = test['CA']\n",
        "\n",
        "# Extract the predicted values from the test dataset for the 'CA_pred' column\n",
        "pred = test['CA_pred']\n",
        "\n",
        "# Calculate Mean Absolute Error (MAE) between true and predicted values\n",
        "mae = mean_absolute_error(true, pred)\n",
        "\n",
        "# Calculate Root Mean Squared Error (RMSE) between true and predicted values\n",
        "rmse = np.sqrt(mean_squared_error(true, pred))\n",
        "\n",
        "# Calculate Mean Absolute Percentage Error (MAPE) between true and predicted values\n",
        "# Adding a small constant (1e-6) to avoid division by zero\n",
        "mape = np.mean(np.abs((true - pred) / (true + 1e-6))) * 100\n",
        "\n",
        "# Define a function to calculate Symmetric Mean Absolute Percentage Error (SMAPE)\n",
        "def smape(A, F):\n",
        "    # SMAPE formula: 100 * mean(2 * abs(F - A) / (abs(A) + abs(F) + small constant))\n",
        "    return 100 * np.mean(2 * np.abs(F - A) / (np.abs(A) + np.abs(F) + 1e-6))\n",
        "\n",
        "# Calculate SMAPE value using the defined function\n",
        "smape_value = smape(true.values, pred.values)\n",
        "\n",
        "# Calculate R-squared (R2) score to measure the goodness of fit\n",
        "r2 = r2_score(true, pred)\n",
        "\n",
        "# Calculate Explained Variance Score (EVS) to measure the proportion of variance explained\n",
        "evs = explained_variance_score(true, pred)\n",
        "\n",
        "# Calculate Median Absolute Error (MedAE) between true and predicted values\n",
        "medae = median_absolute_error(true, pred)\n",
        "\n",
        "# Calculate Maximum Error (Max Error) between true and predicted values\n",
        "max_err = max_error(true, pred)\n",
        "\n",
        "# Print results\n",
        "print(f\"MAE    = {mae:.3f}\")\n",
        "print(f\"RMSE   = {rmse:.3f}\")\n",
        "print(f\"MAPE   = {mape:.2f}%\")\n",
        "print(f\"SMAPE  = {smape_value:.2f}%\")\n",
        "print(f\"R²     = {r2:.3f}\")\n",
        "print(f\"Explained Variance = {evs:.3f}\")\n",
        "print(f\"Median Absolute Error = {medae:.3f}\")\n",
        "print(f\"Max Error = {max_err:.3f}\")"
      ],
      "metadata": {
        "id": "URfID-HDGWzD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize the first rows\n",
        "init_notebook_mode(all_interactive=True)\n",
        "show(test)"
      ],
      "metadata": {
        "id": "QZ1UIomGMi3G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SHAP (SHapley Additive Explanations)\n",
        "\n",
        "In this section we will interpret the contribution of each independent variable to the final predition using the SHAP method"
      ],
      "metadata": {
        "id": "8WJTv7uN8Xgj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- SHAP for Binary Classifier ----\n",
        "# Use TreeExplainer (optimized for RandomForest)\n",
        "explainer = shap.TreeExplainer(clf)"
      ],
      "metadata": {
        "id": "2oRSdJc5G6tB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample the test set or use the full set if not too large\n",
        "X = test[predictors]  # e.g., X = test[predictors].sample(n=200)"
      ],
      "metadata": {
        "id": "xeDQyHlcHBXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to compute SHAP values for a single row\n",
        "def compute_shap(row):\n",
        "    return explainer.shap_values(row)"
      ],
      "metadata": {
        "id": "HRab7ErzHFM-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parallel computation\n",
        "shap_values_list = Parallel(n_jobs=-1)(\n",
        "    delayed(compute_shap)(X.iloc[[i]]) for i in range(len(X))\n",
        ")"
      ],
      "metadata": {
        "id": "rv6IpAxmHru_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine SHAP values for Class 1 into a single array\n",
        "shap_values = np.vstack([vals[0][:, 1] for vals in shap_values_list])  # Class 1 SHAPs\n"
      ],
      "metadata": {
        "id": "bFxmVdtkIGhC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a SHAP summary plot to visualize the impact of features on the model's predictions\n",
        "shap.summary_plot(shap_values, X, feature_names=predictors)\n"
      ],
      "metadata": {
        "id": "zVGzJveyIPkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- SHAP for Regression ----\n",
        "# Use TreeExplainer (optimized for RandomForest)\n",
        "explainer = shap.TreeExplainer(reg)\n",
        "\n",
        "# Sample the test set or use the full set if not too large\n",
        "X = test[predictors]  # e.g., X = test[predictors].sample(n=200)\n",
        "\n",
        "# Function to compute SHAP values for a single row\n",
        "def compute_shap(row):\n",
        "    # For regression, shap_values returns a single 1D array\n",
        "    return explainer.shap_values(row)\n",
        "\n",
        "# Parallel computation (adjust n_jobs as needed)\n",
        "shap_values_list = Parallel(n_jobs=-1)(\n",
        "    delayed(compute_shap)(X.iloc[[i]]) for i in range(len(X))\n",
        ")\n",
        "\n",
        "# Stack the 1D SHAP value arrays vertically\n",
        "# No need to index [:, 1] as there's only one set of SHAP values for regression\n",
        "shap_values = np.vstack(shap_values_list)"
      ],
      "metadata": {
        "id": "yfQ6RYfoL6_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a SHAP summary plot to visualize the impact of features on the model's predictions\n",
        "shap.summary_plot(shap_values, X, feature_names=predictors)"
      ],
      "metadata": {
        "id": "zSPXIag7Kg3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for test change column names CA_pred to CA_2022_PRED\n",
        "test.rename(columns={'CA_pred': 'CA_2022_PRED'}, inplace=True)"
      ],
      "metadata": {
        "id": "Si5PbP4ZTkEi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save test as a csv file\n",
        "test.to_csv('pdt/asthma_mortality/data/csv/results_RF.csv', index=False)"
      ],
      "metadata": {
        "id": "eJorE2pxUqSk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🌍 Mapping actual vs predicted asthma mortality rate"
      ],
      "metadata": {
        "id": "ATMk6nJjNlKG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# open df with results of RF modelling\n",
        "results_df = pd.read_csv('pdt/asthma_mortality/data/csv/results_RF.csv', dtype={'IDDPTO': str})"
      ],
      "metadata": {
        "id": "P5JhYZgiQy8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop columns not required columns in df_results for mapping\n",
        "df_map = results_df.drop(columns=['YEAR', 'CA', 'PM25', 'NBA', 'PD', 'PDPM25', 'PM25_lag1',\n",
        "                                  'PM25_lag2', 'NBA_lag1', 'NBA_lag2', 'PD_lag1', 'PD_lag2',\n",
        "                                  'PDPM25_lag1', 'PDPM25_lag2', 'CA_bin', 'CA_bin_pred',\n",
        "                                  'CA_lag1', 'CA_lag2', 'CA_lag3','CA_lag4'])"
      ],
      "metadata": {
        "id": "wD7BGtbYNmhY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# round CA_2022_PRED to two decimal places\n",
        "df_map['CA_2022_PRED'] = df_map['CA_2022_PRED'].round(2)\n"
      ],
      "metadata": {
        "id": "7w2aeffNTz43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize df_map\n",
        "init_notebook_mode(all_interactive=True)\n",
        "show(df_map)"
      ],
      "metadata": {
        "id": "phGVepcUSMAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get df basic info\n",
        "df_map.info()"
      ],
      "metadata": {
        "id": "IFAC9Y1SSUO5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Join gdf with df_map preserving data of gdf\n",
        "\n",
        "# Ensure 'IDDPTO' column is of the same type in both dataframes before joining\n",
        "gdf['IDDPTO'] = gdf['IDDPTO'].astype(str)\n",
        "df_map['IDDPTO'] = df_map['IDDPTO'].astype(str)\n",
        "\n",
        "# Perform a left merge (preserving all rows from gdf)\n",
        "gdf2 = gdf.merge(df_map, on='IDDPTO', how='left')"
      ],
      "metadata": {
        "id": "EC4psaEtUjt2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display info and the first few rows of the merged GeoDataFrame\n",
        "init_notebook_mode(all_interactive=True)\n",
        "show(gdf2.head())"
      ],
      "metadata": {
        "id": "OQdwkok4Usew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get df basic info\n",
        "gdf2.info()"
      ],
      "metadata": {
        "id": "IAnXcozpVwLV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save df2 as gpkg file\n",
        "gdf2.to_file(\"pdt/asthma_mortality/data/gpkg/results_RF.gpkg\", driver=\"GPKG\")"
      ],
      "metadata": {
        "id": "MemjyiM3VyWh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculate classification schema for mapping"
      ],
      "metadata": {
        "id": "clFu3h07LM8w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use [Pysal](https://pysal.org/)'s [mapclassify](https://pysal.org/mapclassify/index.html) library to determine the best classifier for the choropleth map.\n",
        "\n",
        "We will use the map classifier with the best ACDM (mean Absolute Deviation Around the class Median). In Pysal, ACDM refers to the mean absolute deviation around the class median. It is a measure of a classifier's fit to the data, specifically by evaluating the average distance between each data point and the median value of the assigned class."
      ],
      "metadata": {
        "id": "_vR6QhT5MSgU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from gdf2 preserve only IDDPTO, CA_2022 and CA_2022_PRED\n",
        "df_cl = gdf2[['IDDPTO', 'CA_2022', 'CA_2022_PRED', \"geometry\"]].copy()"
      ],
      "metadata": {
        "id": "NJwi_TDpXUA5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize the dataframe\n",
        "init_notebook_mode(all_interactive=True)\n",
        "show(df_cl.head())"
      ],
      "metadata": {
        "id": "WAtE2YAvX6__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get df basic info\n",
        "df_cl.info()"
      ],
      "metadata": {
        "id": "RfWbAYX4N9N8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the length of the dataframe 'df_cl'\n",
        "len(df_cl)"
      ],
      "metadata": {
        "id": "g0F-jKiQNxvV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select data to analize\n",
        "selected_data = df_cl.loc[:,[\"CA_2022\", \"CA_2022_PRED\"]]"
      ],
      "metadata": {
        "id": "8mOWh83wMtb9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classify the data into 4 quantile groups\n",
        "q4 = mapclassify.Quantiles(selected_data, k=4)\n",
        "q4"
      ],
      "metadata": {
        "id": "xaxBNjrgM8wd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Equal Interval Classification\n",
        "ei5 = mapclassify.EqualInterval(selected_data, k=5)\n",
        "ei5"
      ],
      "metadata": {
        "id": "1OSGjbdRNepG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classify the data into groups based on the head/tail breaks algorithm\n",
        "ht = mapclassify.HeadTailBreaks(selected_data)\n",
        "ht"
      ],
      "metadata": {
        "id": "LdJq40eONexG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MaximumBreaks classification method\n",
        "mb5 = mapclassify.MaximumBreaks(selected_data, k=5)\n",
        "mb5"
      ],
      "metadata": {
        "id": "_4svptQ_Nezr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the Standard Deviation and Mean classification method to the selected data.\n",
        "msd = mapclassify.StdMean(selected_data)\n",
        "msd"
      ],
      "metadata": {
        "id": "Nc0MZ-vdNe2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply Fisher-Jenks classification with 5 classes\n",
        "fj5 = mapclassify.FisherJenks(selected_data, k=5)\n",
        "fj5"
      ],
      "metadata": {
        "id": "MJ-oXygNObrk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ACDM(mean Absolute Deviation Around the class Median) visualization"
      ],
      "metadata": {
        "id": "umQ-3FECNNXz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bunch classifier objects\n",
        "class5 = q4, ei5, ht, mb5, msd, fj5\n",
        "# Collect ADCM for each classifier\n",
        "fits = np.array([c.adcm for c in class5])\n",
        "# Convert ADCM scores to a DataFrame\n",
        "adcms = pd.DataFrame(fits)\n",
        "# Add classifier names\n",
        "adcms[\"classifier\"] = [c.name for c in class5]\n",
        "# Add column names to the ADCM\n",
        "adcms.columns = [\"ADCM\", \"Classifier\"]\n",
        "ax = sns.barplot(\n",
        "    y=\"Classifier\", x=\"ADCM\", data=adcms, hue= adcms[\"Classifier\"],  legend=False\n",
        ")"
      ],
      "metadata": {
        "id": "2ksylA_zG8VN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create choropleth maps"
      ],
      "metadata": {
        "id": "MsI6Mtjcl85R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Two classifiers have the lowest ACDM: FisherJenks and HeadTailBreaks. We'll select FisherJenks as the classifier to create the choropleth maps."
      ],
      "metadata": {
        "id": "EXSn0psmO5kU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the bins to a list for further processing\n",
        "bins = fj5.bins.tolist()\n",
        "bins"
      ],
      "metadata": {
        "id": "Qa6eGH-RO4_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# insert 0 at 0 position\n",
        "bins.insert(0, 0.0)\n",
        "bins"
      ],
      "metadata": {
        "id": "e1qlFA1NRF6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a custom classification using UserDefined for actual values\n",
        "classi_actual = mapclassify.UserDefined(df_cl[\"CA_2022\"], bins)"
      ],
      "metadata": {
        "id": "G8I-KbzeRNQS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a custom classification using UserDefined for predicted values\n",
        "classi_pred = mapclassify.UserDefined(df_cl[\"CA_2022_PRED\"], bins)"
      ],
      "metadata": {
        "id": "0pRkvgeeiZE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(12, 8))\n",
        "fig.subplots_adjust(hspace=0, wspace=-0.9)\n",
        "plt.suptitle('Normalized Asthma Mortality Rate 2022', fontsize=14, y=1)\n",
        "\n",
        "# Plot classi_actual\n",
        "classi_actual.plot(\n",
        "    df_cl,\n",
        "    legend=False,  # We'll build it manually\n",
        "    axis_on=False,\n",
        "    border_color='black',\n",
        "    cmap=\"viridis_r\",\n",
        "    ax=axes[0]\n",
        ")\n",
        "\n",
        "# Plot classi_pred\n",
        "classi_pred.plot(\n",
        "    df_cl,\n",
        "    legend=False,  # We'll build it manually\n",
        "    axis_on=False,\n",
        "    border_color='black',\n",
        "    cmap=\"viridis_r\",\n",
        "    ax=axes[1]\n",
        ")\n",
        "\n",
        "\n",
        "# Custom bin labels and colors\n",
        "bin_labels = [\"0.00\", \"0.00-0.65\", \"0.65-2.16\", \"2.16-4.13\", \"4.13-7.49\", \"7.49-14.15\"]\n",
        "n_bins = len(bin_labels)\n",
        "# cmap = mpl.cm.get_cmap(\"viridis_r\", n_bins)\n",
        "cmap = mpl.colormaps.get_cmap(\"viridis_r\").resampled(n_bins)\n",
        "colors = [mpl.colors.to_hex(cmap(i)) for i in range(cmap.N)]\n",
        "\n",
        "# Create legend patches for bins\n",
        "bin_patches = [Patch(facecolor=color, edgecolor='black', label=label)\n",
        "               for color, label in zip(colors, bin_labels)]\n",
        "\n",
        "\n",
        "# Combine all patches\n",
        "all_patches = bin_patches\n",
        "\n",
        "# Display custom legend\n",
        "#axes[0].legend(handles=all_patches, loc='upper right', bbox_to_anchor=(1.1, 0.4), fontsize=8)\n",
        "axes[1].legend(handles=all_patches, loc='upper right', bbox_to_anchor=(0.9, 0.25), fontsize=10)\n",
        "\n",
        "# Set titles\n",
        "axes[0].set_title('Actual', fontsize=12)\n",
        "axes[1].set_title('Predicted', fontsize=12)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "HQR2id95gs6i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}