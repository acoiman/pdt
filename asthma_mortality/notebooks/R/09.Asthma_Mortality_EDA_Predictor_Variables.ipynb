{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "TclZZ5SYRVcC",
        "FqIc62z1_2G7",
        "VBTPm1kEW6Lt",
        "jHrI2f7Grp8r"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNpTRJzk3Nfv8Lkye9apwQ5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/acoiman/pdt/blob/main/asthma_mortality/notebooks/R/09.Asthma_Mortality_EDA_Predictor_Variables.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ðŸ“Š Exploratory Data Analysis (EDA) of Predictor Variables"
      ],
      "metadata": {
        "id": "hjlpV9riausZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this Notebook we will perform the Exploratory Data Analysis (EDA) of the predictor variables to better understand their temporal and spatial dynamics and their potential association with asthma mortality rate in Argentina. The analysis begins by loading and preparing the data, ensuring its quality through checks for missing values and internal consistency. It then explores the statistical behavior of each predictor through distributional analysis, yearly trends, treemaps, and spatial visualizations such as departmental choropleth maps.\n",
        "\n",
        "Special attention is given to critical variablesâ€”including PMâ‚‚.â‚…, normalized burned areas (NBA), population density (PD), land-use transitions (NAGRT, NNWVT, NBUT), and derived interactions like PDÃ—PMâ‚‚.â‚…â€”providing insight into their geographic patterns and evolution over time.\n",
        "\n",
        "The notebook further evaluates the relationship between predictors and the asthma mortality rate (CA) through correlation analysis, interaction terms, lagged effects, and multicollinearity diagnostics using correlation matrices and VIF. Finally, dimensionality reduction techniques such as PCA or clustering are applied to identify underlying structures in the predictor space. Together, these steps establish a rigorous analytical foundation for subsequent modeling and inference on environmental determinants of asthma mortality.rate."
      ],
      "metadata": {
        "id": "R1aGuAf4a8OG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ¤– Load libraries\n",
        "\n",
        "The libraries required for the analysis will be loaded"
      ],
      "metadata": {
        "id": "OH4WTT6va81O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dataframe libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# plot libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "from matplotlib.patches import Patch\n",
        "import seaborn as sns\n",
        "import squarify\n",
        "\n",
        "# statistical libraries\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# geospatial libraries\n",
        "import geopandas as gpd\n",
        "import mapclassify\n",
        "\n",
        "# other libraries\n",
        "from datetime import datetime\n",
        "from itables import init_notebook_mode, show\n",
        "import os"
      ],
      "metadata": {
        "id": "hy8BgBTGa-Nh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# change directory to work folder (at the begining docker container enter into /home/jovyan/)\n",
        "%cd work"
      ],
      "metadata": {
        "id": "o700iVYSRUAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the PROJ_LIB path\n",
        "os.environ['PROJ_LIB'] = \"/opt/conda/envs/gds/share/proj\""
      ],
      "metadata": {
        "id": "V2QSVvb5ODyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ’¾ Load and reduce data"
      ],
      "metadata": {
        "id": "MLQ67gFZcxBg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "gdf = gpd.read_file(\"pdt/asthma_mortality/data/gpkg/data.gpkg\")"
      ],
      "metadata": {
        "id": "MWuBlQ1IbQLx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize geo data.frame\n",
        "init_notebook_mode(all_interactive=True)\n",
        "gdf.head()"
      ],
      "metadata": {
        "id": "ZuByUooOelSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# inspect any nan in columns\n",
        "init_notebook_mode(all_interactive=True)\n",
        "gdf.isna().sum()"
      ],
      "metadata": {
        "id": "cRkPSS4Cf5J4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape df to ts long format\n",
        "years = range(2001, 2023)\n",
        "records = []"
      ],
      "metadata": {
        "id": "HZQelTg7d8Pd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for _, row in gdf.iterrows():\n",
        "    iddpto = row[\"IDDPTO\"]\n",
        "    geometry = row[\"geometry\"]\n",
        "    for year in years:\n",
        "        records.append({\n",
        "            \"IDDPTO\": iddpto,\n",
        "            \"YEAR\": year,\n",
        "            \"CA\": row.get(f\"CA_{year}\", np.nan),\n",
        "            \"PM25\": row.get(f\"PM25_{year}\", np.nan),\n",
        "            \"NBA\": row.get(f\"NBA_{year}\", np.nan),\n",
        "            \"PD\": row.get(f\"PD_{year}\", np.nan),\n",
        "            \"PDPM25\": row.get(f\"PDPM25_{year}\", np.nan),\n",
        "            \"NAGRT\": row.get(f\"NAGRT_{year}\", np.nan),\n",
        "            \"NNWVT\": row.get(f\"NNWVT_{year}\", np.nan),\n",
        "            \"NBUT\": row.get(f\"NBUT_{year}\", np.nan),\n",
        "            \"ELEV\": row.get(f\"ELEV_{year}\", np.nan),\n",
        "            \"geometry\": geometry # Add geometry\n",
        "            })"
      ],
      "metadata": {
        "id": "9eGHVBgneBX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create new df from list and sort\n",
        "panel_gdf = pd.DataFrame(records)"
      ],
      "metadata": {
        "id": "7GbOZKNj3lsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort and reset index\n",
        "panel_gdf = panel_gdf.sort_values(by=[\"IDDPTO\", \"YEAR\"]).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "j3fbgLZp3lsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize the fisrt rows\n",
        "init_notebook_mode(all_interactive=False)\n",
        "panel_gdf.head()"
      ],
      "metadata": {
        "id": "Vx3JdCS64U_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize the number of rows and columsn of the data.frame\n",
        "panel_gdf.shape"
      ],
      "metadata": {
        "id": "CC9z63QshQ8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ§¹ Data Quality\n",
        "\n",
        "In this section we will inspect missing values per columns, check distribution of each feature and  verify temporal consistency of the dataset."
      ],
      "metadata": {
        "id": "r2crsU7ItBBm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inspect missing values"
      ],
      "metadata": {
        "id": "D9uVStcKlICR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# drop gemetry column\n",
        "df = panel_gdf.drop(columns=[\"geometry\"])"
      ],
      "metadata": {
        "id": "bGs8zRjcuFW9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check missing values\n",
        "print(df.isna().sum())"
      ],
      "metadata": {
        "id": "_XXgQrR3tyZH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check number of duplicated rows\n",
        "print(df.duplicated().sum())"
      ],
      "metadata": {
        "id": "Um8Sf_QeuQoj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Verify data consistency"
      ],
      "metadata": {
        "id": "FgaNh2EAxXmG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Features to check (excluding ID, geometry)\n",
        "features = ['CA', 'PM25', 'NBA', 'PD', 'PDPM25', 'NAGRT', 'NNWVT', 'NBUT', 'ELEV']\n",
        "\n",
        "# Total zero counts per feature\n",
        "zero_counts = (df[features] == 0).sum().sort_values(ascending=False)\n",
        "print(\"Total Zero Values per Feature\")\n",
        "print(zero_counts)\n",
        "\n",
        "# Heatmap visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "pNrvnGnkv-72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Percentage of zero counts per feature\n",
        "total_records = len(df)\n",
        "zero_percentages = round((zero_counts / total_records) * 100, 2)\n",
        "print(\"Percentage of Zero Values per Feature \")\n",
        "print(zero_percentages.sort_values(ascending=False))"
      ],
      "metadata": {
        "id": "uozH3P-vAHaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Heatmap visualization\n",
        "# Calculate zero counts per feature per year\n",
        "zero_counts_yearly = df.groupby('YEAR')[features].apply(lambda x: (x == 0).sum())\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.heatmap(zero_counts_yearly.T, annot=True, fmt=\"d\", cmap=\"Reds\")\n",
        "plt.title(\"Zero Value Counts per Feature per Year\")\n",
        "plt.xlabel(\"Year\")\n",
        "plt.ylabel(\"Feature\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "06-_hIrW_wq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ”® Predictor Variable Exploration\n",
        "\n",
        "In this section wi will explore the distribution, correlations, and spatio-tempral trends of the predictor variables."
      ],
      "metadata": {
        "id": "TkVKT8ztlW0B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualization of distributions of each variable\n",
        "\n",
        "With the following code, we will generate histograms with KDE curves to visualize the distribution shapes (e.g., normal, skewed, multimodal). In addition, we will create boxplots to examine the spread of the data and identify potential outliers"
      ],
      "metadata": {
        "id": "Lg_sZKFxlegb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select only numeric variables for distribution check\n",
        "numeric_vars = ['CA', 'PM25', 'NBA', 'PD', 'PDPM25', 'NAGRT', 'NNWVT', 'NBUT', 'ELEV']"
      ],
      "metadata": {
        "id": "9_RBrclhlegc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot histograms + KDE\n",
        "n_cols = 3\n",
        "n_rows = (len(numeric_vars) + n_cols - 1) // n_cols\n",
        "\n",
        "plt.figure(figsize=(16, n_rows * 4))\n",
        "\n",
        "for i, col in enumerate(numeric_vars, 1):\n",
        "    plt.subplot(n_rows, n_cols, i)\n",
        "    sns.histplot(df[col], kde=True, bins=30, color=\"steelblue\")\n",
        "    plt.title(f\"Distribution of {col}\")\n",
        "    plt.xlabel(col)\n",
        "    plt.ylabel(\"Frequency\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "en0dLG5elegc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# show boxplots for skewed distributions\n",
        "plt.figure(figsize=(16, n_rows * 3))\n",
        "for i, col in enumerate(numeric_vars, 1):\n",
        "    plt.subplot(n_rows, n_cols, i)\n",
        "    sns.boxplot(x=df[col], color=\"orange\")\n",
        "    plt.title(f\"Boxplot of {col}\")\n",
        "    plt.xlabel(col)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dCY7pbeTlegc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Yearly trends of predictor variables"
      ],
      "metadata": {
        "id": "ZQOD0RzSrTgW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ploting yearly trends for each predictor variable"
      ],
      "metadata": {
        "id": "7gNup4Lf9RH0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize the data.frame\n",
        "df.head()"
      ],
      "metadata": {
        "id": "EdOKGmU_qfpd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# copy dataframe\n",
        "df_ts = df.copy()"
      ],
      "metadata": {
        "id": "opR7UJlytzll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure YEAR is in datetime format and extract the year number\n",
        "df_ts['YEAR_DT'] = pd.to_datetime(df_ts['YEAR'], format='%Y')\n",
        "df_ts['year_num'] = df_ts['YEAR_DT'].dt.year"
      ],
      "metadata": {
        "id": "zvjbkaRZqfsw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ts.head()"
      ],
      "metadata": {
        "id": "Y_U2ECLevFNh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define predictor variables\n",
        "predictors = ['PM25', 'NBA', 'PD', 'PDPM25', 'NAGRT', 'NNWVT', 'NBUT', 'ELEV']"
      ],
      "metadata": {
        "id": "fOKHAuCKqfv1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot yearly trends for each predictor variable in separate subplots\n",
        "n_predictors = len(predictors)  # Get the number of predictor variables\n",
        "n_cols = 3  # Set the number of columns for subplots\n",
        "n_rows = (n_predictors + n_cols - 1) // n_cols  # Calculate the number of rows needed for subplots\n",
        "\n",
        "plt.figure(figsize=(15, n_rows * 5))  # Create a figure with a specified size\n",
        "\n",
        "for i, var in enumerate(predictors, 1):  # Loop through each predictor variable\n",
        "    plt.subplot(n_rows, n_cols, i)  # Create a subplot for the current variable\n",
        "    yearly_mean = df_ts.groupby('year_num')[var].mean()  # Calculate yearly mean for the variable\n",
        "    plt.plot(yearly_mean.index, yearly_mean.values, marker='o', linestyle='-')  # Plot the yearly trend\n",
        "    plt.title(f\"Yearly Trend of {var}\")  # Set the title for the subplot\n",
        "    plt.xlabel(\"Year\")  # Label the x-axis\n",
        "    plt.ylabel(\"Mean Value\")  # Label the y-axis\n",
        "    plt.grid(True)  # Enable grid for better visualization\n",
        "\n",
        "plt.tight_layout()  # Adjust layout to prevent overlapping\n",
        "plt.show()  # Display the plots\n"
      ],
      "metadata": {
        "id": "i3VSxiSYu7OV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Creating treemaps of predictor variables by year"
      ],
      "metadata": {
        "id": "bjHpIgTx9Why"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create subplots (adjust number of rows/columns as needed)\n",
        "n_vars = len(predictors)\n",
        "n_cols = 4\n",
        "n_rows = (n_vars + n_cols - 1) // n_cols\n",
        "\n",
        "fig, axes = plt.subplots(n_rows, n_cols, figsize=(18, 10))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, var in enumerate(predictors):\n",
        "    ax = axes[i]\n",
        "\n",
        "    # Compute yearly mean for each predictor\n",
        "    yearly_mean = df_ts.groupby('year_num')[var].mean().reset_index()\n",
        "\n",
        "    # Prepare labels and sizes for the treemap\n",
        "    sizes = yearly_mean[var].values\n",
        "    labels = [f\"{year}\\n{val:.2f}\" for year, val in zip(yearly_mean['year_num'], yearly_mean[var])]\n",
        "\n",
        "    # Create treemap\n",
        "    squarify.plot(\n",
        "        sizes=sizes,\n",
        "        label=labels,\n",
        "        color=plt.cm.RdYlBu(sizes / max(sizes)),\n",
        "        alpha=0.8,\n",
        "        ax=ax\n",
        "    )\n",
        "\n",
        "    ax.set_title(f\"{var} - Mean Value by Year\", fontsize=11)\n",
        "    ax.axis('off')\n",
        "\n",
        "# Remove any empty subplots\n",
        "for j in range(i + 1, len(axes)):\n",
        "    fig.delaxes(axes[j])\n",
        "\n",
        "plt.suptitle(\"Treemaps of Predictor Variables (Mean Value per Year)\", fontsize=14, y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uH6BBTX3u7Tv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Spatial patterns of predictor variables\n",
        "\n",
        "In this section, we will create choropleth maps as faceted of predictor variables by year of study (2001-2022).  We will use [Pysal](https://pysal.org/)'s [mapclassify](https://pysal.org/mapclassify/index.html) library to determine the best classifier for the choropleth map by calculating the  best ACDM (mean Absolute Deviation Around the class Median). In Pysal, ACDM refers to the mean absolute deviation around the class median. It is a measure of a classifier's fit to the data, specifically by evaluating the average distance between each data point and the median value of the assigned class."
      ],
      "metadata": {
        "id": "u3PwubRIAWFY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Particulate Matter < 2.5 um (PM2.5)"
      ],
      "metadata": {
        "id": "TclZZ5SYRVcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a copy of  the geodataframe\n",
        "gdf_cl = gdf.copy()"
      ],
      "metadata": {
        "id": "Lf9h53F89mRL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a list of column names that start with \"PM25_\"\n",
        "pm25_columns = [col for col in gdf_cl.columns if col.startswith(\"PM25_\")]"
      ],
      "metadata": {
        "id": "BaLDuR0JSxo6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select data to analize\n",
        "selected_data = gdf_cl.loc[:,pm25_columns]"
      ],
      "metadata": {
        "id": "CrCm-jTUEpy8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classify the data into 4 quantile groups\n",
        "q4 = mapclassify.Quantiles(selected_data, k=4)\n",
        "q4"
      ],
      "metadata": {
        "id": "SVcTqBRaEp50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Equal Interval Classification\n",
        "ei5 = mapclassify.EqualInterval(selected_data, k=5)\n",
        "ei5"
      ],
      "metadata": {
        "id": "c0oSFl5F9kPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classify the data into groups based on the head/tail breaks algorithm\n",
        "ht = mapclassify.HeadTailBreaks(selected_data)\n",
        "ht"
      ],
      "metadata": {
        "id": "wR089-p89kSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MaximumBreaks classification method\n",
        "mb5 = mapclassify.MaximumBreaks(selected_data, k=5)\n",
        "mb5"
      ],
      "metadata": {
        "id": "oxhWvHrL9kVe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the Standard Deviation and Mean classification method to the selected data.\n",
        "msd = mapclassify.StdMean(selected_data)\n",
        "msd"
      ],
      "metadata": {
        "id": "IkhUqB_JVjq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply Fisher-Jenks classification with 5 classes\n",
        "fj5 = mapclassify.FisherJenks(selected_data, k=5)\n",
        "fj5"
      ],
      "metadata": {
        "id": "bJ5LgXIIVmij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bunch classifier objects\n",
        "class5 = q4, ei5, ht, mb5, msd, fj5\n",
        "# Collect ADCM for each classifier\n",
        "fits = np.array([c.adcm for c in class5])\n",
        "# Convert ADCM scores to a DataFrame\n",
        "adcms = pd.DataFrame(fits)\n",
        "# Add classifier names\n",
        "adcms[\"classifier\"] = [c.name for c in class5]\n",
        "# Add column names to the ADCM\n",
        "adcms.columns = [\"ADCM\", \"Classifier\"]\n",
        "ax = sns.barplot(\n",
        "    y=\"Classifier\", x=\"ADCM\", data=adcms, hue= adcms[\"Classifier\"],  legend=False\n",
        ")"
      ],
      "metadata": {
        "id": "k4G15CzTVqGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Create choropleth maps of PM2.5\n"
      ],
      "metadata": {
        "id": "uhHuXgIy3WbP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Two classifiers have the lowest ACDM: FisherJenks and HeadTailBreaks. We'll select FisherJenks as the classifier to create the choropleth maps."
      ],
      "metadata": {
        "id": "RKcYKNAW3WbP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the bins to a list for further processing\n",
        "bins = fj5.bins.tolist()\n",
        "bins"
      ],
      "metadata": {
        "id": "Ivawb5ee3WbP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will create a function to set a custom classification scheme based on FisherJenks"
      ],
      "metadata": {
        "id": "mTpBjQURKJJT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def maptma(colname, title, row, col):\n",
        "    # Create a custom classification using UserDefined\n",
        "    classification = mapclassify.UserDefined(gdf_cl[colname], bins)\n",
        "\n",
        "    classification.plot(\n",
        "          gdf,  # GeoDataFrame containing the data to be plotted\n",
        "          legend=True,  # Enable the legend for the plot\n",
        "          legend_kwds={\n",
        "                \"fmt\": \"{:.0f}\",  # Format the legend labels as integers\n",
        "                # \"loc\": \"upper right\",  # Position the legend in the upper right corner\n",
        "                \"bbox_to_anchor\": (1.2, 0.4),  # Adjust the legend's position\n",
        "                \"fontsize\": 8,  # Set the font size of the legend\n",
        "                \"labels\": [\"4.51-10.43\", \"10.43-13.56\", \"13.56-17.85\", \"17.85-24.82\", \"24.82-48.35\"]  # Use the custom legend labels\n",
        "          },\n",
        "          axis_on=False,  # Disable the axis display\n",
        "          border_color='black',  # Set the border color of the plot\n",
        "          cmap=\"viridis_r\",  # Use the reversed Viridis colormap\n",
        "          ax=axes[row, col]  # Specify the subplot to draw the plot on\n",
        "     )\n",
        "\n",
        "    # Set the title for the current axis\n",
        "    axes[row, col].set_title(title)"
      ],
      "metadata": {
        "id": "m_ICDmR7FIl-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a 5x5 grid of subplots with a figure size of 20x20\n",
        "fig, axes = plt.subplots(5, 5, figsize=(20, 20))\n",
        "# Add a title to the entire figure with specific font size and position\n",
        "plt.suptitle('Annual mean concentration (Âµg/mÂ³) by departments of $PM_{2.5}$ - 2001-2022', fontsize=14, y=1)\n",
        "\n",
        "# row 0\n",
        "maptma(\"PM25_2001\", \"2001\", 0, 0)  # Map data for 2001 in row 0, column 0\n",
        "maptma(\"PM25_2002\", \"2002\", 0, 1)  # Map data for 2002 in row 0, column 1\n",
        "maptma(\"PM25_2003\", \"2003\", 0, 2)  # Map data for 2003 in row 0, column 2\n",
        "maptma(\"PM25_2004\", \"2004\", 0, 3)  # Map data for 2004 in row 0, column 3\n",
        "maptma(\"PM25_2005\", \"2005\", 0, 4)  # Map data for 2005 in row 0, column 4\n",
        "\n",
        "# row 1\n",
        "maptma(\"PM25_2006\", \"2006\", 1, 0)  # Map data for 2006 in row 1, column 0\n",
        "maptma(\"PM25_2007\", \"2007\", 1, 1)  # Map data for 2007 in row 1, column 1\n",
        "maptma(\"PM25_2008\", \"2008\", 1, 2)  # Map data for 2008 in row 1, column 2\n",
        "maptma(\"PM25_2009\", \"2009\", 1, 3)  # Map data for 2009 in row 1, column 3\n",
        "maptma(\"PM25_2010\", \"2010\", 1, 4)  # Map data for 2010 in row 1, column 4\n",
        "\n",
        "# row 2\n",
        "maptma(\"PM25_2011\", \"2011\", 2, 0)  # Map data for 2011 in row 2, column 0\n",
        "maptma(\"PM25_2012\", \"2012\", 2, 1)  # Map data for 2012 in row 2, column 1\n",
        "maptma(\"PM25_2013\", \"2013\", 2, 2)  # Map data for 2013 in row 2, column 2\n",
        "maptma(\"PM25_2014\", \"2014\", 2, 3)  # Map data for 2014 in row 2, column 3\n",
        "maptma(\"PM25_2015\", \"2015\", 2, 4)  # Map data for 2015 in row 2, column 4\n",
        "\n",
        "# row 3\n",
        "maptma(\"PM25_2016\", \"2016\", 3, 0)  # Map data for 2016 in row 3, column 0\n",
        "maptma(\"PM25_2017\", \"2017\", 3, 1)  # Map data for 2017 in row 3, column 1\n",
        "maptma(\"PM25_2018\", \"2018\", 3, 2)  # Map data for 2018 in row 3, column 2\n",
        "maptma(\"PM25_2019\", \"2019\", 3, 3)  # Map data for 2019 in row 3, column 3\n",
        "maptma(\"PM25_2020\", \"2020\", 3, 4)  # Map data for 2020 in row 3, column 4\n",
        "\n",
        "# row 4\n",
        "maptma(\"PM25_2021\", \"2021\", 4, 0)  # Map data for 2021 in row 4, column 0\n",
        "maptma(\"PM25_2022\", \"2022\", 4, 1)  # Map data for 2022 in row 4, column 1\n",
        "\n",
        "axes[4,2].axis('off')  # Turn off axis for row 4, column 2\n",
        "axes[4,3].axis('off')  # Turn off axis for row 4, column 3\n",
        "axes[4,4].axis('off')  # Turn off axis for row 4, column 4\n",
        "\n",
        "plt.tight_layout()  # Adjust layout to prevent overlap\n",
        "plt.show();  # Display the plot"
      ],
      "metadata": {
        "id": "cPlcPJsRVmoq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### NBA (Normalized Burned Areas)"
      ],
      "metadata": {
        "id": "FqIc62z1_2G7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a copy of  the geodataframe\n",
        "gdf_cl = gdf.copy()"
      ],
      "metadata": {
        "id": "squqbDPa__OC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a list of column names that start with \"NBA_\"\n",
        "nba_columns = [col for col in gdf_cl.columns if col.startswith(\"NBA_\")]"
      ],
      "metadata": {
        "id": "1ydpmhWy__OC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select data to analize\n",
        "selected_data = gdf_cl.loc[:,nba_columns]"
      ],
      "metadata": {
        "id": "vrZapMA___OC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classify the data into 4 quantile groups\n",
        "q4 = mapclassify.Quantiles(selected_data, k=4)\n",
        "q4"
      ],
      "metadata": {
        "id": "6zkDkhgV__OC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Equal Interval Classification\n",
        "ei5 = mapclassify.EqualInterval(selected_data, k=5)\n",
        "ei5"
      ],
      "metadata": {
        "id": "averk2h0__OD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classify the data into groups based on the head/tail breaks algorithm\n",
        "ht = mapclassify.HeadTailBreaks(selected_data)\n",
        "ht"
      ],
      "metadata": {
        "id": "PLk3vTOi__OD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MaximumBreaks classification method\n",
        "mb5 = mapclassify.MaximumBreaks(selected_data, k=5)\n",
        "mb5"
      ],
      "metadata": {
        "id": "5HbSqY6F__OD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the Standard Deviation and Mean classification method to the selected data.\n",
        "msd = mapclassify.StdMean(selected_data)\n",
        "msd"
      ],
      "metadata": {
        "id": "jYWCQcv8__OD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply Fisher-Jenks classification with 5 classes\n",
        "fj5 = mapclassify.FisherJenks(selected_data, k=5)\n",
        "fj5"
      ],
      "metadata": {
        "id": "xhkJ_XUG__OD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bunch classifier objects\n",
        "class5 = q4, ei5, ht, mb5, msd, fj5\n",
        "# Collect ADCM for each classifier\n",
        "fits = np.array([c.adcm for c in class5])\n",
        "# Convert ADCM scores to a DataFrame\n",
        "adcms = pd.DataFrame(fits)\n",
        "# Add classifier names\n",
        "adcms[\"classifier\"] = [c.name for c in class5]\n",
        "# Add column names to the ADCM\n",
        "adcms.columns = [\"ADCM\", \"Classifier\"]\n",
        "ax = sns.barplot(\n",
        "    y=\"Classifier\", x=\"ADCM\", data=adcms, hue= adcms[\"Classifier\"],  legend=False\n",
        ")"
      ],
      "metadata": {
        "id": "eMppP49u__OD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Create choropleth maps of NBA\n"
      ],
      "metadata": {
        "id": "QQCN1-lq__OD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Two classifiers have the lowest ACDM: FisherJenks and HeadTailBreaks. We'll select FisherJenks as the classifier to create the choropleth maps."
      ],
      "metadata": {
        "id": "PrxFp4SU__OD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the bins to a list for further processing\n",
        "bins = fj5.bins.tolist()\n",
        "bins"
      ],
      "metadata": {
        "id": "9irW3jjW__OE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will include a zero (0) value at the first position of the bin list, since in some departments and years no wildfires were detected by satellites."
      ],
      "metadata": {
        "id": "xsWLSsZNVQft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# insert 0 at 0 position\n",
        "bins.insert(0, 0)\n",
        "bins"
      ],
      "metadata": {
        "id": "GTTMQGfeBFu7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will create a function to set a custom classification scheme based on FisherJenks"
      ],
      "metadata": {
        "id": "WShrX_xK__OE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract intervals from bins\n",
        "intervals = [f\"{bins[i]:.2f}-{bins[i+1]:.2f}\" for i in range(len(bins)-1)]\n",
        "intervals"
      ],
      "metadata": {
        "id": "OlpZCVySCHaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add '0.00' at postion 0 to the list of intervals\n",
        "intervals.insert(0, '0.00')\n",
        "intervals"
      ],
      "metadata": {
        "id": "WcR-d0BPUFzC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def maptma(colname, title, row, col):\n",
        "    # Create a custom classification using UserDefined\n",
        "    classification = mapclassify.UserDefined(gdf_cl[colname], bins)\n",
        "\n",
        "    classification.plot(\n",
        "          gdf,  # GeoDataFrame containing the data to be plotted\n",
        "          legend=True,  # Enable the legend for the plot\n",
        "          legend_kwds={\n",
        "                \"fmt\": \"{:.0f}\",  # Format the legend labels as integers\n",
        "                # \"loc\": \"upper right\",  # Position the legend in the upper right corner\n",
        "                \"bbox_to_anchor\": (1.30, 0.4),  # Adjust the legend's position\n",
        "                \"fontsize\": 8,  # Set the font size of the legend\n",
        "                \"labels\":  intervals # Use the custom legend labels\n",
        "          },\n",
        "          axis_on=False,  # Disable the axis display\n",
        "          border_color='black',  # Set the border color of the plot\n",
        "          cmap=\"viridis_r\",  # Use the reversed Viridis colormap\n",
        "          ax=axes[row, col]  # Specify the subplot to draw the plot on\n",
        "     )\n",
        "\n",
        "    # Set the title for the current axis\n",
        "    axes[row, col].set_title(title)"
      ],
      "metadata": {
        "id": "GPV0yMPE__OE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a 5x5 grid of subplots with a figure size of 20x20\n",
        "fig, axes = plt.subplots(5, 5, figsize=(20, 20))\n",
        "# Add a title to the entire figure with specific font size and position\n",
        "plt.suptitle('Normalized Burned Area (km$^2$) per 1000  km$^2$ by departments- 2001-2022', fontsize=14, y=1)\n",
        "\n",
        "# row 0\n",
        "maptma(\"NBA_2001\", \"2001\", 0, 0)  # Map data for 2001 in row 0, column 0\n",
        "maptma(\"NBA_2002\", \"2002\", 0, 1)  # Map data for 2002 in row 0, column 1\n",
        "maptma(\"NBA_2003\", \"2003\", 0, 2)  # Map data for 2003 in row 0, column 2\n",
        "maptma(\"NBA_2004\", \"2004\", 0, 3)  # Map data for 2004 in row 0, column 3\n",
        "maptma(\"NBA_2005\", \"2005\", 0, 4)  # Map data for 2005 in row 0, column 4\n",
        "\n",
        "# row 1\n",
        "maptma(\"NBA_2006\", \"2006\", 1, 0)  # Map data for 2006 in row 1, column 0\n",
        "maptma(\"NBA_2007\", \"2007\", 1, 1)  # Map data for 2007 in row 1, column 1\n",
        "maptma(\"NBA_2008\", \"2008\", 1, 2)  # Map data for 2008 in row 1, column 2\n",
        "maptma(\"NBA_2009\", \"2009\", 1, 3)  # Map data for 2009 in row 1, column 3\n",
        "maptma(\"NBA_2010\", \"2010\", 1, 4)  # Map data for 2010 in row 1, column 4\n",
        "\n",
        "# row 2\n",
        "maptma(\"NBA_2011\", \"2011\", 2, 0)  # Map data for 2011 in row 2, column 0\n",
        "maptma(\"NBA_2012\", \"2012\", 2, 1)  # Map data for 2012 in row 2, column 1\n",
        "maptma(\"NBA_2013\", \"2013\", 2, 2)  # Map data for 2013 in row 2, column 2\n",
        "maptma(\"NBA_2014\", \"2014\", 2, 3)  # Map data for 2014 in row 2, column 3\n",
        "maptma(\"NBA_2015\", \"2015\", 2, 4)  # Map data for 2015 in row 2, column 4\n",
        "\n",
        "# row 3\n",
        "maptma(\"NBA_2016\", \"2016\", 3, 0)  # Map data for 2016 in row 3, column 0\n",
        "maptma(\"NBA_2017\", \"2017\", 3, 1)  # Map data for 2017 in row 3, column 1\n",
        "maptma(\"NBA_2018\", \"2018\", 3, 2)  # Map data for 2018 in row 3, column 2\n",
        "maptma(\"NBA_2019\", \"2019\", 3, 3)  # Map data for 2019 in row 3, column 3\n",
        "maptma(\"NBA_2020\", \"2020\", 3, 4)  # Map data for 2020 in row 3, column 4\n",
        "\n",
        "# row 4\n",
        "maptma(\"NBA_2021\", \"2021\", 4, 0)  # Map data for 2021 in row 4, column 0\n",
        "maptma(\"NBA_2022\", \"2022\", 4, 1)  # Map data for 2022 in row 4, column 1\n",
        "\n",
        "axes[4,2].axis('off')  # Turn off axis for row 4, column 2\n",
        "axes[4,3].axis('off')  # Turn off axis for row 4, column 3\n",
        "axes[4,4].axis('off')  # Turn off axis for row 4, column 4\n",
        "\n",
        "plt.tight_layout()  # Adjust layout to prevent overlap\n",
        "plt.show();  # Display the plot"
      ],
      "metadata": {
        "id": "8X8YPxA2__OE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Population density (PD)"
      ],
      "metadata": {
        "id": "VBTPm1kEW6Lt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a copy of  the geodataframe\n",
        "gdf_cl = gdf.copy()"
      ],
      "metadata": {
        "id": "96OB9yruY6tG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a list of column names that start with \"PD_\"\n",
        "pd_columns = [col for col in gdf_cl.columns if col.startswith(\"PD_\")]"
      ],
      "metadata": {
        "id": "7EWBcKA6Y6tG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select data to analize\n",
        "selected_data = gdf_cl.loc[:,pd_columns]"
      ],
      "metadata": {
        "id": "W18WgFNBY6tG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classify the data into 4 quantile groups\n",
        "q4 = mapclassify.Quantiles(selected_data, k=4)\n",
        "q4"
      ],
      "metadata": {
        "id": "0BnpTHmHY6tG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Equal Interval Classification\n",
        "ei5 = mapclassify.EqualInterval(selected_data, k=5)\n",
        "ei5"
      ],
      "metadata": {
        "id": "kqZEN5YYY6tG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classify the data into groups based on the head/tail breaks algorithm\n",
        "ht = mapclassify.HeadTailBreaks(selected_data)\n",
        "ht"
      ],
      "metadata": {
        "id": "2B41YKbuY6tG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MaximumBreaks classification method\n",
        "mb5 = mapclassify.MaximumBreaks(selected_data, k=5)\n",
        "mb5"
      ],
      "metadata": {
        "id": "pCm4mQR8Y6tH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the Standard Deviation and Mean classification method to the selected data.\n",
        "msd = mapclassify.StdMean(selected_data)\n",
        "msd"
      ],
      "metadata": {
        "id": "kC-3mUL8Y6tH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply Fisher-Jenks classification with 5 classes\n",
        "fj5 = mapclassify.FisherJenks(selected_data, k=5)\n",
        "fj5"
      ],
      "metadata": {
        "id": "oW5OKRIjY6tH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bunch classifier objects\n",
        "class5 = q4, ei5, ht, mb5, msd, fj5\n",
        "# Collect ADCM for each classifier\n",
        "fits = np.array([c.adcm for c in class5])\n",
        "# Convert ADCM scores to a DataFrame\n",
        "adcms = pd.DataFrame(fits)\n",
        "# Add classifier names\n",
        "adcms[\"classifier\"] = [c.name for c in class5]\n",
        "# Add column names to the ADCM\n",
        "adcms.columns = [\"ADCM\", \"Classifier\"]\n",
        "ax = sns.barplot(\n",
        "    y=\"Classifier\", x=\"ADCM\", data=adcms, hue= adcms[\"Classifier\"],  legend=False\n",
        ")"
      ],
      "metadata": {
        "id": "_tHaH8w8Y6tH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Create choropleth maps of PD\n"
      ],
      "metadata": {
        "id": "1IRaDXIzY6tH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We observed that the Fisherâ€“Jenks and Headâ€“Tail Breaks classifiers produced the lowest ACDM values. However, in this case, they do not provide a clear visual spatial pattern for the PD variable. Therefore, we will use the Quantile classifier instead"
      ],
      "metadata": {
        "id": "al9ISLmVY6tH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the bins to a list for further processing\n",
        "bins = q4.bins.tolist()\n",
        "bins"
      ],
      "metadata": {
        "id": "t58zw72jY6tH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add 0.02 to bin for labeling\n",
        "bins_label  = bins.copy()\n",
        "bins_label.insert(0, 0.02)\n",
        "\n",
        "# Extract intervals from bins\n",
        "intervals = [f\"{bins_label[i]:.2f}-{bins_label[i+1]:.2f}\" for i in range(len(bins_label)-1)]\n",
        "intervals"
      ],
      "metadata": {
        "id": "S0wd4Xm8aG8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will create a function to set a custom classification scheme based on FisherJenks"
      ],
      "metadata": {
        "id": "W8iVEQgzY6tH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def maptma(colname, title, row, col):\n",
        "    # Create a custom classification using UserDefined\n",
        "    classification = mapclassify.UserDefined(gdf_cl[colname], bins)\n",
        "\n",
        "    classification.plot(\n",
        "          gdf,  # GeoDataFrame containing the data to be plotted\n",
        "          legend=True,  # Enable the legend for the plot\n",
        "          legend_kwds={\n",
        "                \"fmt\": \"{:.0f}\",  # Format the legend labels as integers\n",
        "                # \"loc\": \"upper right\",  # Position the legend in the upper right corner\n",
        "                \"bbox_to_anchor\": (1.3, 0.4),  # Adjust the legend's position\n",
        "                \"fontsize\": 8,  # Set the font size of the legend\n",
        "                \"labels\": intervals # Use the custom legend labels\n",
        "          },\n",
        "          axis_on=False,  # Disable the axis display\n",
        "          border_color='black',  # Set the border color of the plot\n",
        "          cmap=\"viridis_r\",  # Use the reversed Viridis colormap\n",
        "          ax=axes[row, col]  # Specify the subplot to draw the plot on\n",
        "     )\n",
        "\n",
        "    # Set the title for the current axis\n",
        "    axes[row, col].set_title(title)"
      ],
      "metadata": {
        "id": "FgVN6iv_Y6tH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a 5x5 grid of subplots with a figure size of 20x20\n",
        "fig, axes = plt.subplots(5, 5, figsize=(20, 20))\n",
        "# Add a title to the entire figure with specific font size and position\n",
        "plt.suptitle('Population Density (km$^2$/hab) by departments - 2001-2022', fontsize=14, y=1)\n",
        "\n",
        "# row 0\n",
        "maptma(\"PD_2001\", \"2001\", 0, 0)  # Map data for 2001 in row 0, column 0\n",
        "maptma(\"PD_2002\", \"2002\", 0, 1)  # Map data for 2002 in row 0, column 1\n",
        "maptma(\"PD_2003\", \"2003\", 0, 2)  # Map data for 2003 in row 0, column 2\n",
        "maptma(\"PD_2004\", \"2004\", 0, 3)  # Map data for 2004 in row 0, column 3\n",
        "maptma(\"PD_2005\", \"2005\", 0, 4)  # Map data for 2005 in row 0, column 4\n",
        "\n",
        "# row 1\n",
        "maptma(\"PD_2006\", \"2006\", 1, 0)  # Map data for 2006 in row 1, column 0\n",
        "maptma(\"PD_2007\", \"2007\", 1, 1)  # Map data for 2007 in row 1, column 1\n",
        "maptma(\"PD_2008\", \"2008\", 1, 2)  # Map data for 2008 in row 1, column 2\n",
        "maptma(\"PD_2009\", \"2009\", 1, 3)  # Map data for 2009 in row 1, column 3\n",
        "maptma(\"PD_2010\", \"2010\", 1, 4)  # Map data for 2010 in row 1, column 4\n",
        "\n",
        "# row 2\n",
        "maptma(\"PD_2011\", \"2011\", 2, 0)  # Map data for 2011 in row 2, column 0\n",
        "maptma(\"PD_2012\", \"2012\", 2, 1)  # Map data for 2012 in row 2, column 1\n",
        "maptma(\"PD_2013\", \"2013\", 2, 2)  # Map data for 2013 in row 2, column 2\n",
        "maptma(\"PD_2014\", \"2014\", 2, 3)  # Map data for 2014 in row 2, column 3\n",
        "maptma(\"PD_2015\", \"2015\", 2, 4)  # Map data for 2015 in row 2, column 4\n",
        "\n",
        "# row 3\n",
        "maptma(\"PD_2016\", \"2016\", 3, 0)  # Map data for 2016 in row 3, column 0\n",
        "maptma(\"PD_2017\", \"2017\", 3, 1)  # Map data for 2017 in row 3, column 1\n",
        "maptma(\"PD_2018\", \"2018\", 3, 2)  # Map data for 2018 in row 3, column 2\n",
        "maptma(\"PD_2019\", \"2019\", 3, 3)  # Map data for 2019 in row 3, column 3\n",
        "maptma(\"PD_2020\", \"2020\", 3, 4)  # Map data for 2020 in row 3, column 4\n",
        "\n",
        "# row 4\n",
        "maptma(\"PD_2021\", \"2021\", 4, 0)  # Map data for 2021 in row 4, column 0\n",
        "maptma(\"PD_2022\", \"2022\", 4, 1)  # Map data for 2022 in row 4, column 1\n",
        "\n",
        "axes[4,2].axis('off')  # Turn off axis for row 4, column 2\n",
        "axes[4,3].axis('off')  # Turn off axis for row 4, column 3\n",
        "axes[4,4].axis('off')  # Turn off axis for row 4, column 4\n",
        "\n",
        "plt.tight_layout()  # Adjust layout to prevent overlap\n",
        "plt.show();  # Display the plot"
      ],
      "metadata": {
        "id": "-etI4XnRY6tH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### PDPM25 (Population Desity X Particulate Matter < 2.5 um (PM2.5)"
      ],
      "metadata": {
        "id": "4_LKaiDoaNal"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a copy of  the geodataframe\n",
        "gdf_cl = gdf.copy()"
      ],
      "metadata": {
        "id": "RH26IzQ_b9lC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a list of column names that start with \"PDPM25_\"\n",
        "pdpm25_columns = [col for col in gdf_cl.columns if col.startswith(\"PDPM25_\")]"
      ],
      "metadata": {
        "id": "EQ6nWXfHb9lC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select data to analize\n",
        "selected_data = gdf_cl.loc[:,pdpm25_columns]"
      ],
      "metadata": {
        "id": "Z1reKOQwb9lC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classify the data into 4 quantile groups\n",
        "q4 = mapclassify.Quantiles(selected_data, k=4)\n",
        "q4"
      ],
      "metadata": {
        "id": "EM52KPdjb9lC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Equal Interval Classification\n",
        "ei5 = mapclassify.EqualInterval(selected_data, k=5)\n",
        "ei5"
      ],
      "metadata": {
        "id": "s_1taH08b9lC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classify the data into groups based on the head/tail breaks algorithm\n",
        "ht = mapclassify.HeadTailBreaks(selected_data)\n",
        "ht"
      ],
      "metadata": {
        "id": "WV1OkYFlb9lC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MaximumBreaks classification method\n",
        "mb5 = mapclassify.MaximumBreaks(selected_data, k=5)\n",
        "mb5"
      ],
      "metadata": {
        "id": "plkQKxhtb9lC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the Standard Deviation and Mean classification method to the selected data.\n",
        "msd = mapclassify.StdMean(selected_data)\n",
        "msd"
      ],
      "metadata": {
        "id": "w6MYt4Ksb9lD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply Fisher-Jenks classification with 5 classes\n",
        "fj5 = mapclassify.FisherJenks(selected_data, k=5)\n",
        "fj5"
      ],
      "metadata": {
        "id": "RDovG6Vbb9lD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bunch classifier objects\n",
        "class5 = q4, ei5, ht, mb5, msd, fj5\n",
        "# Collect ADCM for each classifier\n",
        "fits = np.array([c.adcm for c in class5])\n",
        "# Convert ADCM scores to a DataFrame\n",
        "adcms = pd.DataFrame(fits)\n",
        "# Add classifier names\n",
        "adcms[\"classifier\"] = [c.name for c in class5]\n",
        "# Add column names to the ADCM\n",
        "adcms.columns = [\"ADCM\", \"Classifier\"]\n",
        "ax = sns.barplot(\n",
        "    y=\"Classifier\", x=\"ADCM\", data=adcms, hue= adcms[\"Classifier\"],  legend=False\n",
        ")"
      ],
      "metadata": {
        "id": "x0uiezk1b9lD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Create choropleth maps of PDPM25\n"
      ],
      "metadata": {
        "id": "O-y0o5mzb9lD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We observed that the Fisherâ€“Jenks and Headâ€“Tail Breaks classifiers produced the lowest ACDM values. However, in this case, they do not provide a clear visual spatial pattern for the PD variable. Therefore, we will use the Quantile classifier instead"
      ],
      "metadata": {
        "id": "mQeMC9ITb9lD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the bins to a list for further processing\n",
        "bins = q4.bins.tolist()\n",
        "bins"
      ],
      "metadata": {
        "id": "RUQMNdhrb9lD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add 0.19 to bin for labeling\n",
        "bins_label  = bins.copy()\n",
        "bins_label.insert(0, 0.19)\n",
        "\n",
        "# Extract intervals from bins\n",
        "intervals = [f\"{bins_label[i]:.2f}-{bins_label[i+1]:.2f}\" for i in range(len(bins_label)-1)]\n",
        "intervals"
      ],
      "metadata": {
        "id": "FdOtktcgb9lD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will create a function to set a custom classification scheme based on FisherJenks"
      ],
      "metadata": {
        "id": "5PXGnt7sb9lD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def maptma(colname, title, row, col):\n",
        "    # Create a custom classification using UserDefined\n",
        "    classification = mapclassify.UserDefined(gdf_cl[colname], bins)\n",
        "\n",
        "    classification.plot(\n",
        "          gdf,  # GeoDataFrame containing the data to be plotted\n",
        "          legend=True,  # Enable the legend for the plot\n",
        "          legend_kwds={\n",
        "                \"fmt\": \"{:.0f}\",  # Format the legend labels as integers\n",
        "                # \"loc\": \"upper right\",  # Position the legend in the upper right corner\n",
        "                \"bbox_to_anchor\": (1.35, 0.3),  # Adjust the legend's position\n",
        "                \"fontsize\": 8,  # Set the font size of the legend\n",
        "                \"labels\": intervals # Use the custom legend labels\n",
        "          },\n",
        "          axis_on=False,  # Disable the axis display\n",
        "          border_color='black',  # Set the border color of the plot\n",
        "          cmap=\"viridis_r\",  # Use the reversed Viridis colormap\n",
        "          ax=axes[row, col]  # Specify the subplot to draw the plot on\n",
        "     )\n",
        "\n",
        "    # Set the title for the current axis\n",
        "    axes[row, col].set_title(title)"
      ],
      "metadata": {
        "id": "kHtuTzgIb9lD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a 5x5 grid of subplots with a figure size of 20x20\n",
        "fig, axes = plt.subplots(5, 5, figsize=(20, 20))\n",
        "# Add a title to the entire figure with specific font size and position\n",
        "plt.suptitle('Population Density X $PM_{2.5}$ by departments - 2001-2022', fontsize=14, y=1)\n",
        "\n",
        "# row 0\n",
        "maptma(\"PDPM25_2001\", \"2001\", 0, 0)  # Map data for 2001 in row 0, column 0\n",
        "maptma(\"PDPM25_2002\", \"2002\", 0, 1)  # Map data for 2002 in row 0, column 1\n",
        "maptma(\"PDPM25_2003\", \"2003\", 0, 2)  # Map data for 2003 in row 0, column 2\n",
        "maptma(\"PDPM25_2004\", \"2004\", 0, 3)  # Map data for 2004 in row 0, column 3\n",
        "maptma(\"PDPM25_2005\", \"2005\", 0, 4)  # Map data for 2005 in row 0, column 4\n",
        "\n",
        "# row 1\n",
        "maptma(\"PDPM25_2006\", \"2006\", 1, 0)  # Map data for 2006 in row 1, column 0\n",
        "maptma(\"PDPM25_2007\", \"2007\", 1, 1)  # Map data for 2007 in row 1, column 1\n",
        "maptma(\"PDPM25_2008\", \"2008\", 1, 2)  # Map data for 2008 in row 1, column 2\n",
        "maptma(\"PDPM25_2009\", \"2009\", 1, 3)  # Map data for 2009 in row 1, column 3\n",
        "maptma(\"PDPM25_2010\", \"2010\", 1, 4)  # Map data for 2010 in row 1, column 4\n",
        "\n",
        "# row 2\n",
        "maptma(\"PDPM25_2011\", \"2011\", 2, 0)  # Map data for 2011 in row 2, column 0\n",
        "maptma(\"PDPM25_2012\", \"2012\", 2, 1)  # Map data for 2012 in row 2, column 1\n",
        "maptma(\"PDPM25_2013\", \"2013\", 2, 2)  # Map data for 2013 in row 2, column 2\n",
        "maptma(\"PDPM25_2014\", \"2014\", 2, 3)  # Map data for 2014 in row 2, column 3\n",
        "maptma(\"PDPM25_2015\", \"2015\", 2, 4)  # Map data for 2015 in row 2, column 4\n",
        "\n",
        "# row 3\n",
        "maptma(\"PDPM25_2016\", \"2016\", 3, 0)  # Map data for 2016 in row 3, column 0\n",
        "maptma(\"PDPM25_2017\", \"2017\", 3, 1)  # Map data for 2017 in row 3, column 1\n",
        "maptma(\"PDPM25_2018\", \"2018\", 3, 2)  # Map data for 2018 in row 3, column 2\n",
        "maptma(\"PDPM25_2019\", \"2019\", 3, 3)  # Map data for 2019 in row 3, column 3\n",
        "maptma(\"PDPM25_2020\", \"2020\", 3, 4)  # Map data for 2020 in row 3, column 4\n",
        "\n",
        "# row 4\n",
        "maptma(\"PDPM25_2021\", \"2021\", 4, 0)  # Map data for 2021 in row 4, column 0\n",
        "maptma(\"PDPM25_2022\", \"2022\", 4, 1)  # Map data for 2022 in row 4, column 1\n",
        "\n",
        "axes[4,2].axis('off')  # Turn off axis for row 4, column 2\n",
        "axes[4,3].axis('off')  # Turn off axis for row 4, column 3\n",
        "axes[4,4].axis('off')  # Turn off axis for row 4, column 4\n",
        "\n",
        "plt.tight_layout()  # Adjust layout to prevent overlap\n",
        "plt.show();  # Display the plot"
      ],
      "metadata": {
        "id": "qmhxvpA3b9lD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### NAGRT (Normalized Agricultural and Livestock Transition areas)"
      ],
      "metadata": {
        "id": "Tppt10--lnq3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a copy of  the geodataframe\n",
        "gdf_cl = gdf.copy()"
      ],
      "metadata": {
        "id": "zakr1MBSmZP0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a list of column names that start with \"NAGRT_\"\n",
        "nagrt_columns = [col for col in gdf_cl.columns if col.startswith(\"NAGRT_\")]"
      ],
      "metadata": {
        "id": "gL9zbrLXmZP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select data to analize\n",
        "selected_data = gdf_cl.loc[:,nagrt_columns]"
      ],
      "metadata": {
        "id": "0BPocWsfmZP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classify the data into 4 quantile groups\n",
        "q4 = mapclassify.Quantiles(selected_data, k=4)\n",
        "q4"
      ],
      "metadata": {
        "id": "D5Z3M0iWmZP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Equal Interval Classification\n",
        "ei5 = mapclassify.EqualInterval(selected_data, k=5)\n",
        "ei5"
      ],
      "metadata": {
        "id": "-_2-7edwmZP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classify the data into groups based on the head/tail breaks algorithm\n",
        "ht = mapclassify.HeadTailBreaks(selected_data)\n",
        "ht"
      ],
      "metadata": {
        "id": "M8ddHpEzmZP3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MaximumBreaks classification method\n",
        "mb5 = mapclassify.MaximumBreaks(selected_data, k=5)\n",
        "mb5"
      ],
      "metadata": {
        "id": "ATZQ0K2EmZP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the Standard Deviation and Mean classification method to the selected data.\n",
        "msd = mapclassify.StdMean(selected_data)\n",
        "msd"
      ],
      "metadata": {
        "id": "XPhR6csImZP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply Fisher-Jenks classification with 5 classes\n",
        "fj5 = mapclassify.FisherJenks(selected_data, k=5)\n",
        "fj5"
      ],
      "metadata": {
        "id": "6CyQPsPnmZP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bunch classifier objects\n",
        "class5 = q4, ei5, ht, mb5, msd, fj5\n",
        "# Collect ADCM for each classifier\n",
        "fits = np.array([c.adcm for c in class5])\n",
        "# Convert ADCM scores to a DataFrame\n",
        "adcms = pd.DataFrame(fits)\n",
        "# Add classifier names\n",
        "adcms[\"classifier\"] = [c.name for c in class5]\n",
        "# Add column names to the ADCM\n",
        "adcms.columns = [\"ADCM\", \"Classifier\"]\n",
        "ax = sns.barplot(\n",
        "    y=\"Classifier\", x=\"ADCM\", data=adcms, hue= adcms[\"Classifier\"],  legend=False\n",
        ")"
      ],
      "metadata": {
        "id": "Eou7niDgmZP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Create choropleth maps of NAGRT\n"
      ],
      "metadata": {
        "id": "HiYe28t0mZP6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Two classifiers have the lowest ACDM: FisherJenks and HeadTailBreaks. We'll select FisherJenks as the classifier to create the choropleth maps."
      ],
      "metadata": {
        "id": "yTCUm9RtmZP6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the bins to a list for further processing\n",
        "bins = fj5.bins.tolist()\n",
        "bins"
      ],
      "metadata": {
        "id": "t4ZNl-MumZP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# insert 0 at 0 position\n",
        "bins.insert(0, 0)\n",
        "bins"
      ],
      "metadata": {
        "id": "Q3vYQ7QBpgMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract intervals from bins\n",
        "intervals = [f\"{bins[i]:.2f}-{bins[i+1]:.2f}\" for i in range(len(bins)-1)]\n",
        "intervals"
      ],
      "metadata": {
        "id": "5sewYJIopkXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add '0.00' at postion 0 to the list of intervals\n",
        "intervals.insert(0, '0.00')\n",
        "intervals"
      ],
      "metadata": {
        "id": "hu00vpUTp40e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will create a function to set a custom classification scheme based on FisherJenks"
      ],
      "metadata": {
        "id": "OYMti4TmmZP7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def maptma(colname, title, row, col):\n",
        "    # Create a custom classification using UserDefined\n",
        "    classification = mapclassify.UserDefined(gdf_cl[colname], bins)\n",
        "\n",
        "    classification.plot(\n",
        "          gdf,  # GeoDataFrame containing the data to be plotted\n",
        "          legend=True,  # Enable the legend for the plot\n",
        "          legend_kwds={\n",
        "                \"fmt\": \"{:.0f}\",  # Format the legend labels as integers\n",
        "                # \"loc\": \"upper right\",  # Position the legend in the upper right corner\n",
        "                \"bbox_to_anchor\": (1.25, 0.4),  # Adjust the legend's position\n",
        "                \"fontsize\": 8,  # Set the font size of the legend\n",
        "                \"labels\": intervals  # Use the custom legend labels\n",
        "          },\n",
        "          axis_on=False,  # Disable the axis display\n",
        "          border_color='black',  # Set the border color of the plot\n",
        "          cmap=\"viridis_r\",  # Use the reversed Viridis colormap\n",
        "          ax=axes[row, col]  # Specify the subplot to draw the plot on\n",
        "     )\n",
        "\n",
        "    # Set the title for the current axis\n",
        "    axes[row, col].set_title(title)"
      ],
      "metadata": {
        "id": "l8BpWaxImZP8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a 5x5 grid of subplots with a figure size of 20x20\n",
        "fig, axes = plt.subplots(5, 5, figsize=(20, 20))\n",
        "# Add a title to the entire figure with specific font size and position\n",
        "plt.suptitle('Normalized Agricultural and Livestock Transition areas (km$^2$) per 1000 km$^2$ by departments- 2001-2022', fontsize=14, y=1)\n",
        "\n",
        "# row 0\n",
        "maptma(\"NAGRT_2001\", \"2001\", 0, 0)  # Map data for 2001 in row 0, column 0\n",
        "maptma(\"NAGRT_2002\", \"2002\", 0, 1)  # Map data for 2002 in row 0, column 1\n",
        "maptma(\"NAGRT_2003\", \"2003\", 0, 2)  # Map data for 2003 in row 0, column 2\n",
        "maptma(\"NAGRT_2004\", \"2004\", 0, 3)  # Map data for 2004 in row 0, column 3\n",
        "maptma(\"NAGRT_2005\", \"2005\", 0, 4)  # Map data for 2005 in row 0, column 4\n",
        "\n",
        "# row 1\n",
        "maptma(\"NAGRT_2006\", \"2006\", 1, 0)  # Map data for 2006 in row 1, column 0\n",
        "maptma(\"NAGRT_2007\", \"2007\", 1, 1)  # Map data for 2007 in row 1, column 1\n",
        "maptma(\"NAGRT_2008\", \"2008\", 1, 2)  # Map data for 2008 in row 1, column 2\n",
        "maptma(\"NAGRT_2009\", \"2009\", 1, 3)  # Map data for 2009 in row 1, column 3\n",
        "maptma(\"NAGRT_2010\", \"2010\", 1, 4)  # Map data for 2010 in row 1, column 4\n",
        "\n",
        "# row 2\n",
        "maptma(\"NAGRT_2011\", \"2011\", 2, 0)  # Map data for 2011 in row 2, column 0\n",
        "maptma(\"NAGRT_2012\", \"2012\", 2, 1)  # Map data for 2012 in row 2, column 1\n",
        "maptma(\"NAGRT_2013\", \"2013\", 2, 2)  # Map data for 2013 in row 2, column 2\n",
        "maptma(\"NAGRT_2014\", \"2014\", 2, 3)  # Map data for 2014 in row 2, column 3\n",
        "maptma(\"NAGRT_2015\", \"2015\", 2, 4)  # Map data for 2015 in row 2, column 4\n",
        "\n",
        "# row 3\n",
        "maptma(\"NAGRT_2016\", \"2016\", 3, 0)  # Map data for 2016 in row 3, column 0\n",
        "maptma(\"NAGRT_2017\", \"2017\", 3, 1)  # Map data for 2017 in row 3, column 1\n",
        "maptma(\"NAGRT_2018\", \"2018\", 3, 2)  # Map data for 2018 in row 3, column 2\n",
        "maptma(\"NAGRT_2019\", \"2019\", 3, 3)  # Map data for 2019 in row 3, column 3\n",
        "maptma(\"NAGRT_2020\", \"2020\", 3, 4)  # Map data for 2020 in row 3, column 4\n",
        "\n",
        "# row 4\n",
        "maptma(\"NAGRT_2021\", \"2021\", 4, 0)  # Map data for 2021 in row 4, column 0\n",
        "maptma(\"NAGRT_2022\", \"2022\", 4, 1)  # Map data for 2022 in row 4, column 1\n",
        "\n",
        "axes[4,2].axis('off')  # Turn off axis for row 4, column 2\n",
        "axes[4,3].axis('off')  # Turn off axis for row 4, column 3\n",
        "axes[4,4].axis('off')  # Turn off axis for row 4, column 4\n",
        "\n",
        "plt.tight_layout()  # Adjust layout to prevent overlap\n",
        "plt.show();  # Display the plot"
      ],
      "metadata": {
        "id": "WGdDYXvfmZP8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### NNWVT (Normalized Natural Wooded Vegetation Transitions areas)"
      ],
      "metadata": {
        "id": "jHrI2f7Grp8r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a copy of  the geodataframe\n",
        "gdf_cl = gdf.copy()"
      ],
      "metadata": {
        "id": "WNrcyuXQsPwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a list of column names that start with \"NNWVT_\"\n",
        "nnwvt_columns = [col for col in gdf_cl.columns if col.startswith(\"NNWVT_\")]"
      ],
      "metadata": {
        "id": "8RAZTMZysPwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select data to analize\n",
        "selected_data = gdf_cl.loc[:,nnwvt_columns]"
      ],
      "metadata": {
        "id": "s5Dk_UBzsPwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classify the data into 4 quantile groups\n",
        "q4 = mapclassify.Quantiles(selected_data, k=4)\n",
        "q4"
      ],
      "metadata": {
        "id": "uWC8sMF5sPwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Equal Interval Classification\n",
        "ei5 = mapclassify.EqualInterval(selected_data, k=5)\n",
        "ei5"
      ],
      "metadata": {
        "id": "o-2RTU68sPwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classify the data into groups based on the head/tail breaks algorithm\n",
        "ht = mapclassify.HeadTailBreaks(selected_data)\n",
        "ht"
      ],
      "metadata": {
        "id": "ir-8DNxMsPwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MaximumBreaks classification method\n",
        "mb5 = mapclassify.MaximumBreaks(selected_data, k=5)\n",
        "mb5"
      ],
      "metadata": {
        "id": "1D5kzw8qsPwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the Standard Deviation and Mean classification method to the selected data.\n",
        "msd = mapclassify.StdMean(selected_data)\n",
        "msd"
      ],
      "metadata": {
        "id": "Tgnpdjf2sPwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply Fisher-Jenks classification with 5 classes\n",
        "fj5 = mapclassify.FisherJenks(selected_data, k=5)\n",
        "fj5"
      ],
      "metadata": {
        "id": "d3qze6p4sPwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bunch classifier objects\n",
        "class5 = q4, ei5, ht, mb5, msd, fj5\n",
        "# Collect ADCM for each classifier\n",
        "fits = np.array([c.adcm for c in class5])\n",
        "# Convert ADCM scores to a DataFrame\n",
        "adcms = pd.DataFrame(fits)\n",
        "# Add classifier names\n",
        "adcms[\"classifier\"] = [c.name for c in class5]\n",
        "# Add column names to the ADCM\n",
        "adcms.columns = [\"ADCM\", \"Classifier\"]\n",
        "ax = sns.barplot(\n",
        "    y=\"Classifier\", x=\"ADCM\", data=adcms, hue= adcms[\"Classifier\"],  legend=False\n",
        ")"
      ],
      "metadata": {
        "id": "xml_heQPsPwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Create choropleth maps of NNWVT"
      ],
      "metadata": {
        "id": "XySAEbyfsPwT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Two classifiers have the lowest ACDM: FisherJenks and HeadTailBreaks. We'll select FisherJenks as the classifier to create the choropleth maps."
      ],
      "metadata": {
        "id": "NL_IbTjHsPwT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the bins to a list for further processing\n",
        "bins = fj5.bins.tolist()\n",
        "bins"
      ],
      "metadata": {
        "id": "X51beP2hsPwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# insert 0 at 0 position\n",
        "bins.insert(0, 0)\n",
        "bins"
      ],
      "metadata": {
        "id": "RIGb6kTgsPwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract intervals from bins\n",
        "intervals = [f\"{bins[i]:.2f}-{bins[i+1]:.2f}\" for i in range(len(bins)-1)]\n",
        "intervals"
      ],
      "metadata": {
        "id": "C5sE-IRcsPwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add '0.00' at postion 0 to the list of intervals\n",
        "intervals.insert(0, '0.00')\n",
        "intervals"
      ],
      "metadata": {
        "id": "hAs-1InnsPwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will create a function to set a custom classification scheme based on FisherJenks"
      ],
      "metadata": {
        "id": "CC_65Jf3sPwU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def maptma(colname, title, row, col):\n",
        "    # Create a custom classification using UserDefined\n",
        "    classification = mapclassify.UserDefined(gdf_cl[colname], bins)\n",
        "\n",
        "    classification.plot(\n",
        "          gdf,  # GeoDataFrame containing the data to be plotted\n",
        "          legend=True,  # Enable the legend for the plot\n",
        "          legend_kwds={\n",
        "                \"fmt\": \"{:.0f}\",  # Format the legend labels as integers\n",
        "                # \"loc\": \"upper right\",  # Position the legend in the upper right corner\n",
        "                \"bbox_to_anchor\": (1.25, 0.4),  # Adjust the legend's position\n",
        "                \"fontsize\": 8,  # Set the font size of the legend\n",
        "                \"labels\": intervals  # Use the custom legend labels\n",
        "          },\n",
        "          axis_on=False,  # Disable the axis display\n",
        "          border_color='black',  # Set the border color of the plot\n",
        "          cmap=\"viridis_r\",  # Use the reversed Viridis colormap\n",
        "          ax=axes[row, col]  # Specify the subplot to draw the plot on\n",
        "     )\n",
        "\n",
        "    # Set the title for the current axis\n",
        "    axes[row, col].set_title(title)"
      ],
      "metadata": {
        "id": "wGAqZs55sPwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a 5x5 grid of subplots with a figure size of 20x20\n",
        "fig, axes = plt.subplots(5, 5, figsize=(20, 20))\n",
        "# Add a title to the entire figure with specific font size and position\n",
        "plt.suptitle('Normalized Natural Wooded Vegetation Transitions areas (km$^2$) per 1000 km$^2$ by departments- 2001-2022', fontsize=14, y=1)\n",
        "\n",
        "# row 0\n",
        "maptma(\"NAGRT_2001\", \"2001\", 0, 0)  # Map data for 2001 in row 0, column 0\n",
        "maptma(\"NAGRT_2002\", \"2002\", 0, 1)  # Map data for 2002 in row 0, column 1\n",
        "maptma(\"NAGRT_2003\", \"2003\", 0, 2)  # Map data for 2003 in row 0, column 2\n",
        "maptma(\"NAGRT_2004\", \"2004\", 0, 3)  # Map data for 2004 in row 0, column 3\n",
        "maptma(\"NAGRT_2005\", \"2005\", 0, 4)  # Map data for 2005 in row 0, column 4\n",
        "\n",
        "# row 1\n",
        "maptma(\"NAGRT_2006\", \"2006\", 1, 0)  # Map data for 2006 in row 1, column 0\n",
        "maptma(\"NAGRT_2007\", \"2007\", 1, 1)  # Map data for 2007 in row 1, column 1\n",
        "maptma(\"NAGRT_2008\", \"2008\", 1, 2)  # Map data for 2008 in row 1, column 2\n",
        "maptma(\"NAGRT_2009\", \"2009\", 1, 3)  # Map data for 2009 in row 1, column 3\n",
        "maptma(\"NAGRT_2010\", \"2010\", 1, 4)  # Map data for 2010 in row 1, column 4\n",
        "\n",
        "# row 2\n",
        "maptma(\"NAGRT_2011\", \"2011\", 2, 0)  # Map data for 2011 in row 2, column 0\n",
        "maptma(\"NAGRT_2012\", \"2012\", 2, 1)  # Map data for 2012 in row 2, column 1\n",
        "maptma(\"NAGRT_2013\", \"2013\", 2, 2)  # Map data for 2013 in row 2, column 2\n",
        "maptma(\"NAGRT_2014\", \"2014\", 2, 3)  # Map data for 2014 in row 2, column 3\n",
        "maptma(\"NAGRT_2015\", \"2015\", 2, 4)  # Map data for 2015 in row 2, column 4\n",
        "\n",
        "# row 3\n",
        "maptma(\"NAGRT_2016\", \"2016\", 3, 0)  # Map data for 2016 in row 3, column 0\n",
        "maptma(\"NAGRT_2017\", \"2017\", 3, 1)  # Map data for 2017 in row 3, column 1\n",
        "maptma(\"NAGRT_2018\", \"2018\", 3, 2)  # Map data for 2018 in row 3, column 2\n",
        "maptma(\"NAGRT_2019\", \"2019\", 3, 3)  # Map data for 2019 in row 3, column 3\n",
        "maptma(\"NAGRT_2020\", \"2020\", 3, 4)  # Map data for 2020 in row 3, column 4\n",
        "\n",
        "# row 4\n",
        "maptma(\"NAGRT_2021\", \"2021\", 4, 0)  # Map data for 2021 in row 4, column 0\n",
        "maptma(\"NAGRT_2022\", \"2022\", 4, 1)  # Map data for 2022 in row 4, column 1\n",
        "\n",
        "axes[4,2].axis('off')  # Turn off axis for row 4, column 2\n",
        "axes[4,3].axis('off')  # Turn off axis for row 4, column 3\n",
        "axes[4,4].axis('off')  # Turn off axis for row 4, column 4\n",
        "\n",
        "plt.tight_layout()  # Adjust layout to prevent overlap\n",
        "plt.show();  # Display the plot"
      ],
      "metadata": {
        "id": "eLvsMFqwsPwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####NBUT (Normalized Built-up Transitions areas)"
      ],
      "metadata": {
        "id": "eRNDCXMsKnNe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a copy of  the geodataframe\n",
        "gdf_cl = gdf.copy()"
      ],
      "metadata": {
        "id": "bzP4OsRzLqtz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a list of column names that start with \"NBUT_\"\n",
        "nbut_columns = [col for col in gdf_cl.columns if col.startswith(\"NBUT_\")]"
      ],
      "metadata": {
        "id": "x1x88wR7Lqtz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select data to analize\n",
        "selected_data = gdf_cl.loc[:,nbut_columns]"
      ],
      "metadata": {
        "id": "vXR61izhLqt0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classify the data into 4 quantile groups\n",
        "q4 = mapclassify.Quantiles(selected_data, k=4)\n",
        "q4"
      ],
      "metadata": {
        "id": "Qrj5GqDNLqt0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Equal Interval Classification\n",
        "ei5 = mapclassify.EqualInterval(selected_data, k=5)\n",
        "ei5"
      ],
      "metadata": {
        "id": "ciV2zDhQLqt0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classify the data into groups based on the head/tail breaks algorithm\n",
        "ht = mapclassify.HeadTailBreaks(selected_data)\n",
        "ht"
      ],
      "metadata": {
        "id": "_o7BNeFCLqt0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MaximumBreaks classification method\n",
        "mb5 = mapclassify.MaximumBreaks(selected_data, k=5)\n",
        "mb5"
      ],
      "metadata": {
        "id": "wOS5qJ4LLqt0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the Standard Deviation and Mean classification method to the selected data.\n",
        "msd = mapclassify.StdMean(selected_data)\n",
        "msd"
      ],
      "metadata": {
        "id": "diMoutxkLqt0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply Fisher-Jenks classification with 5 classes\n",
        "fj5 = mapclassify.FisherJenks(selected_data, k=5)\n",
        "fj5"
      ],
      "metadata": {
        "id": "6DBdrrlgLqt0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bunch classifier objects\n",
        "class5 = q4, ei5, ht, mb5, msd, fj5\n",
        "# Collect ADCM for each classifier\n",
        "fits = np.array([c.adcm for c in class5])\n",
        "# Convert ADCM scores to a DataFrame\n",
        "adcms = pd.DataFrame(fits)\n",
        "# Add classifier names\n",
        "adcms[\"classifier\"] = [c.name for c in class5]\n",
        "# Add column names to the ADCM\n",
        "adcms.columns = [\"ADCM\", \"Classifier\"]\n",
        "ax = sns.barplot(\n",
        "    y=\"Classifier\", x=\"ADCM\", data=adcms, hue= adcms[\"Classifier\"],  legend=False\n",
        ")"
      ],
      "metadata": {
        "id": "RSXbtnhsLqt0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Create choropleth maps of NBUT"
      ],
      "metadata": {
        "id": "CmyrxCieLqt1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Two classifiers have the lowest ACDM: FisherJenks and HeadTailBreaks. We'll select FisherJenks as the classifier to create the choropleth maps."
      ],
      "metadata": {
        "id": "8geZbDibLqt1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the bins to a list for further processing\n",
        "bins = fj5.bins.tolist()\n",
        "bins"
      ],
      "metadata": {
        "id": "bS_w-ik-Lqt1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add 0.02 to bin for labeling\n",
        "bins_label  = bins.copy()\n",
        "bins_label.insert(0, 0.02)\n",
        "\n",
        "# Extract intervals from bins\n",
        "intervals = [f\"{bins_label[i]:.2f}-{bins_label[i+1]:.2f}\" for i in range(len(bins_label)-1)]\n",
        "intervals"
      ],
      "metadata": {
        "id": "eym-jkW6OcOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will create a function to set a custom classification scheme based on FisherJenks"
      ],
      "metadata": {
        "id": "RVlz2JtELqt1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def maptma(colname, title, row, col):\n",
        "    # Create a custom classification using UserDefined\n",
        "    classification = mapclassify.UserDefined(gdf_cl[colname], bins)\n",
        "\n",
        "    classification.plot(\n",
        "          gdf,  # GeoDataFrame containing the data to be plotted\n",
        "          legend=True,  # Enable the legend for the plot\n",
        "          legend_kwds={\n",
        "                \"fmt\": \"{:.0f}\",  # Format the legend labels as integers\n",
        "                # \"loc\": \"upper right\",  # Position the legend in the upper right corner\n",
        "                \"bbox_to_anchor\": (1.2, 0.4),  # Adjust the legend's position\n",
        "                \"fontsize\": 8,  # Set the font size of the legend\n",
        "                \"labels\": intervals  # Use the custom legend labels\n",
        "          },\n",
        "          axis_on=False,  # Disable the axis display\n",
        "          border_color='black',  # Set the border color of the plot\n",
        "          cmap=\"viridis_r\",  # Use the reversed Viridis colormap\n",
        "          ax=axes[row, col]  # Specify the subplot to draw the plot on\n",
        "     )\n",
        "\n",
        "    # Set the title for the current axis\n",
        "    axes[row, col].set_title(title)"
      ],
      "metadata": {
        "id": "rNHa0XxVLqt1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a 5x5 grid of subplots with a figure size of 20x20\n",
        "fig, axes = plt.subplots(5, 5, figsize=(20, 20))\n",
        "# Add a title to the entire figure with specific font size and position\n",
        "plt.suptitle('Normalized Built-up Transitions areas by departments - 2001-2022', fontsize=14, y=1)\n",
        "\n",
        "# row 0\n",
        "maptma(\"NBUT_2001\", \"2001\", 0, 0)  # Map data for 2001 in row 0, column 0\n",
        "maptma(\"NBUT_2002\", \"2002\", 0, 1)  # Map data for 2002 in row 0, column 1\n",
        "maptma(\"NBUT_2003\", \"2003\", 0, 2)  # Map data for 2003 in row 0, column 2\n",
        "maptma(\"NBUT_2004\", \"2004\", 0, 3)  # Map data for 2004 in row 0, column 3\n",
        "maptma(\"NBUT_2005\", \"2005\", 0, 4)  # Map data for 2005 in row 0, column 4\n",
        "\n",
        "# row 1\n",
        "maptma(\"NBUT_2006\", \"2006\", 1, 0)  # Map data for 2006 in row 1, column 0\n",
        "maptma(\"NBUT_2007\", \"2007\", 1, 1)  # Map data for 2007 in row 1, column 1\n",
        "maptma(\"NBUT_2008\", \"2008\", 1, 2)  # Map data for 2008 in row 1, column 2\n",
        "maptma(\"NBUT_2009\", \"2009\", 1, 3)  # Map data for 2009 in row 1, column 3\n",
        "maptma(\"NBUT_2010\", \"2010\", 1, 4)  # Map data for 2010 in row 1, column 4\n",
        "\n",
        "# row 2\n",
        "maptma(\"NBUT_2011\", \"2011\", 2, 0)  # Map data for 2011 in row 2, column 0\n",
        "maptma(\"NBUT_2012\", \"2012\", 2, 1)  # Map data for 2012 in row 2, column 1\n",
        "maptma(\"NBUT_2013\", \"2013\", 2, 2)  # Map data for 2013 in row 2, column 2\n",
        "maptma(\"NBUT_2014\", \"2014\", 2, 3)  # Map data for 2014 in row 2, column 3\n",
        "maptma(\"NBUT_2015\", \"2015\", 2, 4)  # Map data for 2015 in row 2, column 4\n",
        "\n",
        "# row 3\n",
        "maptma(\"NBUT_2016\", \"2016\", 3, 0)  # Map data for 2016 in row 3, column 0\n",
        "maptma(\"NBUT_2017\", \"2017\", 3, 1)  # Map data for 2017 in row 3, column 1\n",
        "maptma(\"NBUT_2018\", \"2018\", 3, 2)  # Map data for 2018 in row 3, column 2\n",
        "maptma(\"NBUT_2019\", \"2019\", 3, 3)  # Map data for 2019 in row 3, column 3\n",
        "maptma(\"NBUT_2020\", \"2020\", 3, 4)  # Map data for 2020 in row 3, column 4\n",
        "\n",
        "# row 4\n",
        "maptma(\"NBUT_2021\", \"2021\", 4, 0)  # Map data for 2021 in row 4, column 0\n",
        "maptma(\"NBUT_2022\", \"2022\", 4, 1)  # Map data for 2022 in row 4, column 1\n",
        "\n",
        "axes[4,2].axis('off')  # Turn off axis for row 4, column 2\n",
        "axes[4,3].axis('off')  # Turn off axis for row 4, column 3\n",
        "axes[4,4].axis('off')  # Turn off axis for row 4, column 4\n",
        "\n",
        "plt.tight_layout()  # Adjust layout to prevent overlap\n",
        "plt.show();  # Display the plot"
      ],
      "metadata": {
        "id": "L1A8nhAqLqt1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ELEV (Elevation)\n",
        "\n",
        "In this section, we will map the mean elevation for each department for the year 2001 only, as elevation values remain constant throughout the study period."
      ],
      "metadata": {
        "id": "xHiF2pmlTCpY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a copy of  the geodataframe\n",
        "gdf_cl = gdf.copy()"
      ],
      "metadata": {
        "id": "wIxatBT2fffh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select data to analize\n",
        "selected_data = gdf_cl.loc[:,\"ELEV_2001\"]"
      ],
      "metadata": {
        "id": "XMcCW8GYfffi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classify the data into 4 quantile groups\n",
        "q4 = mapclassify.Quantiles(selected_data, k=4)\n",
        "q4"
      ],
      "metadata": {
        "id": "zbzA4Fecfffi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Equal Interval Classification\n",
        "ei5 = mapclassify.EqualInterval(selected_data, k=5)\n",
        "ei5"
      ],
      "metadata": {
        "id": "NHJ5t8I1fffj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classify the data into groups based on the head/tail breaks algorithm\n",
        "ht = mapclassify.HeadTailBreaks(selected_data)\n",
        "ht"
      ],
      "metadata": {
        "id": "HoZKc54Lfffj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MaximumBreaks classification method\n",
        "mb5 = mapclassify.MaximumBreaks(selected_data, k=5)\n",
        "mb5"
      ],
      "metadata": {
        "id": "nlLm5pgBfffj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the Standard Deviation and Mean classification method to the selected data.\n",
        "msd = mapclassify.StdMean(selected_data)\n",
        "msd"
      ],
      "metadata": {
        "id": "N6Az5V44fffj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply Fisher-Jenks classification with 5 classes\n",
        "fj5 = mapclassify.FisherJenks(selected_data, k=5)\n",
        "fj5"
      ],
      "metadata": {
        "id": "hbqup6Z9fffk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bunch classifier objects\n",
        "class5 = q4, ei5, ht, mb5, msd, fj5\n",
        "# Collect ADCM for each classifier\n",
        "fits = np.array([c.adcm for c in class5])\n",
        "# Convert ADCM scores to a DataFrame\n",
        "adcms = pd.DataFrame(fits)\n",
        "# Add classifier names\n",
        "adcms[\"classifier\"] = [c.name for c in class5]\n",
        "# Add column names to the ADCM\n",
        "adcms.columns = [\"ADCM\", \"Classifier\"]\n",
        "ax = sns.barplot(\n",
        "    y=\"Classifier\", x=\"ADCM\", data=adcms, hue= adcms[\"Classifier\"],  legend=False\n",
        ")"
      ],
      "metadata": {
        "id": "mwM-HpUNfffk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Create choropleth maps of Elevation\n"
      ],
      "metadata": {
        "id": "nUa8NYHWfffk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Two classifiers have the lowest ACDM: FisherJenks and HeadTailBreaks. We'll select FisherJenks as the classifier to create the choropleth maps."
      ],
      "metadata": {
        "id": "63e2ShLofffk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the bins to a list for further processing\n",
        "bins = fj5.bins.tolist()\n",
        "bins"
      ],
      "metadata": {
        "id": "8dwSqHa-fffk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add 2.08 to bin for labeling\n",
        "bins_label  = bins.copy()\n",
        "bins_label.insert(0, 2.08)\n",
        "\n",
        "# Extract intervals from bins\n",
        "intervals = [f\"{bins_label[i]:.2f}-{bins_label[i+1]:.2f}\" for i in range(len(bins_label)-1)]\n",
        "intervals"
      ],
      "metadata": {
        "id": "we1c0AvZhKsB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a custom classification using UserDefined for actual values\n",
        "classi_2001 = mapclassify.UserDefined(selected_data, bins)"
      ],
      "metadata": {
        "id": "TMfzcnzZqf1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a single-plot figure\n",
        "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
        "plt.suptitle('Mean Elevation (m) by departments- 2001', fontsize=20, y=0.95)\n",
        "\n",
        "# Plot 2001 data\n",
        "classi_2001.plot(\n",
        "    gdf_cl,\n",
        "    legend=False,  # Custom legend\n",
        "    axis_on=False,\n",
        "    border_color='black',\n",
        "    cmap=\"viridis_r\",\n",
        "    ax=ax\n",
        ")\n",
        "\n",
        "# Custom bin labels and colors\n",
        "bin_labels = intervals\n",
        "\n",
        "n_bins = len(bin_labels)\n",
        "cmap = mpl.colormaps.get_cmap(\"viridis_r\").resampled(n_bins)\n",
        "colors = [mpl.colors.to_hex(cmap(i)) for i in range(cmap.N)]\n",
        "\n",
        "# Create legend patches for bins\n",
        "bin_patches = [Patch(facecolor=color, edgecolor='black', label=label)\n",
        "               for color, label in zip(colors, bin_labels)]\n",
        "\n",
        "# Display legend\n",
        "ax.legend(handles=bin_patches, loc='upper right', bbox_to_anchor=(1.1, 0.25), fontsize=10)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aDYeQ23xdkHB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Correlation of predictor variables with target variable"
      ],
      "metadata": {
        "id": "266TT3mmmZah"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Scatterplots + Linear Fits for Each Predictor"
      ],
      "metadata": {
        "id": "stVeNbo1gYRC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictors = [\"PM25\", \"NBA\", \"PD\", \"PDPM25\", \"NAGRT\", \"NNWVT\", \"NBUT\", \"ELEV\"]\n",
        "\n",
        "plt.figure(figsize=(16, 12))\n",
        "\n",
        "for i, var in enumerate(predictors, 1):\n",
        "    plt.subplot(3, 3, i)\n",
        "    sns.regplot(data=df_ts, x=var, y=\"CA\", scatter_kws={'alpha':0.3}, line_kws={\"color\":\"red\"})\n",
        "    plt.title(f\"CA vs {var}\")\n",
        "    plt.xlabel(var)\n",
        "    plt.ylabel(\"CA\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "6ZHhIklxeL5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Pearson & Spearman Correlations (CA vs predictors)"
      ],
      "metadata": {
        "id": "Q72t_gOdghQh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corr_results = {}\n",
        "\n",
        "for var in predictors:\n",
        "    pearson = df_ts[\"CA\"].corr(df_ts[var], method=\"pearson\")\n",
        "    spearman = df_ts[\"CA\"].corr(df_ts[var], method=\"spearman\")\n",
        "    corr_results[var] = {\"Pearson\": pearson, \"Spearman\": spearman}\n",
        "\n",
        "corr_df = pd.DataFrame(corr_results).T\n",
        "corr_df"
      ],
      "metadata": {
        "id": "leaSjFzXgjY6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Pretty heatmap of correlations"
      ],
      "metadata": {
        "id": "vtj9Z1vJiEEg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(6, 6))\n",
        "sns.heatmap(corr_df, annot=True, cmap=\"coolwarm\", center=0, fmt=\".3f\")\n",
        "plt.title(\"Correlation of CA with Predictors\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "MxpJXPvJiH2A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Interaction & Derived Features"
      ],
      "metadata": {
        "id": "YN7Uo7R_5XNU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code here"
      ],
      "metadata": {
        "id": "WgvVsMCY5ZdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check if PDPM25 is stronger than PM25"
      ],
      "metadata": {
        "id": "pKt34_jX99QX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# copy dataframe\n",
        "df_ts = df.copy()"
      ],
      "metadata": {
        "id": "PXI8t9oU9ycc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation analysis\n",
        "corr_pm25 = df_ts['CA'].corr(df_ts['PM25'])\n",
        "corr_pdpm25 = df_ts['CA'].corr(df_ts['PDPM25'])"
      ],
      "metadata": {
        "id": "gkGnFhgS926-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Correlation with CA (NAMR):\")\n",
        "print(f\"  PM25:    {corr_pm25:.3f}\")\n",
        "print(f\"  PDPM25:  {corr_pdpm25:.3f}\")"
      ],
      "metadata": {
        "id": "2_mvwt5q-LF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple regression comparison (RÂ²)\n",
        "# PM25 model\n",
        "X1 = sm.add_constant(df_ts['PM25'])\n",
        "model_pm25 = sm.OLS(df_ts['CA'], X1, missing='drop').fit()\n",
        "\n",
        "# PDPM25 model\n",
        "X2 = sm.add_constant(df_ts['PDPM25'])\n",
        "model_pdpm25 = sm.OLS(df_ts['CA'], X2, missing='drop').fit()"
      ],
      "metadata": {
        "id": "khE_0d---LS1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nR-squared comparison:\")\n",
        "print(f\"  PM25 model RÂ²:    {model_pm25.rsquared:.3f}\")\n",
        "print(f\"  PDPM25 model RÂ²:  {model_pdpm25.rsquared:.3f}\")"
      ],
      "metadata": {
        "id": "XFhtv_I5-iUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization\n",
        "plt.figure(figsize=(10,4))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "sns.regplot(x='PM25', y='CA', data=df_ts, scatter_kws={'alpha':0.4}, color='royalblue')\n",
        "plt.title(f\"PM25 vs CA (r={corr_pm25:.2f})\")\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "sns.regplot(x='PDPM25', y='CA', data=df_ts, scatter_kws={'alpha':0.4}, color='darkorange')\n",
        "plt.title(f\"PDPM25 vs CA (r={corr_pdpm25:.2f})\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EiYJa7uF-igQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Interpretation**\n",
        "\n",
        "* Both variables have extremely low correlation with asthma mortality rate. |r| < 0.1 usually indicates no meaningful linear relationship.\n",
        "* RÂ² = 0.003 so PMâ‚‚.â‚… explains about 0.3% of the variance in NAMR. PDPM25 explains almost none (RÂ² â‰ˆ 0). This means that multiplying PMâ‚‚.â‚… by population density (PDPM25) did not increase predictive power, it may have even diluted the signal.\n",
        "* The association between asthma mortality and PMâ‚‚.â‚… might be nonlinear or confounded by other spatial and temporal factors (e.g., climate, health access, or socioeconomic structure).PDPM25 might introduce multicollinearity with PD or PMâ‚‚.â‚…, weakening its independent explanatory power.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "v4A5DvbZCjp2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Lag effects"
      ],
      "metadata": {
        "id": "48kLY-_6F27y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# copy df as df_ts\n",
        "df_ts = df.copy()"
      ],
      "metadata": {
        "id": "1jumVz13roHU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define predictor variables and lags to test\n",
        "predictors = ['PM25', 'NBA', 'PD', 'PDPM25', 'NAGRT', 'NNWVT', 'NBUT']\n",
        "lags = [1, 2]  # lag 1 and lag 2 years"
      ],
      "metadata": {
        "id": "NEvUPxQXF459"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create lagged versions per department\n",
        "df_lagged = df_ts.copy()\n",
        "\n",
        "for var in predictors:\n",
        "    for lag in lags:\n",
        "        df_lagged[f'{var}_lag{lag}'] = df_lagged.groupby('IDDPTO')[var].shift(lag)"
      ],
      "metadata": {
        "id": "MmwFsc02rwOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute correlations of CA with current and lagged predictors ---\n",
        "corrs = {}\n",
        "\n",
        "for var in predictors:\n",
        "    corrs[var] = {\n",
        "        'r_current': df_lagged['CA'].corr(df_lagged[var]),\n",
        "        'r_lag1': df_lagged['CA'].corr(df_lagged[f'{var}_lag1']),\n",
        "        'r_lag2': df_lagged['CA'].corr(df_lagged[f'{var}_lag2'])\n",
        "    }\n",
        "\n",
        "corr_df = pd.DataFrame(corrs).T.round(3)\n",
        "print(\"ðŸ“ˆ Correlation of CA with predictors and their lags:\")\n",
        "print(corr_df)"
      ],
      "metadata": {
        "id": "6m32cTzNrwR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize lag correlations as a heatmap\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.heatmap(corr_df, annot=True, cmap=\"coolwarm\", center=0)\n",
        "plt.title(\"Lagged Correlation of Predictors with Asthma Mortality (CA)\")\n",
        "plt.ylabel(\"Predictor\")\n",
        "plt.xlabel(\"Lag type\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0Dtv-iPUsL3o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Interpretation of result**\n",
        "| Predictor                             |  r_current |   r_lag1   |   r_lag2   | ðŸ§­ Interpretation                                                                                                                             |\n",
        "| ------------------------------------- | :--------: | :--------: | :--------: | --------------------------------------------------------------------------------------------------------------------------------------------- |\n",
        "| **PMâ‚‚.â‚…**                             |   âˆ’0.054   |   âˆ’0.058   |   âˆ’0.046   | Weak, slightly stronger at lag-1 â†’ possible short delayed effect but negligible magnitude.                                                    |\n",
        "| **NBA (Burned area)**                 |   +0.011   |   âˆ’0.002   |   âˆ’0.009   | No clear linear relationship; effects may be local or nonlinear.                                                                              |\n",
        "| **PD (Population density)**           |   âˆ’0.004   |   âˆ’0.004   |   âˆ’0.003   | Essentially no correlation; consistent across time.                                                                                           |\n",
        "| **PDÃ—PMâ‚‚.â‚…**                          |    0.000   |   âˆ’0.001   |   +0.001   | Confirms PDPM25 adds no value beyond PMâ‚‚.â‚….                                                                                                   |\n",
        "| **NAGRT (Agro-livestock transition)** | **+0.112** | **+0.109** | **+0.102** | Only variable with modest positive correlation; stable through time. Suggests link between agricultural land conversion and asthma mortality. |\n",
        "| **NNWVT (Natural wooded transition)** |   âˆ’0.013   |   âˆ’0.018   |   âˆ’0.019   | Weak negative trend; may indicate protective vegetation cover.                                                                                |\n",
        "| **NBUT (Built-up transitions)**       |   +0.043   |   +0.043   |   +0.039   | Very weak positive relation, possibly urbanization signal.                                                                                    |\n"
      ],
      "metadata": {
        "id": "uHbj-ogaUvNi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multicollinearity & Dimension Reduction"
      ],
      "metadata": {
        "id": "A7Ji9UwEAEce"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Correlation Matrix"
      ],
      "metadata": {
        "id": "rbA8syOc5Rst"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "panel_gdf.columns"
      ],
      "metadata": {
        "id": "D9nkemj_e9VD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictors = ['PM25', 'NBA', 'PD', 'PDPM25', 'NAGRT', 'NNWVT','NBUT', 'ELEV']  # example\n",
        "X = panel_gdf[predictors].copy()"
      ],
      "metadata": {
        "id": "HfAs4hd9e9Xd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Correlation Matrix\n",
        "\n",
        "corr_matrix = X.corr()\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", square=True)\n",
        "plt.title(\"Correlation Matrix of Predictors\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mvt-o-S66k2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  VIF Calculation"
      ],
      "metadata": {
        "id": "bCPnNvRN56FT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code here"
      ],
      "metadata": {
        "id": "RU7-raZu57Pj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Apply PCA or clustering"
      ],
      "metadata": {
        "id": "V3MBp3rZ6FqL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code here"
      ],
      "metadata": {
        "id": "8kBAc43e58uj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pending**\n",
        "\n",
        "In 03.Asthma_Mortality_EDA.ipynb\n",
        "\n",
        "ðŸ”¥ Heatmaps: CA across departments vs years (matrix form).\n",
        "\n",
        "ðŸ“Š Space-time cube idea: Department vs year vs CA (3D visualization optional)"
      ],
      "metadata": {
        "id": "fF6YHKPz7_YS"
      }
    }
  ]
}